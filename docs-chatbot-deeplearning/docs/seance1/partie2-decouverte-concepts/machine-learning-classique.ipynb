{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook A: Classification avec Machine Learning classique\n",
    "# Classification des chiffres manuscrits avec Random Forest\n",
    "\n",
    "# Partie 1: Importation des bibliothèques\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Partie 2: Chargement et exploration des données\n",
    "print(\"Chargement du jeu de données MNIST...\")\n",
    "# Utilisation du jeu de données MNIST intégré à sklearn\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "X = X / 255.0  # Normalisation des valeurs de pixels entre 0 et 1\n",
    "y = y.astype(np.uint8)  # Conversion des labels en entiers\n",
    "\n",
    "# Exploration des données\n",
    "print(f\"Dimensions du jeu de données: {X.shape}\")\n",
    "print(f\"Nombre de classes: {len(np.unique(y))}\")\n",
    "\n",
    "# Affichage de quelques exemples\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"Label: {y[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Exemples de chiffres manuscrits\", y=1.05)\n",
    "plt.show()\n",
    "\n",
    "# Partie 3: Préparation des données pour Machine Learning classique\n",
    "\n",
    "print(\"\\n--- Préparation des données pour Random Forest ---\")\n",
    "print(\"Pour le Machine Learning classique, nous devons souvent extraire des caractéristiques manuellement.\")\n",
    "\n",
    "# Réduction de dimension avec PCA pour accélérer l'entraînement\n",
    "print(\"Application d'une réduction de dimension (PCA)...\")\n",
    "n_components = 50  # Réduire de 784 à 50 caractéristiques\n",
    "\n",
    "# Séparation en ensembles d'entraînement et de test\n",
    "# Utilisation d'un échantillon réduit pour accélérer la démonstration\n",
    "X_sample = X[:10000]\n",
    "y_sample = y[:10000]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Taille de l'ensemble d'entraînement: {X_train.shape}\")\n",
    "print(f\"Taille de l'ensemble de test: {X_test.shape}\")\n",
    "\n",
    "# Création d'un pipeline d'extraction de caractéristiques\n",
    "feature_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=n_components))\n",
    "])\n",
    "\n",
    "# Application aux données\n",
    "print(\"Extraction de caractéristiques...\")\n",
    "X_train_features = feature_pipeline.fit_transform(X_train)\n",
    "X_test_features = feature_pipeline.transform(X_test)\n",
    "\n",
    "print(f\"Dimensions après extraction de caractéristiques: {X_train_features.shape}\")\n",
    "\n",
    "# Partie 4: Entraînement du modèle Random Forest\n",
    "\n",
    "print(\"\\n--- Entraînement du modèle Random Forest ---\")\n",
    "\n",
    "# Paramètres du modèle - vous pouvez les modifier\n",
    "n_estimators = 100  # Nombre d'arbres\n",
    "max_depth = 10      # Profondeur maximale des arbres\n",
    "min_samples_split = 2  # Nombre minimum d'échantillons requis pour diviser un nœud\n",
    "\n",
    "# Création du modèle\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=n_estimators,\n",
    "    max_depth=max_depth,\n",
    "    min_samples_split=min_samples_split,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Utiliser tous les cœurs disponibles\n",
    ")\n",
    "\n",
    "# Mesure du temps d'entraînement\n",
    "start_time = time.time()\n",
    "print(\"Entraînement du modèle en cours...\")\n",
    "rf_model.fit(X_train_features, y_train)\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "print(f\"Temps d'entraînement: {training_time:.2f} secondes\")\n",
    "\n",
    "# Partie 5: Évaluation du modèle\n",
    "\n",
    "print(\"\\n--- Évaluation du modèle Random Forest ---\")\n",
    "\n",
    "# Prédictions sur l'ensemble de test\n",
    "y_pred = rf_model.predict(X_test_features)\n",
    "\n",
    "# Calcul des métriques\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Précision globale: {accuracy*100:.2f}%\")\n",
    "print(\"\\nMatrice de confusion:\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Prédictions')\n",
    "plt.ylabel('Valeurs réelles')\n",
    "plt.title('Matrice de confusion')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRapport de classification:\")\n",
    "print(class_report)\n",
    "\n",
    "# Partie 6: Visualisation des erreurs\n",
    "\n",
    "print(\"\\n--- Analyse des erreurs ---\")\n",
    "\n",
    "# Identifier les erreurs\n",
    "error_indices = np.where(y_pred != y_test)[0]\n",
    "n_errors = min(10, len(error_indices))  # Afficher max 10 erreurs\n",
    "\n",
    "if n_errors > 0:\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for i, idx in enumerate(error_indices[:n_errors]):\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        # Récupérer l'image originale\n",
    "        img = X_test[idx].reshape(28, 28)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(f\"Réel: {y_test[idx]}\\nPrédit: {y_pred[idx]}\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"Exemples d'erreurs de classification\", y=1.05)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Aucune erreur trouvée dans l'échantillon de test!\")\n",
    "\n",
    "# Partie 7: Importance des caractéristiques\n",
    "\n",
    "print(\"\\n--- Importance des caractéristiques ---\")\n",
    "# Visualiser l'importance des composantes principales\n",
    "feature_importance = rf_model.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(20), feature_importance[sorted_idx[:20]])\n",
    "plt.xticks(range(20), [f\"Feat {i}\" for i in sorted_idx[:20]], rotation=90)\n",
    "plt.xlabel('Composantes principales')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Top 20 des composantes principales les plus importantes')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Les caractéristiques les plus importantes sont les composantes principales qui capturent le plus de variance dans les données.\")\n",
    "\n",
    "# Partie 8: Défi de généralisation\n",
    "\n",
    "print(\"\\n--- Défi de généralisation ---\")\n",
    "print(\"Nous allons maintenant tester le modèle sur des chiffres légèrement modifiés pour évaluer sa capacité de généralisation.\")\n",
    "\n",
    "# Fonction pour ajouter du bruit aux images\n",
    "def add_noise(images, noise_level=0.2):\n",
    "    noisy_images = images.copy()\n",
    "    noise = np.random.normal(0, noise_level, images.shape)\n",
    "    noisy_images = noisy_images + noise\n",
    "    # Assurer que les valeurs restent entre 0 et 1\n",
    "    noisy_images = np.clip(noisy_images, 0, 1)\n",
    "    return noisy_images\n",
    "\n",
    "# Fonction pour appliquer une rotation aux images\n",
    "def rotate_images(images, max_angle=15):\n",
    "    from scipy.ndimage import rotate\n",
    "    rotated_images = np.zeros_like(images)\n",
    "    for i, img in enumerate(images):\n",
    "        angle = np.random.uniform(-max_angle, max_angle)\n",
    "        img_2d = img.reshape(28, 28)\n",
    "        rotated = rotate(img_2d, angle, reshape=False)\n",
    "        rotated_images[i] = rotated.flatten()\n",
    "    return rotated_images\n",
    "\n",
    "# Créer un jeu de données modifié\n",
    "print(\"Création d'un jeu de données avec des chiffres modifiés...\")\n",
    "\n",
    "# Utiliser la partie restante des données pour ce test\n",
    "X_new = X[10000:12000]\n",
    "y_new = y[10000:12000]\n",
    "\n",
    "# Appliquer des transformations\n",
    "X_new_noisy = add_noise(X_new, noise_level=0.2)\n",
    "X_new_rotated = rotate_images(X_new, max_angle=15)\n",
    "\n",
    "# Visualiser quelques exemples\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(5):\n",
    "    # Original\n",
    "    plt.subplot(3, 5, i + 1)\n",
    "    plt.imshow(X_new[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"Original: {y_new[i]}\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Avec bruit\n",
    "    plt.subplot(3, 5, i + 6)\n",
    "    plt.imshow(X_new_noisy[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(\"Avec bruit\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Avec rotation\n",
    "    plt.subplot(3, 5, i + 11)\n",
    "    plt.imshow(X_new_rotated[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(\"Avec rotation\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Exemples de chiffres modifiés\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Évaluer le modèle sur les données modifiées\n",
    "print(\"\\nÉvaluation sur les données avec bruit:\")\n",
    "X_new_noisy_features = feature_pipeline.transform(X_new_noisy)\n",
    "y_new_noisy_pred = rf_model.predict(X_new_noisy_features)\n",
    "accuracy_noisy = accuracy_score(y_new, y_new_noisy_pred)\n",
    "print(f\"Précision sur données bruitées: {accuracy_noisy*100:.2f}%\")\n",
    "\n",
    "print(\"\\nÉvaluation sur les données avec rotation:\")\n",
    "X_new_rotated_features = feature_pipeline.transform(X_new_rotated)\n",
    "y_new_rotated_pred = rf_model.predict(X_new_rotated_features)\n",
    "accuracy_rotated = accuracy_score(y_new, y_new_rotated_pred)\n",
    "print(f\"Précision sur données pivotées: {accuracy_rotated*100:.2f}%\")\n",
    "\n",
    "print(\"\\nComparaison avec la précision originale:\")\n",
    "print(f\"Précision sur données originales: {accuracy*100:.2f}%\")\n",
    "print(f\"Précision sur données bruitées: {accuracy_noisy*100:.2f}%\")\n",
    "print(f\"Précision sur données pivotées: {accuracy_rotated*100:.2f}%\")\n",
    "\n",
    "# Partie 9: Conclusions et réflexion\n",
    "\n",
    "print(\"\\n--- Conclusions sur le Machine Learning classique ---\")\n",
    "print(\"\"\"\n",
    "Points forts du Random Forest:\n",
    "- Entraînement relativement rapide\n",
    "- Bonnes performances sur les données originales\n",
    "- Interprétabilité (importance des caractéristiques)\n",
    "\n",
    "Limites:\n",
    "- Nécessite une extraction manuelle de caractéristiques (PCA dans notre cas)\n",
    "- Sensibilité aux transformations des données (bruit, rotation)\n",
    "- Difficulté à capturer des motifs complexes sans feature engineering approprié\n",
    "\n",
    "Questions pour la réflexion:\n",
    "1. Pourquoi avons-nous besoin de réduire la dimensionnalité pour le Random Forest?\n",
    "2. Comment pourrait-on améliorer la robustesse aux transformations?\n",
    "3. Quelles autres caractéristiques pourraient être extraites manuellement pour améliorer les performances?\n",
    "\"\"\")\n",
    "\n",
    "# Partie 10: Widget interactif pour tester le modèle\n",
    "\n",
    "print(\"\\n--- Testez le modèle vous-même ---\")\n",
    "\n",
    "def test_model(digit_idx):\n",
    "    if digit_idx < len(X_test):\n",
    "        # Afficher l'image\n",
    "        img = X_test[digit_idx].reshape(28, 28)\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(f\"Chiffre à classifier\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        # Faire la prédiction\n",
    "        features = feature_pipeline.transform([X_test[digit_idx]])\n",
    "        prediction = rf_model.predict(features)[0]\n",
    "        real_label = y_test[digit_idx]\n",
    "        \n",
    "        print(f\"Prédiction du modèle Random Forest: {prediction}\")\n",
    "        print(f\"Étiquette réelle: {real_label}\")\n",
    "        print(f\"Prédiction {'correcte' if prediction == real_label else 'incorrecte'}\")\n",
    "    else:\n",
    "        print(\"Index hors limites!\")\n",
    "\n",
    "# Créer un slider pour sélectionner un chiffre à tester\n",
    "digit_selector = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(X_test)-1,\n",
    "    step=1,\n",
    "    description='Index:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "# Bouton pour exécuter le test\n",
    "test_button = widgets.Button(description=\"Tester\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        test_model(digit_selector.value)\n",
    "\n",
    "test_button.on_click(on_button_clicked)\n",
    "\n",
    "# Afficher les widgets\n",
    "display(widgets.HBox([digit_selector, test_button]))\n",
    "display(output)\n",
    "\n",
    "print(\"Utilisez le slider pour sélectionner un index et cliquez sur 'Tester' pour classifier le chiffre correspondant.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
