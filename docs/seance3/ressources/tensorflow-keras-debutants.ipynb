{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# TensorFlow/Keras pour débutants\n",
    "# Notebook d'introduction à TensorFlow pour applications simples\n",
    "\n",
    "# 1. Configuration et importation des bibliothèques\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Vérification de la version de TensorFlow\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Vérification de la disponibilité du GPU (optionnel)\n",
    "print(\"GPU disponible:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# 2. Jeu de données Fashion MNIST (vêtements)\n",
    "# Fashion MNIST est similaire à MNIST mais avec des vêtements au lieu de chiffres\n",
    "# C'est un bon jeu de données pour commencer la vision par ordinateur\n",
    "\n",
    "# Charger les données\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Noms des classes de vêtements\n",
    "class_names = ['T-shirt/haut', 'Pantalon', 'Pull', 'Robe', 'Manteau',\n",
    "               'Sandale', 'Chemise', 'Baskets', 'Sac', 'Bottine']\n",
    "\n",
    "# 3. Exploration des données\n",
    "print(f\"Forme des données d'entraînement: {train_images.shape}\")\n",
    "print(f\"Nombre d'images d'entraînement: {len(train_labels)}\")\n",
    "print(f\"Forme des données de test: {test_images.shape}\")\n",
    "print(f\"Nombre d'images de test: {len(test_labels)}\")\n",
    "\n",
    "# Afficher quelques exemples d'images\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()\n",
    "\n",
    "# 4. Prétraitement des données\n",
    "# Normalisation des valeurs de pixels entre 0 et 1\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# 5. Construction d'un modèle simple\n",
    "model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),      # Conversion de l'image 28x28 en un vecteur 1D de 784 valeurs\n",
    "    layers.Dense(128, activation='relu'),      # Couche cachée avec 128 neurones et activation ReLU\n",
    "    layers.Dense(10, activation='softmax')     # Couche de sortie avec 10 neurones (un par classe) et softmax\n",
    "])\n",
    "\n",
    "# Afficher le résumé du modèle\n",
    "model.summary()\n",
    "\n",
    "# 6. Compilation du modèle\n",
    "model.compile(\n",
    "    optimizer='adam',                          # Algorithme d'optimisation\n",
    "    loss='sparse_categorical_crossentropy',    # Fonction de perte pour la classification\n",
    "    metrics=['accuracy']                       # Métrique à suivre pendant l'entraînement\n",
    ")\n",
    "\n",
    "# 7. Entraînement du modèle\n",
    "history = model.fit(\n",
    "    train_images, \n",
    "    train_labels, \n",
    "    epochs=10,                 # Nombre de passages sur l'ensemble du jeu de données\n",
    "    batch_size=32,             # Nombre d'échantillons traités avant mise à jour des poids\n",
    "    validation_split=0.2       # 20% des données d'entraînement utilisées pour la validation\n",
    ")\n",
    "\n",
    "# 8. Visualisation des courbes d'apprentissage\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Courbe de précision\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Précision (entraînement)')\n",
    "plt.plot(history.history['val_accuracy'], label='Précision (validation)')\n",
    "plt.xlabel('Époque')\n",
    "plt.ylabel('Précision')\n",
    "plt.legend()\n",
    "plt.title('Évolution de la précision')\n",
    "\n",
    "# Courbe de perte\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Perte (entraînement)')\n",
    "plt.plot(history.history['val_loss'], label='Perte (validation)')\n",
    "plt.xlabel('Époque')\n",
    "plt.ylabel('Perte')\n",
    "plt.legend()\n",
    "plt.title('Évolution de la fonction de perte')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9. Évaluation sur les données de test\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f\"\\nPrécision sur les données de test: {test_acc:.4f}\")\n",
    "print(f\"Perte sur les données de test: {test_loss:.4f}\")\n",
    "\n",
    "# 10. Faire des prédictions\n",
    "# Prédire la classe de quelques images de test\n",
    "predictions = model.predict(test_images[:5])\n",
    "\n",
    "# Afficher les 5 premières prédictions\n",
    "for i in range(5):\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(test_images[i], cmap=plt.cm.binary)\n",
    "    plt.title(f\"Image: {class_names[test_labels[i]]}\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.barh(class_names, predictions[i])\n",
    "    plt.title('Probabilités prédites')\n",
    "    \n",
    "    predicted_class = np.argmax(predictions[i])\n",
    "    actual_class = test_labels[i]\n",
    "    \n",
    "    status = \"✓ Correct\" if predicted_class == actual_class else \"✗ Incorrect\"\n",
    "    plt.xlabel(f\"Prédiction: {class_names[predicted_class]} ({status})\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 11. Sauvegarder le modèle\n",
    "model.save('fashion_mnist_model.h5')\n",
    "print(\"Modèle sauvegardé sous 'fashion_mnist_model.h5'\")\n",
    "\n",
    "# 12. Exercices pratiques\n",
    "#\n",
    "# À FAIRE: Modifiez l'architecture du modèle pour améliorer ses performances\n",
    "# Par exemple, essayez d'ajouter des couches, changer le nombre de neurones,\n",
    "# ou ajouter une régularisation.\n",
    "#\n",
    "# Voici un exemple de départ:\n",
    "#\n",
    "# model_improved = models.Sequential([\n",
    "#     layers.Flatten(input_shape=(28, 28)),\n",
    "#     layers.Dense(256, activation='relu'),\n",
    "#     layers.Dropout(0.2),                     # Ajout d'une couche Dropout pour réduire le surapprentissage\n",
    "#     layers.Dense(128, activation='relu'),\n",
    "#     layers.Dense(10, activation='softmax')\n",
    "# ])\n",
    "#\n",
    "# model_improved.compile(optimizer='adam',\n",
    "#                       loss='sparse_categorical_crossentropy',\n",
    "#                       metrics=['accuracy'])\n",
    "#\n",
    "# # Entraîner le modèle amélioré et comparer les performances\n",
    "\n",
    "# 13. Passer à des modèles plus complexes\n",
    "#\n",
    "# Si vous avez le temps, essayez d'utiliser un modèle CNN\n",
    "# qui est beaucoup plus adapté aux images:\n",
    "#\n",
    "# cnn_model = models.Sequential([\n",
    "#     layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "#     layers.MaxPooling2D((2, 2)),\n",
    "#     layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#     layers.MaxPooling2D((2, 2)),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(128, activation='relu'),\n",
    "#     layers.Dense(10, activation='softmax')\n",
    "# ])\n",
    "#\n",
    "# # N'oubliez pas de redimensionner vos images pour le modèle CNN\n",
    "# # train_images_reshaped = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "# # test_images_reshaped = test_images.reshape(test_images.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# TensorFlow/Keras pour débutants - BTS SIO \n",
    "# Notebook d'introduction à TensorFlow pour applications simples\n",
    "\n",
    "# 1. Configuration et importation des bibliothèques\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Vérification de la version de TensorFlow\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Vérification de la disponibilité du GPU (optionnel)\n",
    "print(\"GPU disponible:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# 2. Jeu de données Fashion MNIST (vêtements)\n",
    "# Fashion MNIST est similaire à MNIST mais avec des vêtements au lieu de chiffres\n",
    "# C'est un bon jeu de données pour commencer la vision par ordinateur\n",
    "\n",
    "# Charger les données\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Noms des classes de vêtements\n",
    "class_names = ['T-shirt/haut', 'Pantalon', 'Pull', 'Robe', 'Manteau',\n",
    "               'Sandale', 'Chemise', 'Baskets', 'Sac', 'Bottine']\n",
    "\n",
    "# 3. Exploration des données\n",
    "print(f\"Forme des données d'entraînement: {train_images.shape}\")\n",
    "print(f\"Nombre d'images d'entraînement: {len(train_labels)}\")\n",
    "print(f\"Forme des données de test: {test_images.shape}\")\n",
    "print(f\"Nombre d'images de test: {len(test_labels)}\")\n",
    "\n",
    "# Afficher quelques exemples d'images\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()\n",
    "\n",
    "# 4. Prétraitement des données\n",
    "# Normalisation des valeurs de pixels entre 0 et 1\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# 5. Construction d'un modèle simple\n",
    "model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),      # Conversion de l'image 28x28 en un vecteur 1D de 784 valeurs\n",
    "    layers.Dense(128, activation='relu'),      # Couche cachée avec 128 neurones et activation ReLU\n",
    "    layers.Dense(10, activation='softmax')     # Couche de sortie avec 10 neurones (un par classe) et softmax\n",
    "])\n",
    "\n",
    "# Afficher le résumé du modèle\n",
    "model.summary()\n",
    "\n",
    "# 6. Compilation du modèle\n",
    "model.compile(\n",
    "    optimizer='adam',                          # Algorithme d'optimisation\n",
    "    loss='sparse_categorical_crossentropy',    # Fonction de perte pour la classification\n",
    "    metrics=['accuracy']                       # Métrique à suivre pendant l'entraînement\n",
    ")\n",
    "\n",
    "# 7. Entraînement du modèle\n",
    "history = model.fit(\n",
    "    train_images, \n",
    "    train_labels, \n",
    "    epochs=10,                 # Nombre de passages sur l'ensemble du jeu de données\n",
    "    batch_size=32,             # Nombre d'échantillons traités avant mise à jour des poids\n",
    "    validation_split=0.2       # 20% des données d'entraînement utilisées pour la validation\n",
    ")\n",
    "\n",
    "# 8. Visualisation des courbes d'apprentissage\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Courbe de précision\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Précision (entraînement)')\n",
    "plt.plot(history.history['val_accuracy'], label='Précision (validation)')\n",
    "plt.xlabel('Époque')\n",
    "plt.ylabel('Précision')\n",
    "plt.legend()\n",
    "plt.title('Évolution de la précision')\n",
    "\n",
    "# Courbe de perte\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Perte (entraînement)')\n",
    "plt.plot(history.history['val_loss'], label='Perte (validation)')\n",
    "plt.xlabel('Époque')\n",
    "plt.ylabel('Perte')\n",
    "plt.legend()\n",
    "plt.title('Évolution de la fonction de perte')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9. Évaluation sur les données de test\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f\"\\nPrécision sur les données de test: {test_acc:.4f}\")\n",
    "print(f\"Perte sur les données de test: {test_loss:.4f}\")\n",
    "\n",
    "# 10. Faire des prédictions\n",
    "# Prédire la classe de quelques images de test\n",
    "predictions = model.predict(test_images[:5])\n",
    "\n",
    "# Afficher les 5 premières prédictions\n",
    "for i in range(5):\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(test_images[i], cmap=plt.cm.binary)\n",
    "    plt.title(f\"Image: {class_names[test_labels[i]]}\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.barh(class_names, predictions[i])\n",
    "    plt.title('Probabilités prédites')\n",
    "    \n",
    "    predicted_class = np.argmax(predictions[i])\n",
    "    actual_class = test_labels[i]\n",
    "    \n",
    "    status = \"✓ Correct\" if predicted_class == actual_class else \"✗ Incorrect\"\n",
    "    plt.xlabel(f\"Prédiction: {class_names[predicted_class]} ({status})\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 11. Sauvegarder le modèle\n",
    "model.save('fashion_mnist_model.h5')\n",
    "print(\"Modèle sauvegardé sous 'fashion_mnist_model.h5'\")\n",
    "\n",
    "# 12. Exercices pratiques\n",
    "#\n",
    "# À FAIRE: Modifiez l'architecture du modèle pour améliorer ses performances\n",
    "# Par exemple, essayez d'ajouter des couches, changer le nombre de neurones,\n",
    "# ou ajouter une régularisation.\n",
    "#\n",
    "# Voici un exemple de départ:\n",
    "#\n",
    "# model_improved = models.Sequential([\n",
    "#     layers.Flatten(input_shape=(28, 28)),\n",
    "#     layers.Dense(256, activation='relu'),\n",
    "#     layers.Dropout(0.2),                     # Ajout d'une couche Dropout pour réduire le surapprentissage\n",
    "#     layers.Dense(128, activation='relu'),\n",
    "#     layers.Dense(10, activation='softmax')\n",
    "# ])\n",
    "#\n",
    "# model_improved.compile(optimizer='adam',\n",
    "#                       loss='sparse_categorical_crossentropy',\n",
    "#                       metrics=['accuracy'])\n",
    "#\n",
    "# # Entraîner le modèle amélioré et comparer les performances\n",
    "\n",
    "# 13. Passer à des modèles plus complexes\n",
    "#\n",
    "# Si vous avez le temps, essayez d'utiliser un modèle CNN\n",
    "# qui est beaucoup plus adapté aux images:\n",
    "#\n",
    "# cnn_model = models.Sequential([\n",
    "#     layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "#     layers.MaxPooling2D((2, 2)),\n",
    "#     layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#     layers.MaxPooling2D((2, 2)),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(128, activation='relu'),\n",
    "#     layers.Dense(10, activation='softmax')\n",
    "# ])\n",
    "#\n",
    "# # N'oubliez pas de redimensionner vos images pour le modèle CNN\n",
    "# # train_images_reshaped = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "# # test_images_reshaped = test_images.reshape(test_images.shape[0], 28, 28, 1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
