# üß∞ Phase 1 : Frameworks de Deep Learning (1h30)

![Frameworks pour d√©butants](https://images.unsplash.com/photo-1545987796-200677ee1011?auto=format&fit=crop&q=80&w=1000&h=300)

## üîç Introduction aux frameworks dans un contexte professionnel (15 min)

** üéØ Objectif**: Comprendre l'utilit√© des frameworks de Deep Learning pour un d√©veloppeur en entreprise et identifier ceux qui sont r√©ellement utilis√©s sur le terrain.

### üíº Les frameworks en entreprise

Avant de plonger dans le code, prenons un moment pour comprendre pourquoi les frameworks de Deep Learning sont si importants en contexte professionnel:

- **üöÄ Productivit√©**: Ils permettent de d√©velopper des applications d'IA sans repartir de z√©ro
- **üîß Maintenabilit√©**: Code plus standard, plus facile √† comprendre par d'autres d√©veloppeurs
- **‚ö° Performances**: Optimisations int√©gr√©es qui seraient complexes √† d√©velopper soi-m√™me
- **üö¢ D√©ploiement**: Outils int√©gr√©s pour mettre en production les mod√®les

Dans le monde professionnel actuel, plusieurs frameworks de Deep Learning sont couramment utilis√©s:

| Framework | Principaux cas d'usage |
|-----------|------------------------|
| TensorFlow/Keras | Applications web/mobile, syst√®mes en production |
| PyTorch | Recherche, prototypage, startups |
| Hugging Face | NLP, chatbots, traitement de texte |
| Scikit-learn | Pr√©traitement, ML classique, pipeline de donn√©es |

> "Pour un stage, la capacit√© √† utiliser efficacement des frameworks existants est recherch√©e davantage que l'expertise th√©orique approfondie en Deep Learning." 
> 

### TensorFlow/Keras: la solution pragmatique

Pour cette s√©ance, nous allons nous concentrer sur TensorFlow/Keras pour plusieurs raisons:

1. **Interface simple**: Keras offre une API haut niveau, parfaite pour d√©buter
2. **D√©ploiement facile**: Solutions int√©gr√©es pour mettre en production (TF Serving, TFLite)
3. **Documentation riche**: Ressources abondantes en fran√ßais
4. **Mod√®les pr√©-entra√Æn√©s**: Large biblioth√®que de mod√®les pr√™ts √† l'emploi
5. **Demande professionnelle**: Le plus mentionn√© dans les offres de stage

### D√©monstration: Applications r√©elles en entreprise

Voici quelques exemples concrets d√©velopp√©s par des entreprises locales employant des anciens √©tudiants:

- **PME de logistique**: Application de reconnaissance de documents (bons de livraison, factures) permettant d'automatiser la saisie ‚Üí √âconomie de 15h/semaine
- **Agence web**: Syst√®me de d√©tection de contenu inappropri√© dans les commentaires de sites e-commerce
- **Cabinet m√©dical**: Application de classification d'images pour le tri pr√©liminaire de photos de l√©sions cutan√©es

## Atelier pratique : Prise en main de TensorFlow/Keras (30 min)

### Objectif

D√©velopper une premi√®re application de reconnaissance d'images simple en utilisant TensorFlow/Keras et en suivant les bonnes pratiques de l'industrie.

### Instructions pas √† pas

#### √âtape 1: Configuration de l'environnement (5 min)

1. Ouvrez Google Colab dans votre navigateur en allant sur [colab.research.google.com](https://colab.research.google.com)
2. Cr√©ez un nouveau notebook en cliquant sur "Nouveau notebook"
3. Renommez le notebook en "Reconnaissance d'images TensorFlow" en cliquant sur "Untitled" en haut
4. Copiez-collez le code suivant dans la premi√®re cellule et ex√©cutez-la en cliquant sur le bouton Play ou en appuyant sur Shift+Enter:

```python
# V√©rification de la version de TensorFlow
import tensorflow as tf
print("TensorFlow version:", tf.__version__)

# Importation des biblioth√®ques essentielles
from tensorflow.keras import layers, models
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.preprocessing import image
import numpy as np
import matplotlib.pyplot as plt
```

#### √âtape 2: Utilisation d'un mod√®le pr√©-entra√Æn√© (10 min)

1. Cr√©ez une nouvelle cellule en cliquant sur le bouton "+ Code" ou en appuyant sur Alt+Enter
2. Copiez-collez le code suivant et ex√©cutez-le:

```python
# Chargement d'un mod√®le pr√©-entra√Æn√© complet
model = MobileNetV2(weights='imagenet')

# Affichage du r√©sum√© du mod√®le pour comprendre son architecture
print("Structure du mod√®le:")
model.summary()
```

3. Observez la structure du mod√®le dans la sortie: notez le nombre de param√®tres, les diff√©rentes couches, etc.

#### √âtape 3: Pr√©paration d'une image de test (5 min)

1. Cr√©ez une nouvelle cellule et ex√©cutez le code suivant:

```python
# T√©l√©chargement d'une image d'exemple
!wget -q -O test_image.jpg https://upload.wikimedia.org/wikipedia/commons/thumb/9/9a/Pug_600.jpg/280px-Pug_600.jpg

# Affichage de l'image t√©l√©charg√©e
plt.figure(figsize=(4, 4))
plt.imshow(image.load_img('test_image.jpg'))
plt.axis('off')
plt.title("Image √† classifier")
plt.show()

# Fonction pour pr√©traiter l'image
def preprocess_image(img_path):
    # Chargement et redimensionnement √† la taille attendue par le mod√®le
    img = image.load_img(img_path, target_size=(224, 224))
    
    # Conversion en tableau numpy
    img_array = image.img_to_array(img)
    
    # Ajout de la dimension de batch (pour un seul √©chantillon)
    img_array = np.expand_dims(img_array, axis=0)
    
    # Pr√©traitement sp√©cifique √† MobileNetV2
    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)
    
    return img_array

# Application du pr√©traitement √† notre image
processed_image = preprocess_image('test_image.jpg')
print("Forme de l'image pr√©trait√©e:", processed_image.shape)
```

#### √âtape 4: Pr√©diction et interpr√©tation des r√©sultats (10 min)

1. Cr√©ez une nouvelle cellule et ex√©cutez le code suivant:

```python
# Utilisation du mod√®le pour faire une pr√©diction
predictions = model.predict(processed_image)

# D√©codage des pr√©dictions (conversion des indices en labels)
from tensorflow.keras.applications.mobilenet_v2 import decode_predictions
decoded_predictions = decode_predictions(predictions, top=5)[0]

# Affichage des r√©sultats sous forme de graphique
plt.figure(figsize=(10, 3))
labels = [pred[1].replace('_', ' ') for pred in decoded_predictions]
scores = [pred[2] for pred in decoded_predictions]

plt.barh(labels, scores)
plt.xlabel('Probabilit√©')
plt.title('Top 5 des pr√©dictions')
plt.xlim(0, 1.0)
plt.gca().invert_yaxis()  # Pour que le plus probable soit en haut
plt.tight_layout()
plt.show()

# Affichage des r√©sultats d√©taill√©s
print("Pr√©dictions:")
for i, (imagenet_id, label, score) in enumerate(decoded_predictions):
    print(f"{i+1}. {label} ({score:.2f})")
```

2. Analysez les r√©sultats:
   - Les pr√©dictions indiquent-elles correctement qu'il s'agit d'un chien de race carlin (pug)?
   - Observez les probabilit√©s associ√©es √† chaque classe
   - Quelles autres races de chiens sont d√©tect√©es?

## Mini-projet : Application interactive de reconnaissance d'images (45 min)

### Objectif

Cr√©er une application interactive simple qui permet de tester la reconnaissance d'images sur diff√©rentes photos.

### Instructions pas √† pas

#### √âtape 1: Cr√©ation d'une interface interactive dans Colab (10 min)

1. Cr√©ez une nouvelle cellule et ex√©cutez le code suivant:

```python
# Installation des widgets interactifs
!pip install -q ipywidgets
import ipywidgets as widgets
from IPython.display import display, HTML, clear_output
```

2. Dans une nouvelle cellule, cr√©ez l'interface utilisateur:

```python
# Fonction pour classifier une image t√©l√©charg√©e
def classify_uploaded_image(change):
    # Effacer les sorties pr√©c√©dentes
    clear_output(wait=True)
    
    # Afficher l'interface
    display(file_upload)
    display(output)
    
    # R√©cup√©rer le fichier t√©l√©charg√©
    uploaded_file = list(change['new'].values())[0]
    content = uploaded_file['content']
    
    # Sauvegarder l'image localement
    with open('uploaded_image.jpg', 'wb') as f:
        f.write(content)
    
    # Pr√©traiter l'image
    img = image.load_img('uploaded_image.jpg', target_size=(224, 224))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)
    
    # Afficher l'image originale
    plt.figure(figsize=(10, 6))
    plt.subplot(1, 2, 1)
    plt.imshow(image.load_img('uploaded_image.jpg'))
    plt.title("Image t√©l√©charg√©e")
    plt.axis('off')
    
    # Faire la pr√©diction
    predictions = model.predict(img_array)
    decoded_preds = decode_predictions(predictions, top=5)[0]
    
    # Afficher les r√©sultats sous forme de graphique
    plt.subplot(1, 2, 2)
    labels = [pred[1].replace('_', ' ') for pred in decoded_preds]
    scores = [pred[2] for pred in decoded_preds]
    
    plt.barh(labels, scores)
    plt.xlabel('Probabilit√©')
    plt.title('Top 5 des pr√©dictions')
    plt.xlim(0, 1.0)
    plt.gca().invert_yaxis()
    plt.tight_layout()
    plt.show()
    
    # Afficher les r√©sultats textuels
    print("Pr√©dictions:")
    for i, (imagenet_id, label, score) in enumerate(decoded_preds):
        print(f"{i+1}. {label.replace('_', ' ')} ({score:.2f})")

# Cr√©er les widgets
file_upload = widgets.FileUpload(
    accept='.jpg, .jpeg, .png',
    multiple=False,
    description='T√©l√©charger une image:'
)
output = widgets.Output()

# Lier la fonction au widget
file_upload.observe(classify_uploaded_image, names='value')

# Afficher l'interface
display(HTML("<h3>Application de reconnaissance d'images</h3>"))
display(HTML("<p>T√©l√©chargez une image pour voir ce que le mod√®le peut reconna√Ætre:</p>"))
display(file_upload)
display(output)
```

#### √âtape 2: D√©monstration avec des exemples vari√©s (15 min)

1. Cr√©ez une nouvelle cellule pour t√©l√©charger diff√©rentes images de test:

```python
# T√©l√©chargement d'images vari√©es pour nos tests
!wget -q -O cat.jpg https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/1200px-Cat03.jpg
!wget -q -O car.jpg https://upload.wikimedia.org/wikipedia/commons/thumb/2/2e/2022_Tesla_Model_Y.jpg/1200px-2022_Tesla_Model_Y.jpg
!wget -q -O laptop.jpg https://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/15-inch_MacBook_Pro_with_Touch_Bar_July_2018.jpg/1200px-15-inch_MacBook_Pro_with_Touch_Bar_July_2018.jpg

# Fonction pour classifier les images d'exemple
def classify_example_images():
    example_images = ['cat.jpg', 'car.jpg', 'laptop.jpg']
    
    for img_path in example_images:
        # Pr√©traiter l'image
        img = image.load_img(img_path, target_size=(224, 224))
        img_array = image.img_to_array(img)
        img_array = np.expand_dims(img_array, axis=0)
        img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)
        
        # Afficher l'image originale
        plt.figure(figsize=(10, 4))
        plt.subplot(1, 2, 1)
        plt.imshow(image.load_img(img_path))
        plt.title(f"Image: {img_path}")
        plt.axis('off')
        
        # Faire la pr√©diction
        predictions = model.predict(img_array)
        decoded_preds = decode_predictions(predictions, top=5)[0]
        
        # Afficher les r√©sultats sous forme de graphique
        plt.subplot(1, 2, 2)
        labels = [pred[1].replace('_', ' ') for pred in decoded_preds]
        scores = [pred[2] for pred in decoded_preds]
        
        plt.barh(labels, scores)
        plt.xlabel('Probabilit√©')
        plt.title('Top 5 des pr√©dictions')
        plt.xlim(0, 1.0)
        plt.gca().invert_yaxis()
        plt.tight_layout()
        plt.show()
        
        # Afficher les r√©sultats textuels
        print(f"Pr√©dictions pour {img_path}:")
        for i, (imagenet_id, label, score) in enumerate(decoded_preds):
            print(f"{i+1}. {label.replace('_', ' ')} ({score:.2f})")
        print("\n" + "-"*50 + "\n")

# Ex√©cuter la fonction
classify_example_images()
```

#### √âtape 3: Cr√©ation d'un outil d'analyse approfondie (20 min)

1. Cr√©ez une nouvelle cellule pour impl√©menter un outil qui montre les activations internes du r√©seau:

```python
def visualize_activations(img_path):
    """Visualise les activations interm√©diaires du mod√®le pour mieux comprendre la reconnaissance"""
    # Charger et pr√©traiter l'image
    img = image.load_img(img_path, target_size=(224, 224))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)
    
    # Cr√©er un mod√®le pour extraire les activations interm√©diaires
    layer_outputs = [layer.output for layer in model.layers if 'block' in layer.name][:3]  # Seulement les 3 premi√®res couches de bloc
    activation_model = tf.keras.Model(inputs=model.input, outputs=layer_outputs)
    
    # Obtenir les activations
    activations = activation_model.predict(img_array)
    
    # Afficher l'image originale
    plt.figure(figsize=(15, 10))
    plt.subplot(1, 4, 1)
    plt.title("Image originale")
    plt.imshow(image.load_img(img_path))
    plt.axis('off')
    
    # Afficher quelques activations pour chaque couche
    for i, layer_activation in enumerate(activations):
        # Seulement 9 filtres par couche
        n_features = min(9, layer_activation.shape[-1])
        layer_name = f"Couche {i+1}"
        
        plt.subplot(1, 4, i+2)
        plt.title(layer_name)
        
        # Cr√©er une grille pour les visualisations
        n_cols = 3
        n_rows = n_features // n_cols + (1 if n_features % n_cols > 0 else 0)
        display_grid = np.zeros((n_rows * 64, n_cols * 64))
        
        # Remplir la grille avec des images
        for row in range(n_rows):
            for col in range(n_cols):
                channel_idx = row * n_cols + col
                if channel_idx < n_features:
                    # Prendre une activit√© moyenne sur la dimension du batch
                    channel_image = layer_activation[0, :, :, channel_idx]
                    
                    # Normaliser pour une meilleure visualisation
                    channel_image -= channel_image.mean()
                    if channel_image.std() > 0:
                        channel_image /= channel_image.std()
                    channel_image *= 64
                    channel_image += 128
                    channel_image = np.clip(channel_image, 0, 255).astype('uint8')
                    
                    # Ajouter √† la grille
                    display_grid[row*64:(row+1)*64, col*64:(col+1)*64] = channel_image
        
        plt.imshow(display_grid, aspect='auto', cmap='viridis')
        plt.axis('off')
    
    plt.tight_layout()
    plt.show()
    
    # Faire et afficher la pr√©diction
    predictions = model.predict(img_array)
    decoded_preds = decode_predictions(predictions, top=5)[0]
    
    print(f"Pr√©dictions pour {img_path}:")
    for i, (imagenet_id, label, score) in enumerate(decoded_preds):
        print(f"{i+1}. {label.replace('_', ' ')} ({score:.2f})")

# Tester l'outil sur plusieurs images
for img_path in ['cat.jpg', 'car.jpg', 'laptop.jpg']:
    print("-"*50)
    print(f"Analyse de {img_path}")
    print("-"*50)
    visualize_activations(img_path)
    print("\n")
```

## Bonnes pratiques pour les projets professionnels (15 min)

Pour conclure cette phase, passons en revue les bonnes pratiques essentielles pour d√©velopper des applications de Deep Learning en contexte professionnel:

### 1. Structure du code

- **Modularit√©**: S√©parez clairement les diff√©rentes fonctionnalit√©s (pr√©traitement, mod√®le, API)
- **Documentation**: Commentez votre code et cr√©ez une documentation utilisateur
- **Gestion d'erreurs**: Pr√©voyez des cas d'erreur et des messages adapt√©s
- **Logging**: Ajoutez des logs pour faciliter le d√©bogage

### 2. Performances

- **Batch processing**: Traitez les donn√©es par lots plut√¥t qu'individuellement
- **Mise en cache**: √âvitez de recharger le mod√®le √† chaque requ√™te
- **Pr√©calcul**: Pr√©calculez ce qui peut l'√™tre pour acc√©l√©rer les inf√©rences
- **Optimisation mat√©rielle**: Utilisez GPU/TPU quand disponible, CPU optimis√© sinon

### 3. S√©curit√©

- **Validation des entr√©es**: V√©rifiez toujours les donn√©es entrantes
- **Limitation de taille**: Fixez une taille maximale pour les fichiers
- **Rate limiting**: Limitez le nombre de requ√™tes par utilisateur
- **Sanitization**: Nettoyez les chemins de fichiers et autres entr√©es sensibles

### 4. D√©ploiement

- **Conteneurisation**: Utilisez Docker pour faciliter le d√©ploiement
- **CI/CD**: Automatisez les tests et le d√©ploiement
- **Monitoring**: Surveillez les performances et erreurs
- **Versioning**: Versionnez vos mod√®les et API

## Conclusion et transition

Cette phase vous a permis de d√©couvrir comment utiliser efficacement TensorFlow/Keras dans un contexte professionnel. Vous avez appris √†:

 - Utiliser un mod√®le pr√©-entra√Æn√© pour la reconnaissance d'images
 - Pr√©traiter des images pour l'inf√©rence
 - Cr√©er une interface interactive pour tester votre mod√®le
 - Visualiser et comprendre les activations internes du r√©seau

Ces comp√©tences sont directement applicables dans des projets professionnels. Dans la prochaine partie, nous allons nous concentrer sur l'am√©lioration des performances de nos mod√®les pour les rendre plus adapt√©s √† des environnements de production.

[Retour au Module 3](index.md){ .md-button }
[Continuer vers l'Int√©gration et optimisation](integration.md){ .md-button .md-button--primary }