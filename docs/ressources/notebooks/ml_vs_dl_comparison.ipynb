{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Copier dans un fichier notebook nommé ml-vs-dl-comparison.ipynb\n",
    "# Notebook de comparaison: Machine Learning classique vs Deep Learning\n",
    "# BTS SIO - Séance 1: Découverte des concepts\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuration pour reproductibilité\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"# Comparaison Machine Learning classique vs Deep Learning\")\n",
    "print(\"Ce notebook vous permet d'observer concrètement les différences entre ces deux approches.\")\n",
    "\n",
    "# Partie 1: Chargement des données MNIST\n",
    "print(\"\\n## 1. Chargement du dataset MNIST\")\n",
    "print(\"Chargement du jeu de données de chiffres manuscrits...\")\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print(f\"Forme des données d'entraînement: {x_train.shape}\")\n",
    "print(f\"Forme des données de test: {x_test.shape}\")\n",
    "print(f\"Nombre de classes: {len(np.unique(y_train))}\")\n",
    "\n",
    "# Afficher quelques exemples d'images\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(x_train[i], cmap='gray')\n",
    "    plt.title(f\"Chiffre: {y_train[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Partie 2: Machine Learning classique avec Random Forest\n",
    "print(\"\\n## 2. Approche Machine Learning classique (Random Forest)\")\n",
    "\n",
    "# Prétraitement pour Machine Learning classique\n",
    "print(\"\\n### 2.1 Prétraitement pour Machine Learning classique\")\n",
    "print(\"Pour le ML classique, nous devons transformer les images 2D en vecteurs 1D et réduire leur dimensionnalité.\")\n",
    "\n",
    "# Nous utiliserons un sous-ensemble pour l'efficacité\n",
    "n_samples = 10000\n",
    "x_train_subset = x_train[:n_samples]\n",
    "y_train_subset = y_train[:n_samples]\n",
    "\n",
    "# Aplatir les images 28x28 en vecteurs de 784 pixels\n",
    "X_train_flat = x_train_subset.reshape(n_samples, -1)\n",
    "X_test_flat = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "print(f\"Forme après aplatissement: {X_train_flat.shape}\")\n",
    "\n",
    "# Normalisation\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_flat)\n",
    "X_test_scaled = scaler.transform(X_test_flat)\n",
    "print(\"Données normalisées avec StandardScaler\")\n",
    "\n",
    "# Réduction de dimensionnalité avec PCA\n",
    "pca = PCA(n_components=50)  # Réduire à 50 dimensions\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "print(f\"Forme après PCA: {X_train_pca.shape}\")\n",
    "print(f\"Variance expliquée: {np.sum(pca.explained_variance_ratio_)*100:.2f}%\")\n",
    "\n",
    "# Entraînement du modèle Random Forest\n",
    "print(\"\\n### 2.2 Entraînement du modèle Random Forest\")\n",
    "\n",
    "start_time = time.time()\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_pca, y_train_subset)\n",
    "ml_training_time = time.time() - start_time\n",
    "\n",
    "print(f\"Temps d'entraînement: {ml_training_time:.2f} secondes\")\n",
    "\n",
    "# Prédictions et évaluation\n",
    "y_pred_rf = rf.predict(X_test_pca)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Précision du Random Forest: {accuracy_rf*100:.2f}%\")\n",
    "\n",
    "# Partie 3: Deep Learning avec CNN\n",
    "print(\"\\n## 3. Approche Deep Learning (CNN)\")\n",
    "\n",
    "# Prétraitement pour Deep Learning\n",
    "print(\"\\n### 3.1 Prétraitement pour Deep Learning\")\n",
    "print(\"Pour le Deep Learning, le prétraitement est plus simple, nous normalisons simplement les pixels.\")\n",
    "\n",
    "# Simplement normaliser les pixels entre 0 et 1\n",
    "X_train_dl = x_train_subset.reshape(n_samples, 28, 28, 1) / 255.0\n",
    "X_test_dl = x_test.reshape(x_test.shape[0], 28, 28, 1) / 255.0\n",
    "\n",
    "print(f\"Forme pour le CNN: {X_train_dl.shape}\")\n",
    "print(\"Données normalisées par simple division (pixels entre 0 et 1)\")\n",
    "\n",
    "# Création d'un modèle CNN simple\n",
    "print(\"\\n### 3.2 Création et entraînement d'un modèle CNN\")\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"Architecture du modèle CNN:\")\n",
    "model.summary()\n",
    "\n",
    "# Entraînement rapide (juste quelques époques pour la démonstration)\n",
    "start_time = time.time()\n",
    "history = model.fit(\n",
    "    X_train_dl, y_train_subset,\n",
    "    epochs=3,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "dl_training_time = time.time() - start_time\n",
    "\n",
    "# Évaluation\n",
    "loss, accuracy_dl = model.evaluate(X_test_dl, y_test, verbose=0)\n",
    "print(f\"\\nTemps d'entraînement: {dl_training_time:.2f} secondes\")\n",
    "print(f\"Précision du modèle CNN: {accuracy_dl*100:.2f}%\")\n",
    "\n",
    "# Partie 4: Test de généralisation\n",
    "print(\"\\n## 4. Test de généralisation (robustesse au bruit)\")\n",
    "\n",
    "# Créer des versions perturbées du jeu de test\n",
    "def add_noise(images, noise_level=0.3):\n",
    "    \"\"\"Ajoute du bruit gaussien aux images\"\"\"\n",
    "    noisy_images = images.copy()\n",
    "    \n",
    "    if len(images.shape) == 4:  # Pour le CNN (avec canal)\n",
    "        noise = np.random.normal(0, noise_level, images.shape)\n",
    "        noisy_images += noise\n",
    "        return np.clip(noisy_images, 0, 1)\n",
    "    else:  # Pour le ML classique (sans canal)\n",
    "        noise = np.random.normal(0, noise_level*255, images.shape)\n",
    "        noisy_images += noise\n",
    "        return np.clip(noisy_images, 0, 255)\n",
    "\n",
    "# Créer des images de test bruitées\n",
    "n_test_examples = 1000\n",
    "X_test_subset = X_test_pca[:n_test_examples]\n",
    "X_test_dl_subset = X_test_dl[:n_test_examples]\n",
    "y_test_subset = y_test[:n_test_examples]\n",
    "\n",
    "# Images bruitées pour ML classique\n",
    "X_test_flat_subset = X_test_flat[:n_test_examples]\n",
    "X_test_noisy_flat = add_noise(X_test_flat_subset.reshape(-1, 28, 28), 0.3).reshape(-1, 784)\n",
    "X_test_noisy_pca = pca.transform(scaler.transform(X_test_noisy_flat))\n",
    "\n",
    "# Images bruitées pour Deep Learning\n",
    "X_test_noisy_dl = add_noise(X_test_dl_subset, 0.3)\n",
    "\n",
    "# Évaluer les deux modèles sur les données bruitées\n",
    "y_pred_rf_noisy = rf.predict(X_test_noisy_pca)\n",
    "accuracy_rf_noisy = accuracy_score(y_test_subset, y_pred_rf_noisy)\n",
    "\n",
    "loss_noisy, accuracy_dl_noisy = model.evaluate(X_test_noisy_dl, y_test_subset, verbose=0)\n",
    "\n",
    "print(f\"Précision du Random Forest sur données normales: {accuracy_rf*100:.2f}%\")\n",
    "print(f\"Précision du Random Forest sur données bruitées: {accuracy_rf_noisy*100:.2f}%\")\n",
    "print(f\"Baisse de performance: {(accuracy_rf - accuracy_rf_noisy)*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nPrécision du CNN sur données normales: {accuracy_dl*100:.2f}%\")\n",
    "print(f\"Précision du CNN sur données bruitées: {accuracy_dl_noisy*100:.2f}%\")\n",
    "print(f\"Baisse de performance: {(accuracy_dl - accuracy_dl_noisy)*100:.2f}%\")\n",
    "\n",
    "# Visualiser quelques exemples\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(5):\n",
    "    # Image originale\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(X_test_dl_subset[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"Original: {y_test_subset[i]}\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Image bruitée\n",
    "    plt.subplot(2, 5, i+6)\n",
    "    plt.imshow(X_test_noisy_dl[i].reshape(28, 28), cmap='gray')\n",
    "    \n",
    "    # Prédictions des deux modèles\n",
    "    rf_pred = y_pred_rf_noisy[i]\n",
    "    dl_pred = np.argmax(model.predict(X_test_noisy_dl[i:i+1], verbose=0))\n",
    "    \n",
    "    color = 'green' if rf_pred == y_test_subset[i] and dl_pred == y_test_subset[i] else 'red'\n",
    "    plt.title(f\"RF: {rf_pred} | DL: {dl_pred}\", color=color)\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Partie 5: Comparaison visuelle des performances\n",
    "print(\"\\n## 5. Comparaison des approches\")\n",
    "\n",
    "# Tableau récapitulatif\n",
    "comparison_data = {\n",
    "    'Aspect': ['Prétraitement', 'Extraction de caractéristiques', 'Temps d\\'entraînement (s)', \n",
    "               'Précision standard (%)', 'Précision avec bruit (%)', 'Baisse de performance (%)'],\n",
    "    'Machine Learning (Random Forest)': [\n",
    "        'Complexe (aplatissement, normalisation, PCA)',\n",
    "        'Manuelle (PCA)',\n",
    "        f'{ml_training_time:.2f}',\n",
    "        f'{accuracy_rf*100:.2f}',\n",
    "        f'{accuracy_rf_noisy*100:.2f}',\n",
    "        f'{(accuracy_rf - accuracy_rf_noisy)*100:.2f}'\n",
    "    ],\n",
    "    'Deep Learning (CNN)': [\n",
    "        'Simple (normalisation)',\n",
    "        'Automatique (couches de convolution)',\n",
    "        f'{dl_training_time:.2f}',\n",
    "        f'{accuracy_dl*100:.2f}',\n",
    "        f'{accuracy_dl_noisy*100:.2f}',\n",
    "        f'{(accuracy_dl - accuracy_dl_noisy)*100:.2f}'\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualisation graphique des performances\n",
    "metrics = ['Temps d\\'entraînement (s)', 'Précision standard (%)', 'Précision avec bruit (%)']\n",
    "ml_values = [ml_training_time, accuracy_rf*100, accuracy_rf_noisy*100]\n",
    "dl_values = [dl_training_time, accuracy_dl*100, accuracy_dl_noisy*100]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, ml_values, width, label='Machine Learning (RF)')\n",
    "plt.bar(x + width/2, dl_values, width, label='Deep Learning (CNN)')\n",
    "\n",
    "plt.ylabel('Valeurs')\n",
    "plt.title('Comparaison ML vs DL')\n",
    "plt.xticks(x, metrics)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Partie 6: Analyse des erreurs avec matrices de confusion\n",
    "print(\"\\n## 6. Analyse des erreurs de classification\")\n",
    "\n",
    "# Matrices de confusion\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "cm_rf = confusion_matrix(y_test_subset, y_pred_rf_noisy)\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matrice de confusion - Random Forest')\n",
    "plt.xlabel('Prédit')\n",
    "plt.ylabel('Réel')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "y_pred_dl = np.argmax(model.predict(X_test_noisy_dl, verbose=0), axis=1)\n",
    "cm_dl = confusion_matrix(y_test_subset, y_pred_dl)\n",
    "sns.heatmap(cm_dl, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matrice de confusion - CNN')\n",
    "plt.xlabel('Prédit')\n",
    "plt.ylabel('Réel')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Conclusion\n",
    "print(\"\\n## 7. Conclusion et observations clés\")\n",
    "print(\"\"\"\n",
    "Observations clés sur les différences entre Machine Learning classique et Deep Learning:\n",
    "\n",
    "1. **Prétraitement des données**:\n",
    "   - ML classique: Nécessite un prétraitement complexe (aplatissement, normalisation, réduction de dimension)\n",
    "   - Deep Learning: Prétraitement plus simple (normalisation basique)\n",
    "\n",
    "2. **Extraction de caractéristiques**:\n",
    "   - ML classique: Extraction manuelle de caractéristiques (ici via PCA)\n",
    "   - Deep Learning: Apprentissage automatique des caractéristiques via les couches de convolution\n",
    "\n",
    "3. **Performances**:\n",
    "   - Deep Learning: Généralement plus performant sur les données brutes à haute dimension\n",
    "   - ML classique: Peut être efficace après une bonne ingénierie de caractéristiques\n",
    "\n",
    "4. **Robustesse**:\n",
    "   - Deep Learning: Souvent plus robuste face aux perturbations et variations\n",
    "   - ML classique: Plus sensible aux modifications des entrées\n",
    "\n",
    "5. **Temps et ressources**:\n",
    "   - Deep Learning: Peut nécessiter plus de temps d'entraînement et de ressources\n",
    "   - ML classique: Généralement plus rapide à entraîner sur des datasets de taille modérée\n",
    "\n",
    "Ces observations vous aideront à choisir l'approche la plus adaptée selon le contexte de votre projet de développement.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n## Pour aller plus loin\")\n",
    "print(\"\"\"\n",
    "Suggestions pour approfondir votre compréhension:\n",
    "1. Testez d'autres types de perturbations (rotation, zoom, occlusion)\n",
    "2. Comparez différents algorithmes de ML classique (SVM, KNN, etc.)\n",
    "3. Expérimentez avec des architectures CNN plus complexes\n",
    "4. Essayez ces approches sur d'autres types de données (texte, séries temporelles)\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
