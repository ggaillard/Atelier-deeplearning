{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "  \"cells\": [\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"# CNN pour la classification d'images - MNIST\\n\",\n",
    "        \"\\n\",\n",
    "        \"## BTS SIO SLAM - S√©ance 2: Types de r√©seaux de neurones\\n\",\n",
    "        \"\\n\",\n",
    "        \"Ce notebook vous guidera √† travers l'impl√©mentation et l'utilisation d'un r√©seau de neurones convolutif (CNN) pour la classification d'images, en utilisant le c√©l√®bre dataset MNIST des chiffres manuscrits.\\n\",\n",
    "        \"\\n\",\n",
    "        \"### Objectifs d'apprentissage:\\n\",\n",
    "        \"- Comprendre l'architecture et le principe des r√©seaux convolutifs (CNN)\\n\",\n",
    "        \"- Impl√©menter un CNN avec TensorFlow/Keras pour la reconnaissance d'images\\n\",\n",
    "        \"- Visualiser et interpr√©ter les filtres et feature maps\\n\",\n",
    "        \"- Analyser les performances du mod√®le et les cas d'erreur\\n\",\n",
    "        \"- Explorer l'int√©gration d'un mod√®le CNN dans une application web\\n\",\n",
    "        \"\\n\",\n",
    "        \"### Pr√©requis:\\n\",\n",
    "        \"- Connaissances de base en Python\\n\",\n",
    "        \"- Notions fondamentales de r√©seaux de neurones\\n\",\n",
    "        \"- Avoir suivi la s√©ance 1 d'introduction au Deep Learning\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 1. Configuration de l'environnement\\n\",\n",
    "        \"\\n\",\n",
    "        \"Commen√ßons par importer les biblioth√®ques n√©cessaires et configurer notre environnement.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"import numpy as np\\n\",\n",
    "        \"import matplotlib.pyplot as plt\\n\",\n",
    "        \"import tensorflow as tf\\n\",\n",
    "        \"from tensorflow.keras.models import Sequential\\n\",\n",
    "        \"from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\\n\",\n",
    "        \"from tensorflow.keras.utils import to_categorical\\n\",\n",
    "        \"from tensorflow.keras.datasets import mnist\\n\",\n",
    "        \"import time\\n\",\n",
    "        \"import seaborn as sns\\n\",\n",
    "        \"from sklearn.metrics import confusion_matrix\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Configuration pour reproductibilit√©\\n\",\n",
    "        \"np.random.seed(42)\\n\",\n",
    "        \"tf.random.set_seed(42)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# V√©rifier la version de TensorFlow\\n\",\n",
    "        \"print(f\\\"TensorFlow version: {tf.__version__}\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 2. Chargement et pr√©paration du dataset MNIST\\n\",\n",
    "        \"\\n\",\n",
    "        \"Le dataset MNIST contient 70,000 images de chiffres manuscrits de taille 28x28 pixels. Il est divis√© en 60,000 images d'entra√Ænement et 10,000 images de test.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"print(\\\"Chargement des donn√©es MNIST...\\\")\\n\",\n",
    "        \"(X_train, y_train), (X_test, y_test) = mnist.load_data()\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Afficher les dimensions des donn√©es\\n\",\n",
    "        \"print(f\\\"Dimensions de X_train: {X_train.shape}\\\")\\n\",\n",
    "        \"print(f\\\"Dimensions de y_train: {y_train.shape}\\\")\\n\",\n",
    "        \"print(f\\\"Dimensions de X_test: {X_test.shape}\\\")\\n\",\n",
    "        \"print(f\\\"Dimensions de y_test: {y_test.shape}\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Afficher les premi√®res valeurs de y_train\\n\",\n",
    "        \"print(f\\\"Classes dans y_train: {y_train[:20]}\\\")\\n\",\n",
    "        \"print(f\\\"Nombre de classes: {len(np.unique(y_train))}\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Pr√©paration des donn√©es pour le CNN\\n\",\n",
    "        \"\\n\",\n",
    "        \"Pour utiliser nos images avec un CNN, nous devons :\\n\",\n",
    "        \"1. Ajouter une dimension pour le canal (les images sont en niveaux de gris, donc 1 seul canal)\\n\",\n",
    "        \"2. Normaliser les valeurs de pixels entre 0 et 1\\n\",\n",
    "        \"3. Convertir les √©tiquettes en format one-hot encoding (pas toujours n√©cessaire, mais souvent utile)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Redimensionnement et normalisation\\n\",\n",
    "        \"X_train = X_train.reshape(-1, 28, 28, 1) / 255.0\\n\",\n",
    "        \"X_test = X_test.reshape(-1, 28, 28, 1) / 255.0\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Conversion des √©tiquettes en cat√©gories one-hot\\n\",\n",
    "        \"y_train_onehot = to_categorical(y_train, 10)\\n\",\n",
    "        \"y_test_onehot = to_categorical(y_test, 10)\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(f\\\"Nouvelle forme de X_train: {X_train.shape}\\\")\\n\",\n",
    "        \"print(f\\\"Nouvelle forme de y_train_onehot: {y_train_onehot.shape}\\\")\\n\",\n",
    "        \"print(f\\\"Exemple de label encod√© en one-hot: {y_train_onehot[0]} repr√©sente le chiffre {y_train[0]}\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Visualisation de quelques exemples\\n\",\n",
    "        \"\\n\",\n",
    "        \"Regardons √† quoi ressemblent nos donn√©es.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"plt.figure(figsize=(10, 5))\\n\",\n",
    "        \"for i in range(10):\\n\",\n",
    "        \"    plt.subplot(2, 5, i+1)\\n\",\n",
    "        \"    plt.imshow(X_train[i].reshape(28, 28), cmap='gray')\\n\",\n",
    "        \"    plt.title(f\\\"Chiffre: {y_train[i]}\\\")\\n\",\n",
    "        \"    plt.axis('off')\\n\",\n",
    "        \"plt.tight_layout()\\n\",\n",
    "        \"plt.show()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 3. Cr√©ation d'un mod√®le CNN\\n\",\n",
    "        \"\\n\",\n",
    "        \"Nous allons maintenant cr√©er un r√©seau de neurones convolutif. Les CNN sont particuli√®rement adapt√©s au traitement d'images gr√¢ce √† leur capacit√© √† apprendre des caract√©ristiques spatiales hi√©rarchiques.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"def create_cnn_model():\\n\",\n",
    "        \"    model = Sequential([\\n\",\n",
    "        \"        # Premi√®re couche de convolution\\n\",\n",
    "        \"        Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1), name='conv1'),\\n\",\n",
    "        \"        MaxPooling2D((2, 2), name='pool1'),\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Deuxi√®me couche de convolution\\n\",\n",
    "        \"        Conv2D(64, (3, 3), activation='relu', name='conv2'),\\n\",\n",
    "        \"        MaxPooling2D((2, 2), name='pool2'),\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Aplatissement pour passer aux couches denses\\n\",\n",
    "        \"        Flatten(name='flatten'),\\n\",\n",
    "        \"        \\n\",\n",
    "        \"        # Couches denses (fully connected)\\n\",\n",
    "        \"        Dense(128, activation='relu', name='dense1'),\\n\",\n",
    "        \"        Dropout(0.5, name='dropout1'),  # R√©gularisation\\n\",\n",
    "        \"        Dense(10, activation='softmax', name='output')  # 10 classes (chiffres 0-9)\\n\",\n",
    "        \"    ])\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Compilation du mod√®le\\n\",\n",
    "        \"    model.compile(\\n\",\n",
    "        \"        optimizer='adam',\\n\",\n",
    "        \"        loss='categorical_crossentropy',  # Pour les √©tiquettes one-hot\\n\",\n",
    "        \"        metrics=['accuracy']\\n\",\n",
    "        \"    )\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    return model\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Cr√©er le mod√®le\\n\",\n",
    "        \"model = create_cnn_model()\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Afficher le r√©sum√© de l'architecture\\n\",\n",
    "        \"model.summary()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Explication de l'architecture du CNN\\n\",\n",
    "        \"\\n\",\n",
    "        \"Notre architecture CNN comprend :\\n\",\n",
    "        \"\\n\",\n",
    "        \"1. **Couches de convolution (Conv2D)** :\\n\",\n",
    "        \"   - Appliquent des filtres qui glissent sur l'image pour d√©tecter des caract√©ristiques (bords, textures, formes)\\n\",\n",
    "        \"   - Premi√®res couches : caract√©ristiques simples (lignes, bords)\\n\",\n",
    "        \"   - Couches profondes : caract√©ristiques complexes (formes, parties de chiffres)\\n\",\n",
    "        \"\\n\",\n",
    "        \"2. **Couches de pooling (MaxPooling2D)** :\\n\",\n",
    "        \"   - R√©duisent la dimension spatiale (downsampling)\\n\",\n",
    "        \"   - Rendent le mod√®le plus robuste aux variations de position\\n\",\n",
    "        \"   - Diminuent le nombre de param√®tres\\n\",\n",
    "        \"\\n\",\n",
    "        \"3. **Flatten** :\\n\",\n",
    "        \"   - Convertit les feature maps 2D en un vecteur 1D\\n\",\n",
    "        \"   - N√©cessaire pour passer aux couches denses\\n\",\n",
    "        \"\\n\",\n",
    "        \"4. **Couches denses (Dense)** :\\n\",\n",
    "        \"   - Combinent toutes les caract√©ristiques extraites\\n\",\n",
    "        \"   - Effectuent la classification finale\\n\",\n",
    "        \"\\n\",\n",
    "        \"5. **Dropout** :\\n\",\n",
    "        \"   - Technique de r√©gularisation\\n\",\n",
    "        \"   - D√©sactive al√©atoirement 50% des neurones pendant l'entra√Ænement\\n\",\n",
    "        \"   - Pr√©vient le surapprentissage\\n\",\n",
    "        \"\\n\",\n",
    "        \"Cette architecture est similaire au c√©l√®bre LeNet-5, mais avec plus de filtres et l'ajout de Dropout.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 4. Entra√Ænement du mod√®le\\n\",\n",
    "        \"\\n\",\n",
    "        \"Entra√Ænons maintenant notre mod√®le CNN sur les donn√©es MNIST.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Mesure du temps d'entra√Ænement\\n\",\n",
    "        \"start_time = time.time()\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Entra√Ænement du mod√®le\\n\",\n",
    "        \"history = model.fit(\\n\",\n",
    "        \"    X_train, \\n\",\n",
    "        \"    y_train_onehot, \\n\",\n",
    "        \"    batch_size=128, \\n\",\n",
    "        \"    epochs=5,  # Nombre r√©duit d'√©poques pour la d√©monstration\\n\",\n",
    "        \"    validation_split=0.2,  # 20% des donn√©es d'entra√Ænement pour la validation\\n\",\n",
    "        \"    verbose=1\\n\",\n",
    "        \")\\n\",\n",
    "        \"\\n\",\n",
    "        \"training_time = time.time() - start_time\\n\",\n",
    "        \"print(f\\\"\\\\nTemps d'entra√Ænement: {training_time:.2f} secondes\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Visualisation de l'√©volution de l'entra√Ænement\\n\",\n",
    "        \"\\n\",\n",
    "        \"Observons comment la pr√©cision et la perte ont √©volu√© au cours de l'entra√Ænement.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"plt.figure(figsize=(12, 4))\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Graphique de pr√©cision\\n\",\n",
    "        \"plt.subplot(1, 2, 1)\\n\",\n",
    "        \"plt.plot(history.history['accuracy'], label='Entra√Ænement')\\n\",\n",
    "        \"plt.plot(history.history['val_accuracy'], label='Validation')\\n\",\n",
    "        \"plt.title('√âvolution de la pr√©cision')\\n\",\n",
    "        \"plt.xlabel('√âpoque')\\n\",\n",
    "        \"plt.ylabel('Pr√©cision')\\n\",\n",
    "        \"plt.legend()\\n\",\n",
    "        \"plt.grid(True, linestyle='--', alpha=0.6)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Graphique de perte\\n\",\n",
    "        \"plt.subplot(1, 2, 2)\\n\",\n",
    "        \"plt.plot(history.history['loss'], label='Entra√Ænement')\\n\",\n",
    "        \"plt.plot(history.history['val_loss'], label='Validation')\\n\",\n",
    "        \"plt.title('√âvolution de la perte')\\n\",\n",
    "        \"plt.xlabel('√âpoque')\\n\",\n",
    "        \"plt.ylabel('Perte')\\n\",\n",
    "        \"plt.legend()\\n\",\n",
    "        \"plt.grid(True, linestyle='--', alpha=0.6)\\n\",\n",
    "        \"\\n\",\n",
    "        \"plt.tight_layout()\\n\",\n",
    "        \"plt.show()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 5. √âvaluation du mod√®le\\n\",\n",
    "        \"\\n\",\n",
    "        \"√âvaluons maintenant notre mod√®le sur l'ensemble de test.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# √âvaluation sur l'ensemble de test\\n\",\n",
    "        \"test_loss, test_acc = model.evaluate(X_test, y_test_onehot, verbose=1)\\n\",\n",
    "        \"print(f\\\"Pr√©cision sur l'ensemble de test: {test_acc*100:.2f}%\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Pr√©dictions\\n\",\n",
    "        \"y_pred = model.predict(X_test)\\n\",\n",
    "        \"y_pred_classes = np.argmax(y_pred, axis=1)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Matrice de confusion\\n\",\n",
    "        \"conf_mat = confusion_matrix(y_test, y_pred_classes)\\n\",\n",
    "        \"plt.figure(figsize=(10, 8))\\n\",\n",
    "        \"sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\\n\",\n",
    "        \"plt.xlabel('Pr√©dit')\\n\",\n",
    "        \"plt.ylabel('R√©el')\\n\",\n",
    "        \"plt.title('Matrice de confusion')\\n\",\n",
    "        \"plt.show()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Visualisation des exemples mal classifi√©s\\n\",\n",
    "        \"\\n\",\n",
    "        \"Explorons quelques exemples que notre mod√®le a mal classifi√©s pour comprendre ses faiblesses.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Identifier les erreurs\\n\",\n",
    "        \"misclassified_indices = np.where(y_pred_classes != y_test)[0]\\n\",\n",
    "        \"misclassified_count = len(misclassified_indices)\\n\",\n",
    "        \"print(f\\\"Nombre total d'erreurs: {misclassified_count} sur {len(y_test)} images de test\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Afficher quelques exemples mal classifi√©s\\n\",\n",
    "        \"num_examples = min(10, misclassified_count)\\n\",\n",
    "        \"plt.figure(figsize=(15, 6))\\n\",\n",
    "        \"\\n\",\n",
    "        \"for i, idx in enumerate(misclassified_indices[:num_examples]):\\n\",\n",
    "        \"    plt.subplot(2, 5, i+1)\\n\",\n",
    "        \"    plt.imshow(X_test[idx].reshape(28, 28), cmap='gray')\\n\",\n",
    "        \"    plt.title(f\\\"R√©el: {y_test[idx]}\\\\nPr√©dit: {y_pred_classes[idx]}\\\")\\n\",\n",
    "        \"    plt.axis('off')\\n\",\n",
    "        \"    \\n\",\n",
    "        \"plt.tight_layout()\\n\",\n",
    "        \"plt.show()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### üß† R√©flexion sur les erreurs\\n\",\n",
    "        \"\\n\",\n",
    "        \"**Question**: En observant les exemples mal classifi√©s, quelles pourraient √™tre les raisons de ces erreurs? Notez vos observations et hypoth√®ses ci-dessous.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"*√âcrivez vos observations ici...*\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 6. Visualisation des filtres et feature maps\\n\",\n",
    "        \"\\n\",\n",
    "        \"Une des grandes forces des CNNs est leur interpr√©tabilit√© visuelle. Explorons ce que le r√©seau \\\"voit\\\" r√©ellement.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Fonction pour visualiser les filtres de convolution\\n\",\n",
    "        \"def visualize_filters(model, layer_name, num_filters=8):\\n\",\n",
    "        \"    \\\"\\\"\\\"Visualise les filtres d'une couche de convolution\\\"\\\"\\\"\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # R√©cup√©rer les poids du filtre de la couche sp√©cifi√©e\\n\",\n",
    "        \"    filters, biases = model.get_layer(layer_name).get_weights()\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Normaliser les filtres pour une meilleure visualisation\\n\",\n",
    "        \"    f_min, f_max = filters.min(), filters.max()\\n\",\n",
    "        \"    filters = (filters - f_min) / (f_max - f_min)\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Afficher les premiers filtres\\n\",\n",
    "        \"    plt.figure(figsize=(12, 4))\\n\",\n",
    "        \"    for i in range(num_filters):\\n\",\n",
    "        \"        plt.subplot(2, 4, i+1)\\n\",\n",
    "        \"        # Pour la premi√®re couche de convolution, les filtres sont 3D (hauteur, largeur, canaux)\\n\",\n",
    "        \"        # Nous affichons le filtre pour le premier canal (0)\\n\",\n",
    "        \"        plt.imshow(filters[:, :, 0, i], cmap='viridis')\\n\",\n",
    "        \"        plt.title(f'Filtre {i+1}')\\n\",\n",
    "        \"        plt.axis('off')\\n\",\n",
    "        \"    plt.suptitle(f'Filtres de la couche {layer_name}')\\n\",\n",
    "        \"    plt.tight_layout()\\n\",\n",
    "        \"    plt.show()\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Visualiser les filtres de la premi√®re couche de convolution\\n\",\n",
    "        \"visualize_filters(model, 'conv1')\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### Visualisation des feature maps (cartes d'activation)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"def visualize_feature_maps(model, image, layer_name, num_features=8):\\n\",\n",
    "        \"    \\\"\\\"\\\"Visualise les feature maps (activations) d'une couche pour une image donn√©e\\\"\\\"\\\"\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Cr√©er un mod√®le qui renvoie les activations de la couche sp√©cifi√©e\\n\",\n",
    "        \"    layer_model = tf.keras.Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Obtenir les activations pour une image\\n\",\n",
    "        \"    feature_maps = layer_model.predict(image.reshape(1, 28, 28, 1))\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Afficher les premi√®res cartes d'activation\\n\",\n",
    "        \"    plt.figure(figsize=(12, 4))\\n\",\n",
    "        \"    for i in range(min(num_features, feature_maps.shape[3])):\\n\",\n",
    "        \"        plt.subplot(2, 4, i+1)\\n\",\n",
    "        \"        plt.imshow(feature_maps[0, :, :, i], cmap='viridis')\\n\",\n",
    "        \"        plt.title(f'Feature {i+1}')\\n\",\n",
    "        \"        plt.axis('off')\\n\",\n",
    "        \"    plt.suptitle(f'Feature Maps de la couche {layer_name}')\\n\",\n",
    "        \"    plt.tight_layout()\\n\",\n",
    "        \"    plt.show()\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Choisir une image de test\\n\",\n",
    "        \"sample_idx = 12  # Vous pouvez essayer avec diff√©rents indices\\n\",\n",
    "        \"sample_image = X_test[sample_idx]\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Afficher l'image originale\\n\",\n",
    "        \"plt.figure(figsize=(3, 3))\\n\",\n",
    "        \"plt.imshow(sample_image.reshape(28, 28), cmap='gray')\\n\",\n",
    "        \"plt.title(f\\\"Chiffre: {y_test[sample_idx]}\\\")\\n\",\n",
    "        \"plt.axis('off')\\n\",\n",
    "        \"plt.show()\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Visualiser les feature maps pour chaque couche de convolution\\n\",\n",
    "        \"print(\\\"Feature maps de la premi√®re couche de convolution:\\\")\\n\",\n",
    "        \"visualize_feature_maps(model, sample_image, 'conv1')\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"Feature maps de la deuxi√®me couche de convolution:\\\")\\n\",\n",
    "        \"visualize_feature_maps(model, sample_image, 'conv2')\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"### üí° Interpr√©tation des feature maps\\n\",\n",
    "        \"\\n\",\n",
    "        \"Les feature maps nous montrent ce que \\\"voit\\\" chaque filtre de convolution :\\n\",\n",
    "        \"\\n\",\n",
    "        \"- **Premi√®re couche** : D√©tecte principalement des caract√©ristiques de base comme les bords et les contours\\n\",\n",
    "        \"- **Deuxi√®me couche** : Combine ces caract√©ristiques de base pour d√©tecter des formes plus complexes\\n\",\n",
    "        \"\\n\",\n",
    "        \"Cette hi√©rarchie de repr√©sentations est ce qui rend les CNNs si puissants pour la vision par ordinateur.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 7. Test du mod√®le avec des images bruit√©es\\n\",\n",
    "        \"\\n\",\n",
    "        \"Testons la robustesse de notre mod√®le face √† des perturbations.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Fonction pour ajouter du bruit aux images\\n\",\n",
    "        \"def add_noise(images, noise_level=0.2):\\n\",\n",
    "        \"    \\\"\\\"\\\"Ajoute du bruit gaussien aux images\\\"\\\"\\\"\\n\",\n",
    "        \"    noisy_images = images.copy()\\n\",\n",
    "        \"    noise = np.random.normal(0, noise_level, images.shape)\\n\",\n",
    "        \"    noisy_images = noisy_images + noise\\n\",\n",
    "        \"    # Assurer que les valeurs restent entre 0 et 1\\n\",\n",
    "        \"    return np.clip(noisy_images, 0, 1)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Cr√©er des versions bruit√©es de quelques images de test\\n\",\n",
    "        \"num_test_images = 10\\n\",\n",
    "        \"test_samples = X_test[:num_test_images]\\n\",\n",
    "        \"noisy_samples = add_noise(test_samples, noise_level=0.3)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Visualiser les images originales et bruit√©es\\n\",\n",
    "        \"plt.figure(figsize=(15, 6))\\n\",\n",
    "        \"for i in range(num_test_images):\\n\",\n",
    "        \"    # Image originale\\n\",\n",
    "        \"    plt.subplot(2, num_test_images, i+1)\\n\",\n",
    "        \"    plt.imshow(test_samples[i].reshape(28, 28), cmap='gray')\\n\",\n",
    "        \"    plt.title(f\\\"Original: {y_test[i]}\\\")\\n\",\n",
    "        \"    plt.axis('off')\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Image bruit√©e\\n\",\n",
    "        \"    plt.subplot(2, num_test_images, i+num_test_images+1)\\n\",\n",
    "        \"    plt.imshow(noisy_samples[i].reshape(28, 28), cmap='gray')\\n\",\n",
    "        \"    plt.axis('off')\\n\",\n",
    "        \"    \\n\",\n",
    "        \"plt.tight_layout()\\n\",\n",
    "        \"plt.show()\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Pr√©dire sur les images bruit√©es\\n\",\n",
    "        \"noisy_predictions = model.predict(noisy_samples)\\n\",\n",
    "        \"noisy_pred_classes = np.argmax(noisy_predictions, axis=1)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Afficher les r√©sultats\\n\",\n",
    "        \"print(\\\"R√©sultats des pr√©dictions sur les images bruit√©es:\\\")\\n\",\n",
    "        \"for i in range(num_test_images):\\n\",\n",
    "        \"    confidence = noisy_predictions[i][noisy_pred_classes[i]] * 100\\n\",\n",
    "        \"    status = \\\"‚úì\\\" if noisy_pred_classes[i] == y_test[i] else \\\"‚úó\\\"\\n\",\n",
    "        \"    print(f\\\"Image {i+1} - R√©el: {y_test[i]}, Pr√©dit: {noisy_pred_classes[i]}, \\\"  \\n\",\n",
    "        \"          f\\\"Confiance: {confidence:.1f}% {status}\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Calculer la pr√©cision sur les images bruit√©es\\n\",\n",
    "        \"accuracy_on_noisy = np.mean(noisy_pred_classes == y_test[:num_test_images]) * 100\\n\",\n",
    "        \"print(f\\\"\\\\nPr√©cision sur les images bruit√©es: {accuracy_on_noisy:.1f}%\\\")\n",
    "\n",
    "# Comparaison avec la pr√©cision sur les donn√©es originales\n",
    "original_accuracy = np.mean(y_pred_classes[:num_test_images] == y_test[:num_test_images]) * 100\n",
    "print(f\\\"Pr√©cision sur les images originales (pour le m√™me sous-ensemble): {original_accuracy:.1f}%\\\")\n",
    "print(f\\\"Baisse de pr√©cision due au bruit: {original_accuracy - accuracy_on_noisy:.1f} points de pourcentage\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 8. Pr√©dictions d√©taill√©es sur de nouvelles images\\n\",\n",
    "        \"\\n\",\n",
    "        \"Voyons comment notre mod√®le pr√©dit des images sp√©cifiques et quelles sont les probabilit√©s pour chaque classe.\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"def predict_and_visualize_probabilities(model, image, true_label=None):\\n\",\n",
    "        \"    \\\"\\\"\\\"Pr√©dit et visualise les probabilit√©s pour chaque classe\\\"\\\"\\\"\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Pr√©diction\\n\",\n",
    "        \"    prediction = model.predict(image.reshape(1, 28, 28, 1))[0]\\n\",\n",
    "        \"    predicted_class = np.argmax(prediction)\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Visualisation\\n\",\n",
    "        \"    plt.figure(figsize=(12, 4))\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Afficher l'image\\n\",\n",
    "        \"    plt.subplot(1, 2, 1)\\n\",\n",
    "        \"    plt.imshow(image.reshape(28, 28), cmap='gray')\\n\",\n",
    "        \"    if true_label is not None:\\n\",\n",
    "        \"        title = f\\\"Image (Vrai: {true_label})\\\"\\n\",\n",
    "        \"    else:\\n\",\n",
    "        \"        title = \\\"Image\\\"\\n\",\n",
    "        \"    plt.title(title)\\n\",\n",
    "        \"    plt.axis('off')\\n\",\n",
    "        \"    \\n\",\n",
    "        \"    # Afficher les probabilit√©s\\n\",\n",
    "        \"    plt.subplot(1, 2, 2)\\n\",\n",
    "        \"    bars = plt.bar(range(10), prediction, color='skyblue')\\n\",\n",
    "        \"    \\n\",\n",
    "        \"\n",
    "\n",
    "      ## 9. Exportation et int√©gration du mod√®le dans une application web\n",
    "\n",
    "Dans cette section, nous allons voir comment exporter notre mod√®le CNN entra√Æn√© et l'int√©grer dans une application web simple.\n",
    "\n",
    "### Sauvegarde du mod√®le\n",
    "\n",
    "Commen√ßons par sauvegarder notre mod√®le entra√Æn√© pour pouvoir le r√©utiliser ult√©rieurement.\n",
    "\n",
    "```python\n",
    "# Sauvegarder le mod√®le complet (architecture + poids)\n",
    "model.save('mnist_cnn_model.h5')\n",
    "print(\"Mod√®le sauvegard√© avec succ√®s!\")\n",
    "\n",
    "# Sauvegarder uniquement les poids (si n√©cessaire)\n",
    "model.save_weights('mnist_cnn_weights.h5')\n",
    "print(\"Poids du mod√®le sauvegard√©s avec succ√®s!\")\n",
    "```\n",
    "\n",
    "### Conversion du mod√®le pour le web (TensorFlow.js)\n",
    "\n",
    "Pour int√©grer notre mod√®le dans une application web, nous pouvons utiliser TensorFlow.js. Il faut d'abord convertir notre mod√®le Keras en format TensorFlow.js.\n",
    "\n",
    "```python\n",
    "# Installer tensorflowjs (si pas d√©j√† install√©)\n",
    "!pip install tensorflowjs\n",
    "\n",
    "# Convertir le mod√®le pour TensorFlow.js\n",
    "import tensorflowjs as tfjs\n",
    "tfjs.converters.save_keras_model(model, 'tfjs_mnist_model')\n",
    "print(\"Mod√®le converti pour TensorFlow.js!\")\n",
    "```\n",
    "\n",
    "### Cr√©ation d'une application web simple\n",
    "\n",
    "Voici un exemple de code HTML et JavaScript pour cr√©er une application web simple permettant aux utilisateurs de dessiner un chiffre et d'obtenir une pr√©diction de notre mod√®le CNN.\n",
    "\n",
    "```html\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"fr\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Reconnaissance de chiffres manuscrits</title>\n",
    "    <script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0/dist/tf.min.js\"></script>\n",
    "    <style>\n",
    "        body {\n",
    "            font-family: Arial, sans-serif;\n",
    "            text-align: center;\n",
    "            margin: 20px;\n",
    "        }\n",
    "        #canvas-container {\n",
    "            display: flex;\n",
    "            justify-content: center;\n",
    "            margin: 20px 0;\n",
    "        }\n",
    "        canvas {\n",
    "            border: 2px solid #333;\n",
    "            cursor: crosshair;\n",
    "        }\n",
    "        button {\n",
    "            margin: 10px;\n",
    "            padding: 10px 20px;\n",
    "            font-size: 16px;\n",
    "            cursor: pointer;\n",
    "        }\n",
    "        #result {\n",
    "            font-size: 24px;\n",
    "            margin: 20px;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "        .confidence-bar {\n",
    "            height: 20px;\n",
    "            background-color: #4CAF50;\n",
    "            text-align: left;\n",
    "            margin: 5px 0;\n",
    "            color: white;\n",
    "            font-weight: bold;\n",
    "            padding-left: 5px;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Reconnaissance de chiffres manuscrits avec CNN</h1>\n",
    "    <p>Dessinez un chiffre (0-9) dans le cadre ci-dessous:</p>\n",
    "    \n",
    "    <div id=\"canvas-container\">\n",
    "        <canvas id=\"drawingCanvas\" width=\"280\" height=\"280\"></canvas>\n",
    "    </div>\n",
    "    \n",
    "    <div>\n",
    "        <button id=\"predictBtn\">Pr√©dire</button>\n",
    "        <button id=\"clearBtn\">Effacer</button>\n",
    "    </div>\n",
    "    \n",
    "    <div id=\"result\">R√©sultat: -</div>\n",
    "    \n",
    "    <div id=\"confidences\" style=\"width: 300px; margin: 0 auto;\"></div>\n",
    "    \n",
    "    <script>\n",
    "        // Configuration du canvas\n",
    "        const canvas = document.getElementById('drawingCanvas');\n",
    "        const ctx = canvas.getContext('2d');\n",
    "        ctx.lineWidth = 15;\n",
    "        ctx.lineCap = 'round';\n",
    "        ctx.strokeStyle = 'black';\n",
    "        ctx.fillStyle = 'white';\n",
    "        ctx.fillRect(0, 0, canvas.width, canvas.height);\n",
    "        \n",
    "        // Variables pour le dessin\n",
    "        let isDrawing = false;\n",
    "        let lastX = 0;\n",
    "        let lastY = 0;\n",
    "        \n",
    "        // Chargement du mod√®le\n",
    "        let model;\n",
    "        async function loadModel() {\n",
    "            model = await tf.loadLayersModel('tfjs_mnist_model/model.json');\n",
    "            console.log('Mod√®le charg√©!');\n",
    "        }\n",
    "        loadModel();\n",
    "        \n",
    "        // Fonctions de dessin\n",
    "        function startDrawing(e) {\n",
    "            isDrawing = true;\n",
    "            [lastX, lastY] = [e.offsetX, e.offsetY];\n",
    "        }\n",
    "        \n",
    "        function draw(e) {\n",
    "            if (!isDrawing) return;\n",
    "            ctx.beginPath();\n",
    "            ctx.moveTo(lastX, lastY);\n",
    "            ctx.lineTo(e.offsetX, e.offsetY);\n",
    "            ctx.stroke();\n",
    "            [lastX, lastY] = [e.offsetX, e.offsetY];\n",
    "        }\n",
    "        \n",
    "        function stopDrawing() {\n",
    "            isDrawing = false;\n",
    "        }\n",
    "        \n",
    "        // Event listeners pour le dessin\n",
    "        canvas.addEventListener('mousedown', startDrawing);\n",
    "        canvas.addEventListener('mousemove', draw);\n",
    "        canvas.addEventListener('mouseup', stopDrawing);\n",
    "        canvas.addEventListener('mouseout', stopDrawing);\n",
    "        \n",
    "        // Pr√©traitement de l'image\n",
    "        function preprocessCanvas() {\n",
    "            // Redimensionner √† 28x28 (taille attendue par le mod√®le)\n",
    "            const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);\n",
    "            const tempCanvas = document.createElement('canvas');\n",
    "            tempCanvas.width = 28;\n",
    "            tempCanvas.height = 28;\n",
    "            const tempCtx = tempCanvas.getContext('2d');\n",
    "            tempCtx.drawImage(canvas, 0, 0, canvas.width, canvas.height, 0, 0, 28, 28);\n",
    "            \n",
    "            // Convertir en niveaux de gris et normaliser (0-1)\n",
    "            const tempImageData = tempCtx.getImageData(0, 0, 28, 28);\n",
    "            const data = tempImageData.data;\n",
    "            const grayscale = new Float32Array(28 * 28);\n",
    "            \n",
    "            for (let i = 0; i < 28 * 28; i++) {\n",
    "                // Inverser les couleurs (fond blanc -> 0, trait noir -> 1)\n",
    "                grayscale[i] = (255 - data[i * 4]) / 255.0;\n",
    "            }\n",
    "            \n",
    "            // Cr√©er un tenseur au format attendu par le mod√®le\n",
    "            return tf.tensor(grayscale).reshape([1, 28, 28, 1]);\n",
    "        }\n",
    "        \n",
    "        // Pr√©diction\n",
    "        async function predict() {\n",
    "            if (!model) {\n",
    "                alert('Le mod√®le n\\'est pas encore charg√©. Veuillez patienter.');\n",
    "                return;\n",
    "            }\n",
    "            \n",
    "            // Pr√©traiter l'image\n",
    "            const input = preprocessCanvas();\n",
    "            \n",
    "            // Faire la pr√©diction\n",
    "            const predictions = await model.predict(input).data();\n",
    "            \n",
    "            // Trouver la classe avec la plus haute probabilit√©\n",
    "            let maxProb = 0;\n",
    "            let predictedClass = -1;\n",
    "            \n",
    "            for (let i = 0; i < predictions.length; i++) {\n",
    "                if (predictions[i] > maxProb) {\n",
    "                    maxProb = predictions[i];\n",
    "                    predictedClass = i;\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            // Afficher le r√©sultat\n",
    "            document.getElementById('result').textContent = `R√©sultat: ${predictedClass} (${(maxProb * 100).toFixed(2)}%)`;\n",
    "            \n",
    "            // Afficher les probabilit√©s pour chaque classe\n",
    "            const confidencesDiv = document.getElementById('confidences');\n",
    "            confidencesDiv.innerHTML = '';\n",
    "            \n",
    "            for (let i = 0; i < predictions.length; i++) {\n",
    "                const prob = predictions[i] * 100;\n",
    "                const barDiv = document.createElement('div');\n",
    "                barDiv.className = 'confidence-bar';\n",
    "                barDiv.style.width = `${prob}%`;\n",
    "                barDiv.textContent = i + ': ' + prob.toFixed(1) + '%';\n",
    "                confidencesDiv.appendChild(barDiv);\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        // Effacer le canvas\n",
    "        function clearCanvas() {\n",
    "            ctx.fillStyle = 'white';\n",
    "            ctx.fillRect(0, 0, canvas.width, canvas.height);\n",
    "            document.getElementById('result').textContent = 'R√©sultat: -';\n",
    "            document.getElementById('confidences').innerHTML = '';\n",
    "        }\n",
    "        \n",
    "        // Event listeners pour les boutons\n",
    "        document.getElementById('predictBtn').addEventListener('click', predict);\n",
    "        document.getElementById('clearBtn').addEventListener('click', clearCanvas);\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "```\n",
    "\n",
    "### D√©ploiement de l'application\n",
    "\n",
    "Pour d√©ployer cette application, suivez ces √©tapes:\n",
    "\n",
    "1. Cr√©ez un dossier pour votre application web\n",
    "2. Placez le code HTML ci-dessus dans un fichier `index.html`\n",
    "3. Copiez le dossier `tfjs_mnist_model` (cr√©√© lors de la conversion) dans le m√™me r√©pertoire\n",
    "4. Utilisez un serveur web pour servir ces fichiers (pour √©viter les probl√®mes CORS)\n",
    "   \n",
    "Exemple avec Python:\n",
    "\n",
    "```python\n",
    "# Lancer un serveur web simple avec Python\n",
    "!python -m http.server 8000\n",
    "```\n",
    "\n",
    "Vous pouvez alors acc√©der √† votre application √† l'adresse `http://localhost:8000`.\n",
    "\n",
    "### Am√©liorations possibles\n",
    "\n",
    "Voici quelques id√©es pour am√©liorer cette application:\n",
    "\n",
    "1. **Augmenter la robustesse**:\n",
    "   - Ajouter un pr√©traitement plus avanc√© pour centrer et normaliser les dessins\n",
    "   - Impl√©menter l'augmentation de donn√©es c√¥t√© client\n",
    "\n",
    "2. **Am√©liorer l'exp√©rience utilisateur**:\n",
    "   - Ajouter une animation pendant le chargement du mod√®le\n",
    "   - Permettre le dessin sur mobile (√©v√©nements tactiles)\n",
    "   - Ajouter un historique des pr√©dictions\n",
    "\n",
    "3. **Optimisations**:\n",
    "   - Quantifier le mod√®le pour r√©duire sa taille\n",
    "   - Utiliser la d√©tection de changements pour pr√©dire automatiquement apr√®s le dessin\n",
    "\n",
    "## 10. Conclusion et perspectives\n",
    "\n",
    "Dans ce notebook, nous avons:\n",
    "\n",
    "- Compris l'architecture et le principe des r√©seaux convolutifs (CNN)\n",
    "- Impl√©ment√© un CNN avec TensorFlow/Keras pour la reconnaissance d'images MNIST\n",
    "- Visualis√© et interpr√©t√© les filtres et feature maps\n",
    "- Analys√© les performances du mod√®le et les cas d'erreur\n",
    "- Explor√© l'int√©gration d'un mod√®le CNN dans une application web\n",
    "\n",
    "### Perspectives et extensions possibles\n",
    "\n",
    "- **Am√©liorer le mod√®le**:\n",
    "  - Exp√©rimenter avec des architectures plus complexes (VGG, ResNet, etc.)\n",
    "  - Utiliser des techniques d'augmentation de donn√©es pour am√©liorer la robustesse\n",
    "  - Appliquer l'apprentissage par transfert\n",
    "\n",
    "- **Applications √† d'autres jeux de donn√©es**:\n",
    "  - Fashion MNIST (v√™tements)\n",
    "  - CIFAR-10 (objets color√©s)\n",
    "  - ImageNet (classification √† grande √©chelle)\n",
    "\n",
    "- **Techniques avanc√©es**:\n",
    "  - D√©tection d'objets (YOLO, SSD)\n",
    "  - Segmentation s√©mantique (U-Net)\n",
    "  - Style transfer\n",
    "\n",
    "Les r√©seaux de neurones convolutifs sont aujourd'hui la base de nombreuses applications de vision par ordinateur. La compr√©hension de leur fonctionnement est essentielle pour tout d√©veloppeur souhaitant exploiter le potentiel de l'IA dans ce domaine.\n",
    "\n",
    "## Exercices suppl√©mentaires\n",
    "\n",
    "1. Modifiez l'architecture du CNN pour am√©liorer sa pr√©cision (ajoutez des couches, modifiez les hyperparam√®tres)\n",
    "2. Impl√©mentez l'augmentation de donn√©es pour am√©liorer la robustesse du mod√®le\n",
    "3. Testez le mod√®le sur vos propres dessins de chiffres\n",
    "4. Adaptez ce notebook pour classifier le dataset Fashion MNIST\n",
    "5. Cr√©ez une version web plus √©labor√©e avec une interface utilisateur am√©lior√©e"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
