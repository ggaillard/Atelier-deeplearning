{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook B: Classification avec Deep Learning\n",
    "# Classification des chiffres manuscrits avec un réseau de neurones\n",
    "\n",
    "# Partie 1: Importation des bibliothèques\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Vérifier la version de TensorFlow\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Partie 2: Chargement et exploration des données\n",
    "print(\"Chargement du jeu de données MNIST...\")\n",
    "# Utilisation du jeu de données MNIST intégré à TensorFlow\n",
    "(X_train_full, y_train_full), (X_test_full, y_test_full) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalisation des valeurs de pixels entre 0 et 1\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test_full = X_test_full / 255.0\n",
    "\n",
    "# Exploration des données\n",
    "print(f\"Dimensions des données d'entraînement: {X_train_full.shape}\")\n",
    "print(f\"Dimensions des données de test: {X_test_full.shape}\")\n",
    "print(f\"Nombre de classes: {len(np.unique(y_train_full))}\")\n",
    "\n",
    "# Affichage de quelques exemples\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_train_full[i], cmap='gray')\n",
    "    plt.title(f\"Label: {y_train_full[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Exemples de chiffres manuscrits\", y=1.05)\n",
    "plt.show()\n",
    "\n",
    "# Partie 3: Préparation des données pour Deep Learning\n",
    "\n",
    "print(\"\\n--- Préparation des données pour le réseau de neurones ---\")\n",
    "print(\"Pour le Deep Learning, nous n'avons pas besoin d'extraire manuellement des caractéristiques.\")\n",
    "\n",
    "# Utiliser un sous-ensemble des données pour accélérer la démonstration (même taille que le Random Forest)\n",
    "n_samples = 10000\n",
    "X_train = X_train_full[:n_samples]\n",
    "y_train = y_train_full[:n_samples]\n",
    "X_test = X_test_full[:2000]\n",
    "y_test = y_test_full[:2000]\n",
    "\n",
    "# Pour le Deep Learning, il nous faut juste redimensionner les images\n",
    "print(\"Redimensionnement des images...\")\n",
    "print(f\"Forme originale: {X_train.shape}\")\n",
    "\n",
    "# Aplatir les images 28x28 en vecteurs de 784 pixels\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], 28*28)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], 28*28)\n",
    "\n",
    "print(f\"Forme après redimensionnement: {X_train_flat.shape}\")\n",
    "\n",
    "# One-hot encoding des labels\n",
    "y_train_cat = to_categorical(y_train, 10)\n",
    "y_test_cat = to_categorical(y_test, 10)\n",
    "\n",
    "print(\"Encodage one-hot des labels\")\n",
    "print(f\"Forme originale des labels: {y_train.shape}\")\n",
    "print(f\"Forme après encodage one-hot: {y_train_cat.shape}\")\n",
    "\n",
    "# Partie 4: Création du modèle de Deep Learning\n",
    "\n",
    "print(\"\\n--- Création du modèle de réseau de neurones ---\")\n",
    "\n",
    "# Paramètres du modèle - vous pouvez les modifier\n",
    "n_hidden1 = 128  # Nombre de neurones dans la première couche cachée\n",
    "n_hidden2 = 64   # Nombre de neurones dans la seconde couche cachée\n",
    "learning_rate = 0.001  # Taux d'apprentissage\n",
    "dropout_rate = 0.2  # Taux de dropout pour la régularisation\n",
    "n_epochs = 10  # Nombre d'époques d'entraînement\n",
    "batch_size = 32  # Taille du batch\n",
    "\n",
    "# Création du modèle\n",
    "model = Sequential([\n",
    "    # Couche d'entrée: 784 neurones (un par pixel)\n",
    "    # Première couche cachée\n",
    "    Dense(n_hidden1, activation='relu', input_shape=(784,)),\n",
    "    Dropout(dropout_rate),\n",
    "    # Deuxième couche cachée\n",
    "    Dense(n_hidden2, activation='relu'),\n",
    "    Dropout(dropout_rate),\n",
    "    # Couche de sortie: 10 neurones (un par classe)\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilation du modèle\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Affichage du résumé du modèle\n",
    "model.summary()\n",
    "\n",
    "# Partie 5: Entraînement du modèle\n",
    "\n",
    "print(\"\\n--- Entraînement du modèle de Deep Learning ---\")\n",
    "\n",
    "# Mesure du temps d'entraînement\n",
    "start_time = time.time()\n",
    "print(\"Entraînement du modèle en cours...\")\n",
    "\n",
    "# Entraînement du modèle\n",
    "history = model.fit(\n",
    "    X_train_flat, y_train_cat,\n",
    "    epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Temps d'entraînement: {training_time:.2f} secondes\")\n",
    "\n",
    "# Partie 6: Visualisation de l'apprentissage\n",
    "\n",
    "print(\"\\n--- Visualisation de l'apprentissage ---\")\n",
    "\n",
    "# Tracer l'évolution de la précision et de la perte\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Évolution de la précision\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Entraînement')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.title('Évolution de la précision')\n",
    "plt.xlabel('Époque')\n",
    "plt.ylabel('Précision')\n",
    "plt.legend()\n",
    "\n",
    "# Évolution de la perte\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Entraînement')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.title('Évolution de la perte')\n",
    "plt.xlabel('Époque')\n",
    "plt.ylabel('Perte')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Partie 7: Évaluation du modèle\n",
    "\n",
    "print(\"\\n--- Évaluation du modèle de Deep Learning ---\")\n",
    "\n",
    "# Évaluation sur l'ensemble de test\n",
    "test_loss, test_accuracy = model.evaluate(X_test_flat, y_test_cat, verbose=0)\n",
    "print(f\"Précision sur l'ensemble de test: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "# Prédictions sur l'ensemble de test\n",
    "y_pred_prob = model.predict(X_test_flat)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Calcul des métriques\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"\\nMatrice de confusion:\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Prédictions')\n",
    "plt.ylabel('Valeurs réelles')\n",
    "plt.title('Matrice de confusion')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRapport de classification:\")\n",
    "print(class_report)\n",
    "\n",
    "# Partie 8: Visualisation des erreurs\n",
    "\n",
    "print(\"\\n--- Analyse des erreurs ---\")\n",
    "\n",
    "# Identifier les erreurs\n",
    "error_indices = np.where(y_pred != y_test)[0]\n",
    "n_errors = min(10, len(error_indices))  # Afficher max 10 erreurs\n",
    "\n",
    "if n_errors > 0:\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for i, idx in enumerate(error_indices[:n_errors]):\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.imshow(X_test[idx], cmap='gray')\n",
    "        plt.title(f\"Réel: {y_test[idx]}\\nPrédit: {y_pred[idx]}\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"Exemples d'erreurs de classification\", y=1.05)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Aucune erreur trouvée dans l'échantillon de test!\")\n",
    "\n",
    "# Partie 9: Visualisation des poids\n",
    "\n",
    "print(\"\\n--- Visualisation des poids appris ---\")\n",
    "\n",
    "# Récupérer les poids de la première couche\n",
    "weights = model.layers[0].get_weights()[0]  # [784, n_hidden1]\n",
    "\n",
    "# Visualiser quelques filtres (neurones de la première couche)\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    # Redimensionner les poids du neurone en 28x28\n",
    "    neuron_weights = weights[:, i].reshape(28, 28)\n",
    "    plt.imshow(neuron_weights, cmap='coolwarm')\n",
    "    plt.title(f\"Neurone {i+1}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Poids appris par les neurones de la première couche\", y=1.05)\n",
    "plt.show()\n",
    "\n",
    "print(\"Ces visualisations montrent ce que 'recherchent' les neurones de la première couche dans les images.\")\n",
    "\n",
    "# Partie 10: Défi de généralisation\n",
    "\n",
    "print(\"\\n--- Défi de généralisation ---\")\n",
    "print(\"Nous allons maintenant tester le modèle sur des chiffres légèrement modifiés pour évaluer sa capacité de généralisation.\")\n",
    "\n",
    "# Fonction pour ajouter du bruit aux images\n",
    "def add_noise(images, noise_level=0.2):\n",
    "    noisy_images = images.copy()\n",
    "    noise = np.random.normal(0, noise_level, images.shape)\n",
    "    noisy_images = noisy_images + noise\n",
    "    # Assurer que les valeurs restent entre 0 et 1\n",
    "    noisy_images = np.clip(noisy_images, 0, 1)\n",
    "    return noisy_images\n",
    "\n",
    "# Fonction pour appliquer une rotation aux images\n",
    "def rotate_images(images, max_angle=15):\n",
    "    from scipy.ndimage import rotate\n",
    "    rotated_images = np.zeros_like(images)\n",
    "    for i, img in enumerate(images):\n",
    "        angle = np.random.uniform(-max_angle, max_angle)\n",
    "        rotated = rotate(img, angle, reshape=False)\n",
    "        rotated_images[i] = rotated\n",
    "    return rotated_images\n",
    "\n",
    "# Créer un jeu de données modifié\n",
    "print(\"Création d'un jeu de données avec des chiffres modifiés...\")\n",
    "\n",
    "# Utiliser un nouvel ensemble de données pour ce test\n",
    "X_new = X_test_full[2000:4000]\n",
    "y_new = y_test_full[2000:4000]\n",
    "\n",
    "# Appliquer des transformations\n",
    "X_new_noisy = add_noise(X_new, noise_level=0.2)\n",
    "X_new_rotated = rotate_images(X_new, max_angle=15)\n",
    "\n",
    "# Visualiser quelques exemples\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(5):\n",
    "    # Original\n",
    "    plt.subplot(3, 5, i + 1)\n",
    "    plt.imshow(X_new[i], cmap='gray')\n",
    "    plt.title(f\"Original: {y_new[i]}\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Avec bruit\n",
    "    plt.subplot(3, 5, i + 6)\n",
    "    plt.imshow(X_new_noisy[i], cmap='gray')\n",
    "    plt.title(\"Avec bruit\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Avec rotation\n",
    "    plt.subplot(3, 5, i + 11)\n",
    "    plt.imshow(X_new_rotated[i], cmap='gray')\n",
    "    plt.title(\"Avec rotation\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Exemples de chiffres modifiés\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Préparation des données modifiées\n",
    "X_new_flat = X_new.reshape(X_new.shape[0], 28*28)\n",
    "X_new_noisy_flat = X_new_noisy.reshape(X_new_noisy.shape[0], 28*28)\n",
    "X_new_rotated_flat = X_new_rotated.reshape(X_new_rotated.shape[0], 28*28)\n",
    "\n",
    "# Évaluer le modèle sur les données modifiées\n",
    "print(\"\\nÉvaluation sur les données originales:\")\n",
    "y_new_pred = np.argmax(model.predict(X_new_flat), axis=1)\n",
    "accuracy_original = accuracy_score(y_new, y_new_pred)\n",
    "print(f\"Précision sur données originales: {accuracy_original*100:.2f}%\")\n",
    "\n",
    "print(\"\\nÉvaluation sur les données avec bruit:\")\n",
    "y_new_noisy_pred = np.argmax(model.predict(X_new_noisy_flat), axis=1)\n",
    "accuracy_noisy = accuracy_score(y_new, y_new_noisy_pred)\n",
    "print(f\"Précision sur données bruitées: {accuracy_noisy*100:.2f}%\")\n",
    "\n",
    "print(\"\\nÉvaluation sur les données avec rotation:\")\n",
    "y_new_rotated_pred = np.argmax(model.predict(X_new_rotated_flat), axis=1)\n",
    "accuracy_rotated = accuracy_score(y_new, y_new_rotated_pred)\n",
    "print(f\"Précision sur données pivotées: {accuracy_rotated*100:.2f}%\")\n",
    "\n",
    "print(\"\\nComparaison des précisions:\")\n",
    "print(f\"Précision sur données originales: {accuracy_original*100:.2f}%\")\n",
    "print(f\"Précision sur données bruitées: {accuracy_noisy*100:.2f}%\")\n",
    "print(f\"Précision sur données pivotées: {accuracy_rotated*100:.2f}%\")\n",
    "\n",
    "# Partie 11: Conclusions et réflexion\n",
    "\n",
    "print(\"\\n--- Conclusions sur le Deep Learning ---\")\n",
    "print(\"\"\"\n",
    "Points forts du réseau de neurones:\n",
    "- Apprentissage automatique des caractéristiques (pas de feature engineering manuel)\n",
    "- Bonnes performances sur les données originales et transformées\n",
    "- Capacité à capturer des motifs complexes\n",
    "\n",
    "Limites:\n",
    "- Temps d'entraînement généralement plus long que les méthodes classiques\n",
    "- Plus de paramètres à régler\n",
    "- Risque de surapprentissage sur petits ensembles de données\n",
    "- Interprétabilité plus difficile\n",
    "\n",
    "Questions pour la réflexion:\n",
    "1. Pourquoi le Deep Learning gère-t-il mieux les transformations des données?\n",
    "2. Comment pourrions-nous améliorer encore les performances du modèle?\n",
    "3. Quels types de problèmes sont particulièrement adaptés au Deep Learning?\n",
    "\"\"\")\n",
    "\n",
    "# Partie 12: Widget interactif pour tester le modèle\n",
    "\n",
    "print(\"\\n--- Testez le modèle vous-même ---\")\n",
    "\n",
    "def test_dl_model(digit_idx):\n",
    "    if digit_idx < len(X_test):\n",
    "        # Afficher l'image\n",
    "        img = X_test[digit_idx]\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(f\"Chiffre à classifier\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        # Faire la prédiction\n",
    "        img_flat = img.reshape(1, 784)\n",
    "        prediction_prob = model.predict(img_flat)[0]\n",
    "        prediction = np.argmax(prediction_prob)\n",
    "        real_label = y_test[digit_idx]\n",
    "        \n",
    "        # Afficher les probabilités\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.bar(range(10), prediction_prob)\n",
    "        plt.xticks(range(10))\n",
    "        plt.xlabel('Chiffre')\n",
    "        plt.ylabel('Probabilité')\n",
    "        plt.title('Probabilités prédites pour chaque chiffre')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Prédiction du modèle Deep Learning: {prediction}\")\n",
    "        print(f\"Étiquette réelle: {real_label}\")\n",
    "        print(f\"Prédiction {'correcte' if prediction == real_label else 'incorrecte'}\")\n",
    "        \n",
    "        # Afficher les 3 prédictions les plus probables\n",
    "        top3_idx = np.argsort(prediction_prob)[-3:][::-1]\n",
    "        print(\"\\nTop 3 des prédictions:\")\n",
    "        for i, idx in enumerate(top3_idx):\n",
    "            print(f\"{i+1}. Chiffre {idx}: {prediction_prob[idx]*100:.2f}%\")\n",
    "    else:\n",
    "        print(\"Index hors limites!\")\n",
    "\n",
    "# Créer un slider pour sélectionner un chiffre à tester\n",
    "digit_selector = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(X_test)-1,\n",
    "    step=1,\n",
    "    description='Index:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "# Bouton pour exécuter le test\n",
    "test_button = widgets.Button(description=\"Tester\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        test_dl_model(digit_selector.value)\n",
    "\n",
    "test_button.on_click(on_button_clicked)\n",
    "\n",
    "# Afficher les widgets\n",
    "display(widgets.HBox([digit_selector, test_button]))\n",
    "display(output)\n",
    "\n",
    "print(\"Utilisez le slider pour sélectionner un index et cliquez sur 'Tester' pour classifier le chiffre correspondant.\")\n",
    "\n",
    "# Partie 13: Comparaison avec le modèle Random Forest\n",
    "\n",
    "print(\"\\n--- Comment comparer avec le modèle de Machine Learning classique? ---\")\n",
    "print(\"\"\"\n",
    "Après avoir exploré ce modèle de Deep Learning, comparez-le avec le modèle Random Forest (Notebook A) sur les aspects suivants:\n",
    "\n",
    "1. Préparation des données:\n",
    "   - Random Forest: nécessite une réduction de dimension (PCA)\n",
    "   - Deep Learning: travaille directement avec les pixels bruts\n",
    "\n",
    "2. Architecture et hyperparamètres:\n",
    "   - Random Forest: nombre d'arbres, profondeur, critères de division\n",
    "   - Deep Learning: nombre de couches, neurones, fonctions d'activation, dropout\n",
    "\n",
    "3. Temps d'entraînement:\n",
    "   - Lequel est plus rapide sur ce jeu de données?\n",
    "   - Comment cela évoluerait-il avec plus de données?\n",
    "\n",
    "4. Performance:\n",
    "   - Sur les données originales\n",
    "   - Sur les données modifiées (bruit, rotation)\n",
    "\n",
    "5. Interprétabilité:\n",
    "   - Facilité à comprendre ce que le modèle a appris\n",
    "   - Visualisation des caractéristiques importantes\n",
    "\n",
    "Remplissez le tableau comparatif fourni pour structurer votre analyse.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
