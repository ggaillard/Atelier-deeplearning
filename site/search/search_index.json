{"config":{"lang":["fr"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Chatbot p\u00e9dagogique pour le Deep Learning","text":""},{"location":"#bienvenue-dans-ce-parcours-sur-le-deep-learning","title":"Bienvenue dans ce parcours sur le Deep Learning !","text":"<p>Ce cours vous permettra de d\u00e9couvrir et d'appliquer les technologies de Deep Learning, avec une approche pratique et progressive adapt\u00e9e aux \u00e9tudiants de BTS SIO SLAM. Plut\u00f4t que de commencer par la th\u00e9orie abstraite, vous explorerez les concepts \u00e0 travers des d\u00e9monstrations concr\u00e8tes et des manipulations directes.</p>"},{"location":"#projet-fil-rouge-chatbot-pedagogique","title":"Projet fil rouge : Chatbot p\u00e9dagogique","text":"<p>\ud83e\udd16 Tout au long de ce parcours, vous d\u00e9velopperez un chatbot p\u00e9dagogique capable d'expliquer les concepts du Deep Learning. Ce projet fil rouge vous permettra d'appliquer directement les connaissances acquises et de cr\u00e9er un outil concret utilisant l'IA avanc\u00e9e.</p> <p>\ud83c\udfaf Objectif : Concevoir un chatbot interactif qui aide les \u00e9tudiants \u00e0 comprendre les concepts du Deep Learning \u00e0 travers des explications, exemples et exercices.</p> <ul> <li> <p>4 s\u00e9ances intensives</p> <ul> <li>4 heures par s\u00e9ance</li> <li>Alternance entre th\u00e9orie et pratique</li> <li>Exp\u00e9rimentations progressives</li> <li>\u00c9valuations interm\u00e9diaires</li> </ul> </li> <li> <p>Comp\u00e9tences d\u00e9velopp\u00e9es</p> <ul> <li>Ma\u00eetrise des frameworks principaux (TensorFlow, Keras)</li> <li>Conception de r\u00e9seaux de neurones</li> <li>Optimisation des mod\u00e8les</li> <li>Int\u00e9gration d'IA dans des applications</li> </ul> </li> <li> <p>Technologies utilis\u00e9es</p> <ul> <li>API Mistral AI</li> <li>Google Colab pour l'exp\u00e9rimentation</li> <li>Frameworks de Deep Learning</li> <li>Techniques de traitement du langage naturel</li> </ul> </li> </ul>"},{"location":"#structure-du-cours","title":"Structure du cours","text":"<p>Notre progression a \u00e9t\u00e9 pens\u00e9e pour construire vos comp\u00e9tences de mani\u00e8re coh\u00e9rente et graduelle :</p> <pre><code>flowchart TB\n    A[Introduction au Deep Learning] --&gt; B[R\u00e9seaux de neurones ANN]\n    B --&gt; C[Types de r\u00e9seaux de neurones]\n    C --&gt; D[Apprentissage et entra\u00eenement]\n    D --&gt; E[Outils et biblioth\u00e8ques]\n    E --&gt; F[Exercices pratiques]\n\n    A1[\u00c9valuation niveau 1] -.-&gt; B\n    B1[\u00c9valuation niveau 2] -.-&gt; C\n    C1[\u00c9valuation niveau 3] -.-&gt; D\n    D1[\u00c9valuation niveau 4] -.-&gt; E\n    E1[\u00c9valuation niveau 5] -.-&gt; F\n\n    G[Base de donn\u00e9es Q&amp;A]\n    H[G\u00e9n\u00e9rateur d'exercices]\n    I[Ressources suppl\u00e9mentaires]\n\n    A &amp; B &amp; C &amp; D &amp; E &amp; F --- G\n    F --- H\n    A &amp; B &amp; C &amp; D &amp; E &amp; F --- I</code></pre>"},{"location":"#seance-1-introduction-au-deep-learning-par-lexperimentation","title":"S\u00e9ance 1 : Introduction au Deep Learning par l'exp\u00e9rimentation","text":"<ul> <li>D\u00e9couverte du Deep Learning par des d\u00e9monstrations et manipulations concr\u00e8tes</li> <li>Comparaison entre Machine Learning classique et Deep Learning</li> <li>Exploration du fonctionnement interne d'un r\u00e9seau de neurones</li> <li>Mini-projet collaboratif et d\u00e9brief assist\u00e9 par IA</li> </ul>"},{"location":"#seance-2-types-de-reseaux-et-leurs-applications","title":"S\u00e9ance 2 : Types de r\u00e9seaux et leurs applications","text":"<ul> <li>R\u00e9seaux de neurones convolutifs (CNN) pour la vision par ordinateur</li> <li>R\u00e9seaux r\u00e9currents (RNN) pour le traitement des s\u00e9quences</li> <li>Mini-projets pratiques sur les architectures sp\u00e9cifiques</li> <li>Challenge d'am\u00e9lioration d'un mod\u00e8le en groupe</li> </ul>"},{"location":"#seance-3-optimisation-et-frameworks","title":"S\u00e9ance 3 : Optimisation et frameworks","text":"<ul> <li>Techniques d'optimisation des r\u00e9seaux de neurones</li> <li>R\u00e9tropropagation et descente de gradient</li> <li>D\u00e9couverte de TensorFlow/Keras et PyTorch</li> <li>Pr\u00e9paration du projet final (chatbot p\u00e9dagogique)</li> </ul>"},{"location":"#seance-4-projet-integrateur","title":"S\u00e9ance 4 : Projet int\u00e9grateur","text":"<ul> <li>Application de l'ensemble des connaissances acquises</li> <li>D\u00e9veloppement du chatbot p\u00e9dagogique</li> <li>Int\u00e9gration de l'API Mistral AI</li> <li>Pr\u00e9sentation et d\u00e9fense du projet</li> </ul>"},{"location":"#competences-developpees","title":"Comp\u00e9tences d\u00e9velopp\u00e9es","text":"<p>Ce cours d\u00e9veloppe des comp\u00e9tences essentielles du r\u00e9f\u00e9rentiel BTS SIO SLAM :</p> Comp\u00e9tence Description Activit\u00e9s associ\u00e9es B1.3 Gestion des donn\u00e9es Manipulation des datasets d'images et de texte B1.4 Exploitation des standards Utilisation des API REST, frameworks standard B2.2 Conception de solutions applicatives D\u00e9veloppement de mod\u00e8les et prototypes B2.3 D\u00e9veloppement Int\u00e9gration des mod\u00e8les ML dans des applications B3.2 V\u00e9rification et validation Tests et optimisation des mod\u00e8les B3.3 Documentation technique Documentation des impl\u00e9mentations"},{"location":"#progression-des-competences","title":"Progression des comp\u00e9tences","text":"<p>Le tableau ci-dessous vous permet de visualiser la progression des comp\u00e9tences d\u00e9velopp\u00e9es tout au long du parcours :</p> Comp\u00e9tence S\u00e9ance 1 S\u00e9ance 2 S\u00e9ance 3 S\u00e9ance 4 Compr\u00e9hension du Deep Learning Introduction Architectures sp\u00e9cifiques Optimisation Application compl\u00e8te Programmation Python Notebooks basiques Impl\u00e9mentation mod\u00e8les Frameworks Application compl\u00e8te Visualisation et analyse Outils basiques Filtres et feature maps Outils avanc\u00e9s Int\u00e9gration Optimisation de mod\u00e8les - Premiers ajustements Techniques avanc\u00e9es Application r\u00e9elle Traitement du langage - RNN basiques API Mistral Chatbot complet Travail en \u00e9quipe Bin\u00f4mes Groupes Planification Projet complet"},{"location":"#modalites-devaluation","title":"Modalit\u00e9s d'\u00e9valuation","text":"<p>L'\u00e9valuation globale du parcours se d\u00e9compose ainsi :</p> <ul> <li>Participation active (10%) : Engagement dans les activit\u00e9s, pertinence des contributions</li> <li>Mini-projets (30%) : Qualit\u00e9 des livrables pour les mini-projets des s\u00e9ances 2 et 3</li> <li>Projet final - Produit (30%) : Fonctionnalit\u00e9 et qualit\u00e9 technique du chatbot</li> <li>Projet final - Processus (15%) : Organisation, m\u00e9thodologie, r\u00e9partition des t\u00e2ches</li> <li>Projet final - Pr\u00e9sentation (15%) : Qualit\u00e9 de la pr\u00e9sentation et de la documentation</li> </ul>"},{"location":"#prerequis","title":"Pr\u00e9requis","text":"<p>Pour suivre cette formation, vous devez :</p> <ul> <li>Avoir des connaissances de base en programmation Python</li> <li>Comprendre les principes fondamentaux des algorithmes</li> <li>Disposer d'un compte Google pour utiliser Google Colab</li> <li>Avoir une curiosit\u00e9 pour l'intelligence artificielle et ses applications</li> </ul> <p>\ud83d\udca1Conseil     M\u00eame si vous n'avez pas toutes les connaissances pr\u00e9alables, la nature pratique de cette formation vous permettra d'apprendre progressivement. N'h\u00e9sitez pas \u00e0 poser des questions et \u00e0 exp\u00e9rimenter !</p>"},{"location":"#ressources-complementaires","title":"Ressources compl\u00e9mentaires","text":"<p>En plus des contenus structur\u00e9s par s\u00e9ance, vous trouverez dans cet atelier :</p> <ul> <li>Des notebooks Jupyter pour l'exp\u00e9rimentation (outil pour l'exp\u00e9rimentation et l'analyse de donn\u00e9es)</li> <li>Une base de connaissances sur le Deep Learning</li> <li>La documentation de l'API Mistral</li> <li>Des sch\u00e9mas JSON pour la structuration des donn\u00e9es</li> </ul>"},{"location":"#demarrage-rapide","title":"D\u00e9marrage rapide","text":"<p>Vous \u00eates pr\u00eat \u00e0 plonger dans le monde fascinant du Deep Learning ? Commencez par la premi\u00e8re s\u00e9ance pour d\u00e9couvrir les concepts fondamentaux \u00e0 travers des d\u00e9monstrations et exp\u00e9rimentations concr\u00e8tes.</p> <p>D\u00e9buter avec la premi\u00e8re s\u00e9ance Consulter le projet fil rouge</p>"},{"location":"carte-progression/","title":"Carte de progression","text":""},{"location":"carte-progression/#gps-pedagogique-votre-itineraire-dapprentissage","title":"GPS p\u00e9dagogique : votre itin\u00e9raire d'apprentissage","text":"<p>Cette carte de progression vous guidera \u00e0 travers les 4 s\u00e9ances de formation, en vous permettant de visualiser clairement les objectifs, les activit\u00e9s et les comp\u00e9tences d\u00e9velopp\u00e9es \u00e0 chaque \u00e9tape.</p>"},{"location":"carte-progression/#vue-densemble-du-parcours","title":"Vue d'ensemble du parcours","text":"<pre><code>gantt\n    title Progression p\u00e9dagogique du parcours Deep Learning\n    axisFormat %s\n\n    section S\u00e9ance 1\n    Introduction par l'exp\u00e9rimentation    :a1, 0, 4h\n\n    section S\u00e9ance 2\n    Types de r\u00e9seaux et applications      :a2, after a1, 4h\n\n    section S\u00e9ance 3\n    Optimisation et frameworks            :a3, after a2, 4h\n\n    section S\u00e9ance 4\n    Projet int\u00e9grateur                    :a4, after a3, 4h</code></pre>"},{"location":"carte-progression/#seance-1-introduction-au-deep-learning-par-lexperimentation","title":"S\u00e9ance 1 : Introduction au Deep Learning par l'exp\u00e9rimentation","text":""},{"location":"carte-progression/#objectifs-pedagogiques","title":"Objectifs p\u00e9dagogiques","text":"<ul> <li>D\u00e9couvrir le Deep Learning par des d\u00e9monstrations et manipulations concr\u00e8tes</li> <li>Comprendre les diff\u00e9rences fondamentales entre Machine Learning classique et Deep Learning</li> <li>Explorer le fonctionnement interne d'un r\u00e9seau de neurones</li> <li>Acqu\u00e9rir le vocabulaire technique de base du Deep Learning</li> </ul>"},{"location":"carte-progression/#activites","title":"Activit\u00e9s","text":"<ul> <li>Mise en situation pratique (1h) : D\u00e9monstrations, prise en main sur Google Colab</li> <li>D\u00e9couverte des concepts (1h30) : Comparaison ML vs DL, exploration de notebooks</li> <li>TP guid\u00e9 (1h15) : Anatomie d'un r\u00e9seau de neurones, manipulation des composants</li> <li>D\u00e9brief (15min) : Synth\u00e8se des concepts cl\u00e9s</li> </ul>"},{"location":"carte-progression/#livrables","title":"Livrables","text":"<ul> <li>Fiches d'observations compl\u00e9t\u00e9es</li> <li>Tableau comparatif ML vs DL</li> <li>Sch\u00e9ma annot\u00e9 d'un r\u00e9seau de neurones</li> </ul>"},{"location":"carte-progression/#seance-2-types-de-reseaux-et-leurs-applications","title":"S\u00e9ance 2 : Types de r\u00e9seaux et leurs applications","text":"<p>Dur\u00e9e : 4 heures</p>"},{"location":"carte-progression/#objectifs-pedagogiques_1","title":"Objectifs p\u00e9dagogiques","text":"<ul> <li>Comprendre les architectures CNN pour la vision par ordinateur</li> <li>Explorer les r\u00e9seaux RNN pour le traitement des s\u00e9quences</li> <li>Appliquer ces connaissances \u00e0 des cas d'usage concrets</li> <li>D\u00e9velopper une approche d'am\u00e9lioration it\u00e9rative des mod\u00e8les</li> </ul>"},{"location":"carte-progression/#activites_1","title":"Activit\u00e9s","text":"<ul> <li>Mini-projet CNN (1h30) : Exploration d'un r\u00e9seau convolutif, classification d'images</li> <li>Mini-projet RNN (1h30) : Manipulation d'un r\u00e9seau r\u00e9current, traitement de s\u00e9quences</li> <li>Challenge d'am\u00e9lioration (1h) : Optimisation d'un mod\u00e8le en \u00e9quipe</li> </ul>"},{"location":"carte-progression/#livrables_1","title":"Livrables","text":"<ul> <li>Mod\u00e8le CNN fonctionnel avec visualisations</li> <li>Mod\u00e8le RNN/LSTM avec analyse des performances</li> <li>Rapport d'am\u00e9lioration documentant les exp\u00e9rimentations</li> </ul>"},{"location":"carte-progression/#seance-3-optimisation-et-frameworks","title":"S\u00e9ance 3 : Optimisation et frameworks","text":"<p>Dur\u00e9e : 4 heures</p>"},{"location":"carte-progression/#objectifs-pedagogiques_2","title":"Objectifs p\u00e9dagogiques","text":"<ul> <li>Ma\u00eetriser les techniques d'optimisation des r\u00e9seaux de neurones</li> <li>D\u00e9couvrir les principaux frameworks de Deep Learning</li> <li>Pr\u00e9parer la conception du projet final (chatbot p\u00e9dagogique)</li> <li>S'initier \u00e0 l'API Mistral AI pour la g\u00e9n\u00e9ration de texte</li> </ul>"},{"location":"carte-progression/#activites_2","title":"Activit\u00e9s","text":"<ul> <li>Projet d'optimisation (1h30) : R\u00e9tropropagation, comparaison d'optimiseurs</li> <li>D\u00e9couverte des frameworks (1h30) : TensorFlow/Keras vs PyTorch</li> <li>Pr\u00e9paration au projet final (1h) : Cahier des charges, formation des \u00e9quipes</li> </ul>"},{"location":"carte-progression/#livrables_2","title":"Livrables","text":"<ul> <li>Rapport d'optimisation avec analyse comparative</li> <li>Mod\u00e8le impl\u00e9ment\u00e9 dans deux frameworks diff\u00e9rents</li> <li>Document de conception initiale du chatbot p\u00e9dagogique</li> </ul>"},{"location":"carte-progression/#seance-4-projet-integrateur","title":"S\u00e9ance 4 : Projet int\u00e9grateur","text":"<p>Dur\u00e9e : 4 heures</p>"},{"location":"carte-progression/#objectifs-pedagogiques_3","title":"Objectifs p\u00e9dagogiques","text":"<ul> <li>Appliquer l'ensemble des connaissances acquises \u00e0 un projet concret</li> <li>D\u00e9velopper un chatbot p\u00e9dagogique fonctionnel</li> <li>Int\u00e9grer l'API Mistral AI dans une solution compl\u00e8te</li> <li>Pr\u00e9senter et d\u00e9fendre un projet technique</li> </ul>"},{"location":"carte-progression/#activites_3","title":"Activit\u00e9s","text":"<ul> <li>D\u00e9veloppement du chatbot (2h30) : Base de connaissances, impl\u00e9mentation, int\u00e9gration API</li> <li>Finalisation et tests (1h) : Tests, optimisation, documentation</li> <li>Pr\u00e9sentation des projets (30min) : D\u00e9monstration par \u00e9quipe</li> </ul>"},{"location":"carte-progression/#livrables_3","title":"Livrables","text":"<ul> <li>Code source complet du chatbot p\u00e9dagogique</li> <li>Documentation technique et guide utilisateur</li> <li>Pr\u00e9sentation du projet</li> <li>Base de connaissances structur\u00e9e sur le Deep Learning</li> </ul>"},{"location":"carte-progression/#progression-des-competences","title":"Progression des comp\u00e9tences","text":"Comp\u00e9tence S\u00e9ance 1 S\u00e9ance 2 S\u00e9ance 3 S\u00e9ance 4 Deep Learning Introduction Architectures Optimisation Application Programmation Notebooks Impl\u00e9mentation Frameworks Application Visualisation Outils basiques Feature maps Outils avanc\u00e9s Int\u00e9gration Optimisation - Ajustements Techniques Application NLP - RNN basiques API Mistral Chatbot Travail en \u00e9quipe Bin\u00f4mes Groupes Planification Projet"},{"location":"carte-progression/#evaluation","title":"\u00c9valuation","text":"Composante % Description Participation 10% Engagement et contributions Mini-projets 30% Livrables des s\u00e9ances 2-3 Projet - Produit 30% Fonctionnalit\u00e9 du chatbot Projet - Processus 15% Organisation, m\u00e9thodologie Projet - Pr\u00e9sentation 15% Pr\u00e9sentation et documentation <p>Commencer la S\u00e9ance 1</p>"},{"location":"presentation/","title":"Pr\u00e9sentation du projet fil rouge","text":""},{"location":"presentation/#le-chatbot-pedagogique-sur-le-deep-learning","title":"Le chatbot p\u00e9dagogique sur le Deep Learning","text":""},{"location":"presentation/#vision-du-projet","title":"Vision du projet","text":"<p>Imaginez un assistant virtuel capable d'expliquer les concepts complexes du Deep Learning, de r\u00e9pondre aux questions, de proposer des exercices adapt\u00e9s et d'accompagner l'apprenant dans sa progression. C'est exactement ce que nous allons cr\u00e9er ensemble au cours de ce parcours !</p> <p>\ud83c\udfaf Objectif : Concevoir un chatbot interactif qui aide les \u00e9tudiants de BTS SIO SLAM \u00e0 comprendre les concepts du Deep Learning \u00e0 travers des explications, exemples et exercices.</p>"},{"location":"presentation/#pourquoi-ce-projet","title":"Pourquoi ce projet ?","text":"<p>Ce projet fil rouge a \u00e9t\u00e9 choisi pour plusieurs raisons strat\u00e9giques :</p> <ol> <li>Application concr\u00e8te : Il permet d'appliquer directement les concepts du Deep Learning \u00e0 un cas d'usage r\u00e9el</li> <li>Dimension m\u00e9ta : Le chatbot enseigne le Deep Learning en utilisant lui-m\u00eame des techniques de Deep Learning</li> <li>Utilit\u00e9 p\u00e9dagogique : Le produit final pourra \u00eatre utilis\u00e9 comme support d'apprentissage pour d'autres \u00e9tudiants</li> <li>Technologies actuelles : Il int\u00e8gre l'utilisation d'API modernes comme Mistral AI</li> <li>Comp\u00e9tences transversales : Il mobilise des connaissances en d\u00e9veloppement, IA, p\u00e9dagogie et conception d'interfaces</li> </ol>"},{"location":"presentation/#concepts-abordes-par-le-chatbot","title":"Concepts abord\u00e9s par le chatbot","text":"<p>Le chatbot que vous d\u00e9velopperez devra \u00eatre capable d'expliquer progressivement les notions suivantes :</p> <ol> <li> <p>Introduction au Deep Learning</p> <ul> <li>Diff\u00e9rence entre Machine Learning &amp; Deep Learning</li> <li>Exemples d'applications dans les entreprises</li> </ul> </li> <li> <p>Les r\u00e9seaux de neurones artificiels (ANN)</p> <ul> <li>Fonctionnement des neurones et couches</li> <li>R\u00f4le des poids et biais</li> </ul> </li> <li> <p>Les types de r\u00e9seaux de neurones</p> <ul> <li>R\u00e9seaux de neurones profonds (DNN)</li> <li>R\u00e9seaux convolutifs (CNN \u2013 vision par ordinateur)</li> <li>R\u00e9seaux r\u00e9currents (RNN \u2013 traitement de texte)</li> </ul> </li> <li> <p>L'apprentissage et l'entra\u00eenement d'un mod\u00e8le</p> <ul> <li>Propagation avant &amp; r\u00e9tropropagation</li> <li>Fonction de perte et optimisation</li> </ul> </li> <li> <p>Les outils et biblioth\u00e8ques</p> <ul> <li>TensorFlow, Keras, PyTorch</li> </ul> </li> <li> <p>Exercices interactifs</p> <ul> <li>QCM, mini-codes \u00e0 compl\u00e9ter, quiz</li> </ul> </li> </ol>"},{"location":"presentation/#architecture-du-projet","title":"Architecture du projet","text":"<p>Le chatbot s'appuiera sur une architecture modulaire comprenant :</p> <pre><code>flowchart TB\n    A[Introduction au Deep Learning] --&gt; B[R\u00e9seaux de neurones ANN]\n    B --&gt; C[Types de r\u00e9seaux de neurones]\n    C --&gt; D[Apprentissage et entra\u00eenement]\n    D --&gt; E[Outils et biblioth\u00e8ques]\n    E --&gt; F[Exercices pratiques]\n\n    A1[\u00c9valuation niveau 1] -.-&gt; B\n    B1[\u00c9valuation niveau 2] -.-&gt; C\n    C1[\u00c9valuation niveau 3] -.-&gt; D\n    D1[\u00c9valuation niveau 4] -.-&gt; E\n    E1[\u00c9valuation niveau 5] -.-&gt; F\n\n    G[Base de donn\u00e9es Q&amp;A]\n    H[G\u00e9n\u00e9rateur d'exercices]\n    I[Ressources suppl\u00e9mentaires]\n\n    A &amp; B &amp; C &amp; D &amp; E &amp; F --- G\n    F --- H\n    A &amp; B &amp; C &amp; D &amp; E &amp; F --- I</code></pre>"},{"location":"presentation/#integration-de-mistral-ai","title":"Int\u00e9gration de Mistral AI","text":"<p>Une dimension innovante du projet est l'int\u00e9gration de l'API Mistral AI, un mod\u00e8le de langage avanc\u00e9 qui permettra d'am\u00e9liorer significativement les capacit\u00e9s conversationnelles et p\u00e9dagogiques du chatbot.</p> <p>Voici comment cette int\u00e9gration sera d\u00e9velopp\u00e9e progressivement :</p> <ol> <li>S\u00e9ances 1-2: Fondamentaux et structure, introduction \u00e0 l'API Mistral AI, test de connexion</li> <li>S\u00e9ances 3-4: Impl\u00e9mentation avanc\u00e9e, prompt engineering, finalisation et optimisation</li> </ol>"},{"location":"presentation/#organisation-sur-4-seances","title":"Organisation sur 4 s\u00e9ances","text":"<p>Le projet sera d\u00e9velopp\u00e9 sur 4 s\u00e9ances de 4 heures chacune :</p> <ol> <li>Introduction au Deep Learning par l'exp\u00e9rimentation : Fondamentaux, mise en situation pratique, d\u00e9couverte des concepts, exploration des r\u00e9seaux de neurones</li> <li>Types de r\u00e9seaux et leurs applications : R\u00e9seaux convolutifs (CNN) pour la vision, r\u00e9seaux r\u00e9currents (RNN) pour le texte, am\u00e9lioration it\u00e9rative des mod\u00e8les</li> <li>Optimisation et frameworks : Techniques d'optimisation, d\u00e9couverte des frameworks (TensorFlow, PyTorch), pr\u00e9paration du projet final</li> <li>Projet int\u00e9grateur : D\u00e9veloppement du chatbot, finalisation, tests, pr\u00e9sentation</li> </ol>"},{"location":"presentation/#livrables-attendus","title":"Livrables attendus","text":"<p>\u00c0 la fin du parcours, votre \u00e9quipe devra remettre :</p> <ul> <li>Le code source complet du chatbot p\u00e9dagogique</li> <li>La base de connaissances structur\u00e9e</li> <li>La documentation technique expliquant l'architecture</li> <li>Le guide utilisateur pour une prise en main facile</li> <li>Une pr\u00e9sentation de votre solution</li> </ul>"},{"location":"presentation/#competences-developpees","title":"Comp\u00e9tences d\u00e9velopp\u00e9es","text":"<p>Ce projet vous permettra de d\u00e9velopper plusieurs comp\u00e9tences essentielles :</p> Domaine Comp\u00e9tences d\u00e9velopp\u00e9es Deep Learning Compr\u00e9hension des architectures de r\u00e9seaux, entra\u00eenement de mod\u00e8les, optimisation Programmation D\u00e9veloppement Python, utilisation d'API, gestion de donn\u00e9es structur\u00e9es Ing\u00e9nierie NLP Traitement du langage naturel, gestion de conversations, prompt engineering Conception Architecture logicielle, mod\u00e9lisation de bases de connaissances Gestion de projet Travail en \u00e9quipe, planification, documentation"},{"location":"presentation/#modalites-devaluation","title":"Modalit\u00e9s d'\u00e9valuation","text":"<p>L'\u00e9valuation du projet se fera selon plusieurs dimensions :</p> <ul> <li>Qualit\u00e9 du produit final (fonctionnalit\u00e9s, exp\u00e9rience utilisateur)</li> <li>Exactitude du contenu p\u00e9dagogique (pr\u00e9cision des explications)</li> <li>Qualit\u00e9 technique (architecture, optimisation, robustesse)</li> <li>Processus de d\u00e9veloppement (organisation, m\u00e9thodologie)</li> <li>Pr\u00e9sentation et documentation (clart\u00e9, exhaustivit\u00e9)</li> </ul> <p>Consultez la grille d\u00e9taill\u00e9e d'\u00e9valuation pour plus d'informations.</p>"},{"location":"presentation/#organisation-du-travail-en-equipe","title":"Organisation du travail en \u00e9quipe","text":"<p>Vous travaillerez en \u00e9quipes de 1-2 \u00e9tudiants. Pour garantir une r\u00e9partition \u00e9quilibr\u00e9e des t\u00e2ches, vous utiliserez la grille de r\u00e9partition des t\u00e2ches fournie.</p>"},{"location":"presentation/#pret-a-commencer-laventure","title":"Pr\u00eat \u00e0 commencer l'aventure ?","text":"<p>Maintenant que vous avez une vision claire du projet fil rouge, d\u00e9couvrez la progression p\u00e9dagogique qui vous guidera tout au long de ce parcours.</p> <p>Voir la carte de progression Commencer la S\u00e9ance 1</p>"},{"location":"evaluation/criteres-evaluation/","title":"Crit\u00e8res d'\u00e9valuation","text":"<p>Ce document pr\u00e9sente les crit\u00e8res d'\u00e9valuation du projet de chatbot p\u00e9dagogique sur le Deep Learning.</p>"},{"location":"evaluation/criteres-evaluation/#repartition-globale","title":"R\u00e9partition globale","text":"Composante % Description Participation active 10% Engagement dans les activit\u00e9s et contributions Mini-projets 30% Qualit\u00e9 des livrables des s\u00e9ances 2 et 3 Projet final - Produit 30% Fonctionnalit\u00e9 et qualit\u00e9 du chatbot Projet final - Processus 15% Organisation et m\u00e9thodologie Projet final - Pr\u00e9sentation 15% Pr\u00e9sentation et documentation"},{"location":"evaluation/criteres-evaluation/#detail-des-criteres","title":"D\u00e9tail des crit\u00e8res","text":""},{"location":"evaluation/criteres-evaluation/#1-participation-active-10","title":"1. Participation active (10%)","text":"<ul> <li>Pr\u00e9sence et engagement : Assiduit\u00e9 et implication dans les activit\u00e9s</li> <li>Pertinence des interventions : Qualit\u00e9 des questions et contributions</li> <li>Collaboration : Attitude constructive dans le travail d'\u00e9quipe</li> </ul>"},{"location":"evaluation/criteres-evaluation/#2-mini-projets-30","title":"2. Mini-projets (30%)","text":""},{"location":"evaluation/criteres-evaluation/#mini-projet-cnn-10","title":"Mini-projet CNN (10%)","text":"<ul> <li>Fonctionnalit\u00e9 du mod\u00e8le CNN</li> <li>Qualit\u00e9 du code et des visualisations</li> <li>Compr\u00e9hension des concepts</li> </ul>"},{"location":"evaluation/criteres-evaluation/#mini-projet-rnn-10","title":"Mini-projet RNN (10%)","text":"<ul> <li>Fonctionnalit\u00e9 du mod\u00e8le RNN/LSTM</li> <li>Analyse des performances</li> <li>Compr\u00e9hension des concepts</li> </ul>"},{"location":"evaluation/criteres-evaluation/#projet-doptimisation-10","title":"Projet d'optimisation (10%)","text":"<ul> <li>Techniques d'optimisation appliqu\u00e9es</li> <li>Am\u00e9lioration mesurable des performances</li> <li>Qualit\u00e9 de l'analyse comparative</li> </ul>"},{"location":"evaluation/criteres-evaluation/#3-projet-final-produit-30","title":"3. Projet final - Produit (30%)","text":"<ul> <li>Fonctionnalit\u00e9 du chatbot (12%)</li> <li>Capacit\u00e9 conversationnelle</li> <li>Exactitude des r\u00e9ponses sur le Deep Learning</li> <li>Robustesse et adaptabilit\u00e9</li> <li>Base de connaissances (9%)</li> <li>Couverture des concepts cl\u00e9s</li> <li>Organisation logique des connaissances</li> <li>Qualit\u00e9 p\u00e9dagogique</li> <li>Int\u00e9gration technique (9%)</li> <li>Utilisation de l'API Mistral AI</li> <li>Qualit\u00e9 de l'architecture</li> <li>Performance du syst\u00e8me</li> </ul>"},{"location":"evaluation/criteres-evaluation/#4-projet-final-processus-15","title":"4. Projet final - Processus (15%)","text":"<ul> <li>Organisation de l'\u00e9quipe et r\u00e9partition des t\u00e2ches</li> <li>Respect des d\u00e9lais interm\u00e9diaires</li> <li>Gestion des difficult\u00e9s techniques</li> <li>Communication au sein de l'\u00e9quipe</li> </ul>"},{"location":"evaluation/criteres-evaluation/#5-projet-final-presentation-15","title":"5. Projet final - Pr\u00e9sentation (15%)","text":"<ul> <li>Pr\u00e9sentation orale (7%)</li> <li>Clart\u00e9 de l'expos\u00e9</li> <li>Qualit\u00e9 de la d\u00e9monstration</li> <li>R\u00e9ponses aux questions</li> <li>Documentation (8%)</li> <li>Documentation technique</li> <li>Guide utilisateur</li> <li>Organisation du code source</li> </ul>"},{"location":"evaluation/criteres-evaluation/#systeme-de-notation","title":"Syst\u00e8me de notation","text":"Note % Description A 90-100% Excellent B 75-89% Tr\u00e8s bien C 60-74% Bien D 50-59% Passable E 0-49% Insuffisant"},{"location":"evaluation/grille-repartition-taches/","title":"Grille de r\u00e9partition des t\u00e2ches","text":""},{"location":"evaluation/grille-repartition-taches/#organisation-du-travail-dequipe-pour-le-projet-chatbot-pedagogique","title":"Organisation du travail d'\u00e9quipe pour le projet chatbot p\u00e9dagogique","text":"<p>Cette grille vous aidera \u00e0 organiser efficacement le travail au sein de votre \u00e9quipe pour le d\u00e9veloppement du chatbot p\u00e9dagogique sur le Deep Learning. Une bonne r\u00e9partition des t\u00e2ches est essentielle pour la r\u00e9ussite du projet et fait partie des crit\u00e8res d'\u00e9valuation.</p>"},{"location":"evaluation/grille-repartition-taches/#composition-de-lequipe","title":"Composition de l'\u00e9quipe","text":"Nom et pr\u00e9nom R\u00f4le principal Comp\u00e9tences cl\u00e9s Contact <p>\u00c0 compl\u00e9ter avec les informations de votre \u00e9quipe (2 personnes maximum par \u00e9quipe)</p>"},{"location":"evaluation/grille-repartition-taches/#domaines-de-responsabilite","title":"Domaines de responsabilit\u00e9","text":"<p>Pour \u00e9quilibrer le travail entre les deux membres de l'\u00e9quipe, nous recommandons de r\u00e9partir les responsabilit\u00e9s selon les domaines suivants. Chaque \u00e9tudiant doit prendre en charge une partie technique et une partie contenu/documentation.</p>"},{"location":"evaluation/grille-repartition-taches/#repartition-suggeree-des-responsabilites","title":"R\u00e9partition sugg\u00e9r\u00e9e des responsabilit\u00e9s","text":""},{"location":"evaluation/grille-repartition-taches/#etudiant-1","title":"\u00c9tudiant 1","text":"<p>Responsabilit\u00e9s techniques : - Conception de l'architecture globale du chatbot - D\u00e9veloppement de la logique de traitement des requ\u00eates - Int\u00e9gration technique avec l'API Mistral AI - Tests d'int\u00e9gration</p> <p>Responsabilit\u00e9s de contenu : - Structuration de la base de connaissances sur le Deep Learning - Organisation des concepts en niveaux de difficult\u00e9 - Validation de l'exactitude des informations techniques</p>"},{"location":"evaluation/grille-repartition-taches/#etudiant-2","title":"\u00c9tudiant 2","text":"<p>Responsabilit\u00e9s techniques : - Conception de l'interface conversationnelle - D\u00e9veloppement de l'interface utilisateur - Gestion des flux de conversation - Tests utilisateurs</p> <p>Responsabilit\u00e9s de contenu : - Recherche et r\u00e9daction des contenus p\u00e9dagogiques - Cr\u00e9ation des exemples et illustrations - Pr\u00e9paration de la documentation technique et du guide utilisateur</p>"},{"location":"evaluation/grille-repartition-taches/#planification-des-taches-par-seance","title":"Planification des t\u00e2ches par s\u00e9ance","text":""},{"location":"evaluation/grille-repartition-taches/#a-lissue-de-la-seance-2","title":"\u00c0 l'issue de la s\u00e9ance 2","text":"T\u00e2che Responsable Deadline Statut Document d'architecture initial Premi\u00e8re version de la structure de la base de connaissances Prototype d'interface minimaliste Plan de projet d\u00e9taill\u00e9"},{"location":"evaluation/grille-repartition-taches/#a-lissue-de-la-seance-3","title":"\u00c0 l'issue de la s\u00e9ance 3","text":"T\u00e2che Responsable Deadline Statut Int\u00e9gration initiale avec l'API Mistral Base de connaissances niveau 1 et 2 Interface conversationnelle fonctionnelle Documentation technique (version pr\u00e9liminaire)"},{"location":"evaluation/grille-repartition-taches/#pour-la-seance-4-finalisation","title":"Pour la s\u00e9ance 4 (finalisation)","text":"T\u00e2che Responsable Deadline Statut Chatbot complet et fonctionnel Base de connaissances compl\u00e8te Interface utilisateur finalis\u00e9e Documentation et guide utilisateur Pr\u00e9sentation du projet"},{"location":"evaluation/grille-repartition-taches/#suivi-des-reunions-dequipe","title":"Suivi des r\u00e9unions d'\u00e9quipe","text":"Date Dur\u00e9e Participants Sujets abord\u00e9s D\u00e9cisions prises Prochaines actions <p>Planifiez au moins une r\u00e9union d'\u00e9quipe entre chaque s\u00e9ance</p>"},{"location":"evaluation/grille-repartition-taches/#gestion-des-risques","title":"Gestion des risques","text":"<p>Identifiez les principaux risques pour votre projet et pr\u00e9voyez des strat\u00e9gies d'att\u00e9nuation :</p> Risque Probabilit\u00e9 (1-5) Impact (1-5) Strat\u00e9gie d'att\u00e9nuation Responsable Difficult\u00e9s d'int\u00e9gration avec l'API Mistral Probl\u00e8mes de coh\u00e9rence dans la base de connaissances D\u00e9passement des d\u00e9lais Conflits techniques ou de conception"},{"location":"evaluation/grille-repartition-taches/#outils-de-collaboration","title":"Outils de collaboration","text":"<p>Listez les outils que vous utiliserez pour la collaboration d'\u00e9quipe :</p> <ul> <li>Gestion de code : ___ (ex: GitHub, GitLab)</li> <li>Communication : ___ (ex: Discord, Slack)</li> <li>Partage de documents : ___ (ex: Google Drive, OneDrive)</li> <li>Suivi de projet : ___ (ex: Trello, GitHub Projects)</li> </ul>"},{"location":"evaluation/grille-repartition-taches/#engagement-de-lequipe","title":"Engagement de l'\u00e9quipe","text":"<p>En tant que membres de l'\u00e9quipe, nous nous engageons \u00e0 : - Respecter les d\u00e9lais et les responsabilit\u00e9s assign\u00e9es - Communiquer r\u00e9guli\u00e8rement sur l'avancement de nos t\u00e2ches - Demander de l'aide si nous rencontrons des difficult\u00e9s - Contribuer activement \u00e0 la r\u00e9ussite collective du projet - Documenter notre travail pour faciliter l'int\u00e9gration</p> <p>Signatures des membres de l'\u00e9quipe :</p> <p>__ __</p>"},{"location":"evaluation/grille-repartition-taches/#evaluation-de-la-repartition-des-taches","title":"\u00c9valuation de la r\u00e9partition des t\u00e2ches","text":"<p>Cette grille sera utilis\u00e9e dans l'\u00e9valuation finale du projet, dans la composante \"Projet final - Processus\" (15% de la note finale). Les crit\u00e8res suivants seront consid\u00e9r\u00e9s :</p> <ul> <li>\u00c9quilibre dans la r\u00e9partition des responsabilit\u00e9s</li> <li>Ad\u00e9quation entre les comp\u00e9tences et les r\u00f4les assign\u00e9s</li> <li>Respect des engagements pris</li> <li>Qualit\u00e9 de la collaboration et de la communication</li> <li>Capacit\u00e9 d'adaptation face aux difficult\u00e9s rencontr\u00e9es</li> </ul> <p>Consultez la grille d\u00e9taill\u00e9e d'\u00e9valuation pour plus d'informations sur les autres crit\u00e8res d'\u00e9valuation du projet.</p>"},{"location":"ressources/guide-etudiant/","title":"Guide d'utilisation des ressources - Formation Deep Learning","text":""},{"location":"ressources/guide-etudiant/#bienvenue-dans-votre-formation-deep-learning","title":"Bienvenue dans votre formation Deep Learning !","text":"<p>Ce guide vous explique comment acc\u00e9der et utiliser les diff\u00e9rentes ressources du cours.</p>"},{"location":"ressources/guide-etudiant/#1-acces-aux-notebooks-jupyter","title":"1. Acc\u00e8s aux notebooks Jupyter","text":""},{"location":"ressources/guide-etudiant/#quest-ce-quun-notebook-jupyter","title":"Qu'est-ce qu'un notebook Jupyter ?","text":"<p>Un notebook Jupyter est un document interactif qui vous permet d'ex\u00e9cuter du code Python directement dans votre navigateur, tout en incluant du texte explicatif, des images et des visualisations. C'est l'outil id\u00e9al pour apprendre le Deep Learning de fa\u00e7on pratique.</p>"},{"location":"ressources/guide-etudiant/#comment-acceder-aux-notebooks-du-cours","title":"Comment acc\u00e9der aux notebooks du cours","text":"<p>Nous utilisons Google Colab, qui vous permet d'ex\u00e9cuter des notebooks Jupyter dans le cloud, sans aucune installation sur votre ordinateur. Vous avez simplement besoin d'un compte Google.</p> <p>Pour acc\u00e9der \u00e0 chaque notebook : 1. Cliquez sur le badge \"Open in Colab\" ou le lien correspondant au notebook 2. Le notebook s'ouvrira dans Google Colab 3. Si demand\u00e9, connectez-vous avec votre compte Google</p>"},{"location":"ressources/guide-etudiant/#enregistrer-votre-travail","title":"Enregistrer votre travail","text":"<p>Important : Les notebooks s'ouvrent en mode lecture seule. Pour sauvegarder votre travail : 1. Allez dans le menu \"Fichier\" &gt; \"Enregistrer une copie dans Drive\" 2. Une copie personnelle sera cr\u00e9\u00e9e dans votre Google Drive 3. Travaillez d\u00e9sormais sur cette copie</p>"},{"location":"ressources/guide-etudiant/#liste-des-notebooks-disponibles","title":"Liste des notebooks disponibles","text":"Notebook Description Lien direct Hello World du Deep Learning Premier r\u00e9seau de neurones sur MNIST Machine Learning classique Classification avec Random Forest Deep Learning Classification avec r\u00e9seau de neurones Anatomie d'un r\u00e9seau Exploration interactive d'un r\u00e9seau Template du mini-projet Base pour le challenge d'am\u00e9lioration"},{"location":"ressources/guide-etudiant/#2-utilisation-des-notebooks","title":"2. Utilisation des notebooks","text":""},{"location":"ressources/guide-etudiant/#executer-les-cellules","title":"Ex\u00e9cuter les cellules","text":"<ul> <li>Pour ex\u00e9cuter une cellule de code, cliquez sur le bouton \u25b6\ufe0f \u00e0 gauche de la cellule ou appuyez sur <code>Ctrl+Entr\u00e9e</code></li> <li>Ex\u00e9cutez les cellules dans l'ordre, de haut en bas</li> <li>Attendez qu'une cellule ait termin\u00e9 son ex\u00e9cution avant de passer \u00e0 la suivante (le symbole \u25cf devient \u2713)</li> </ul>"},{"location":"ressources/guide-etudiant/#types-de-cellules","title":"Types de cellules","text":"<ul> <li>Cellules de code : Contiennent du code Python ex\u00e9cutable</li> <li>Cellules de texte : Contiennent des explications et des instructions</li> </ul>"},{"location":"ressources/guide-etudiant/#conseils-pratiques","title":"Conseils pratiques","text":"<ul> <li>Red\u00e9marrer le runtime : Si vous rencontrez des erreurs, essayez de red\u00e9marrer le runtime (Menu \"Runtime\" &gt; \"Restart runtime\")</li> <li>RAM limit\u00e9e : Si vous recevez des erreurs de m\u00e9moire, fermez les autres onglets Colab</li> <li>D\u00e9connexion : Google Colab peut se d\u00e9connecter apr\u00e8s inactivit\u00e9, sauvegardez r\u00e9guli\u00e8rement</li> </ul>"},{"location":"ressources/guide-etudiant/#3-documents-a-completer","title":"3. Documents \u00e0 compl\u00e9ter","text":""},{"location":"ressources/guide-etudiant/#telechargement-des-fiches","title":"T\u00e9l\u00e9chargement des fiches","text":"<p>Pour chaque s\u00e9ance, t\u00e9l\u00e9chargez les fiches d'observation et autres documents \u00e0 compl\u00e9ter : 1. Cliquez sur les liens fournis dans la page de la s\u00e9ance 2. Choisissez entre la version PDF (pour impression) ou Word/ODT (pour \u00e9dition \u00e9lectronique)</p>"},{"location":"ressources/guide-etudiant/#soumission-des-travaux","title":"Soumission des travaux","text":"<p>Pour soumettre vos travaux compl\u00e9t\u00e9s : 1. Nommez vos fichiers avec votre nom et le num\u00e9ro de s\u00e9ance (ex: \"Dupont_Seance1_Fiche.docx\") 2. D\u00e9posez-les sur la plateforme de cours en ligne ou envoyez-les par email selon les instructions de votre formateur 3. Pour les notebooks, partagez l'URL de votre copie dans Google Drive ou exportez-les au format .ipynb</p>"},{"location":"ressources/guide-etudiant/#4-resolution-des-problemes-courants","title":"4. R\u00e9solution des probl\u00e8mes courants","text":"Probl\u00e8me Solution Le notebook ne se charge pas V\u00e9rifiez votre connexion internet ou r\u00e9essayez dans quelques minutes Erreur \"CUDA out of memory\" Allez dans \"Runtime\" &gt; \"Change runtime type\" et s\u00e9lectionnez \"None\" pour GPU Modules manquants Ex\u00e9cutez <code>!pip install nom-du-module</code> dans une cellule Acc\u00e8s refus\u00e9 Assurez-vous d'\u00eatre connect\u00e9 \u00e0 votre compte Google"},{"location":"ressources/guide-etudiant/#5-ressources-complementaires","title":"5. Ressources compl\u00e9mentaires","text":"<ul> <li>Documentation TensorFlow</li> <li>Documentation Keras</li> <li>Tutoriels Google Colab</li> </ul> <p>Pour toute question, n'h\u00e9sitez pas \u00e0 contacter votre formateur !</p>"},{"location":"ressources/notebooks/anatomie-reseau/","title":"Anatomie reseau","text":"In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! <pre># Anatomie d'un r\u00e9seau de neurones\n# Exploration interactive du fonctionnement interne d'un r\u00e9seau de neurones\n\n# Partie 1: Configuration initiale\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom google.colab import output\noutput.enable_custom_widget_manager()\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output\nfrom matplotlib.colors import LinearSegmentedColormap\n\nprint(\"Configuration termin\u00e9e!\")\n\n# Partie 2: Exploration d'un neurone unique\nprint(\"\\n--- Exploration d'un neurone unique ---\")\nprint(\"Dans cette partie, nous allons observer le fonctionnement d'un neurone artificiel.\")\n\n# Fonction pour calculer la sortie d'un neurone\ndef neuron_output(x1, x2, w1, w2, b, activation=\"relu\"):\n    # Calcul de la somme pond\u00e9r\u00e9e\n    z = x1 * w1 + x2 * w2 + b\n    \n    # Application de la fonction d'activation\n    if activation == \"relu\":\n        a = max(0, z)\n    elif activation == \"sigmoid\":\n        a = 1 / (1 + np.exp(-z))\n    elif activation == \"tanh\":\n        a = np.tanh(z)\n    else:\n        a = z  # Lin\u00e9aire\n    \n    return z, a\n\n# Fonction pour visualiser un neurone\ndef visualize_neuron(x1, x2, w1, w2, b, activation=\"relu\"):\n    # Calculer la sortie\n    z, a = neuron_output(x1, x2, w1, w2, b, activation)\n    \n    # Cr\u00e9er la figure\n    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n    \n    # 1. Repr\u00e9sentation du neurone\n    ax = axes[0]\n    ax.set_xlim(-0.5, 2.5)\n    ax.set_ylim(-0.5, 2.5)\n    \n    # Dessiner le neurone\n    circle = plt.Circle((1, 1), 0.4, fill=True, color='lightblue', alpha=0.7)\n    ax.add_artist(circle)\n    \n    # Dessiner les entr\u00e9es\n    ax.plot(0, 0.7, 'ro', markersize=10)\n    ax.plot(0, 1.3, 'ro', markersize=10)\n    \n    # Dessiner la sortie\n    ax.plot(2, 1, 'go', markersize=10)\n    \n    # Ajouter les connexions\n    ax.arrow(0, 0.7, 0.6, 0.1, head_width=0.1, head_length=0.1, fc='black', ec='black', linewidth=2)\n    ax.arrow(0, 1.3, 0.6, -0.1, head_width=0.1, head_length=0.1, fc='black', ec='black', linewidth=2)\n    ax.arrow(1.4, 1, 0.6, 0, head_width=0.1, head_length=0.1, fc='black', ec='black', linewidth=2)\n    \n    # Ajouter les textes\n    ax.text(-0.1, 0.7, f\"x\u2081 = {x1:.2f}\", fontsize=12, ha='right')\n    ax.text(-0.1, 1.3, f\"x\u2082 = {x2:.2f}\", fontsize=12, ha='right')\n    ax.text(1, 1, f\"z = {z:.2f}\\na = {a:.2f}\", fontsize=12, ha='center')\n    ax.text(0.5, 0.95, f\"w\u2081 = {w1:.2f}\", fontsize=10, rotation=15)\n    ax.text(0.5, 1.15, f\"w\u2082 = {w2:.2f}\", fontsize=10, rotation=-15)\n    ax.text(2.1, 1, f\"Sortie = {a:.2f}\", fontsize=12, ha='left')\n    ax.text(1, 0.5, f\"Biais = {b:.2f}\", fontsize=10)\n    \n    ax.set_title(\"Neurone artificiel\", fontsize=14)\n    ax.set_axis_off()\n    \n    # 2. Repr\u00e9sentation de la fonction d'activation\n    ax = axes[1]\n    x = np.linspace(-5, 5, 100)\n    \n    if activation == \"relu\":\n        y = np.maximum(0, x)\n        title = \"Fonction d'activation: ReLU\"\n    elif activation == \"sigmoid\":\n        y = 1 / (1 + np.exp(-x))\n        title = \"Fonction d'activation: Sigmoid\"\n    elif activation == \"tanh\":\n        y = np.tanh(x)\n        title = \"Fonction d'activation: Tanh\"\n    else:\n        y = x\n        title = \"Fonction d'activation: Lin\u00e9aire\"\n    \n    ax.plot(x, y, 'b-', linewidth=2)\n    ax.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n    ax.axvline(x=0, color='k', linestyle='-', alpha=0.3)\n    \n    # Marquer le point correspondant \u00e0 z\n    ax.plot(z, a, 'ro', markersize=8)\n    ax.plot([z, z], [0, a], 'r--', alpha=0.5)\n    ax.plot([0, z], [a, a], 'r--', alpha=0.5)\n    \n    ax.set_xlim(-5, 5)\n    ax.set_ylim(-1.5, 1.5)\n    ax.set_xlabel(\"z (somme pond\u00e9r\u00e9e)\")\n    ax.set_ylabel(\"a (activation)\")\n    ax.set_title(title, fontsize=14)\n    ax.grid(True, alpha=0.3)\n    \n    # 3. Visualisation de la fronti\u00e8re de d\u00e9cision\n    ax = axes[2]\n    \n    # Cr\u00e9er des points pour former une grille\n    grid_size = 20\n    x1_values = np.linspace(0, 1, grid_size)\n    x2_values = np.linspace(0, 1, grid_size)\n    x1_grid, x2_grid = np.meshgrid(x1_values, x2_values)\n    \n    # Calculer la sortie pour chaque point de la grille\n    z_grid = x1_grid * w1 + x2_grid * w2 + b\n    \n    if activation == \"relu\":\n        a_grid = np.maximum(0, z_grid)\n    elif activation == \"sigmoid\":\n        a_grid = 1 / (1 + np.exp(-z_grid))\n    elif activation == \"tanh\":\n        a_grid = np.tanh(z_grid)\n    else:\n        a_grid = z_grid\n    \n    # Cr\u00e9er une carte de couleur\n    cmap = plt.get_cmap('coolwarm')\n    \n    # Tracer la heatmap\n    im = ax.imshow(a_grid, origin='lower', extent=[0, 1, 0, 1], \n                   cmap=cmap, vmin=0, vmax=1)\n    plt.colorbar(im, ax=ax, label=\"Activation\")\n    \n    # Ajouter le point actuel\n    ax.plot(x1, x2, 'ko', markersize=8)\n    \n    # Tracer la fronti\u00e8re de d\u00e9cision (a = 0.5)\n    if activation in [\"sigmoid\", \"tanh\"]:\n        threshold = 0.5\n        CS = ax.contour(x1_grid, x2_grid, a_grid, levels=[threshold], \n                         colors='k', linestyles='--')\n        ax.clabel(CS, inline=True, fontsize=10, fmt={threshold: \"a = 0.5\"})\n    \n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_xlabel(\"x\u2081\")\n    ax.set_ylabel(\"x\u2082\")\n    ax.set_title(\"Carte d'activation\", fontsize=14)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return a\n\n# Cr\u00e9er des widgets interactifs pour le neurone\nw1_slider = widgets.FloatSlider(value=1.0, min=-3.0, max=3.0, step=0.1, description='Poids w\u2081:')\nw2_slider = widgets.FloatSlider(value=1.0, min=-3.0, max=3.0, step=0.1, description='Poids w\u2082:')\nb_slider = widgets.FloatSlider(value=0.0, min=-3.0, max=3.0, step=0.1, description='Biais:')\nx1_slider = widgets.FloatSlider(value=0.5, min=0.0, max=1.0, step=0.05, description='Entr\u00e9e x\u2081:')\nx2_slider = widgets.FloatSlider(value=0.5, min=0.0, max=1.0, step=0.05, description='Entr\u00e9e x\u2082:')\nactivation_dropdown = widgets.Dropdown(\n    options=['relu', 'sigmoid', 'tanh', 'linear'],\n    value='relu',\n    description='Activation:'\n)\n\n# Fonction pour mettre \u00e0 jour la visualisation\ndef update_neuron_visualization(w1, w2, b, x1, x2, activation):\n    clear_output(wait=True)\n    output = visualize_neuron(x1, x2, w1, w2, b, activation)\n    print(f\"Sortie du neurone: {output:.4f}\")\n    \n    # Expliquer le calcul\n    z = x1 * w1 + x2 * w2 + b\n    print(f\"\\nCalcul d\u00e9taill\u00e9:\")\n    print(f\"z = (x\u2081 \u00d7 w\u2081) + (x\u2082 \u00d7 w\u2082) + b\")\n    print(f\"z = ({x1:.2f} \u00d7 {w1:.2f}) + ({x2:.2f} \u00d7 {w2:.2f}) + {b:.2f}\")\n    print(f\"z = {x1*w1:.2f} + {x2*w2:.2f} + {b:.2f}\")\n    print(f\"z = {z:.2f}\")\n    \n    if activation == \"relu\":\n        print(f\"a = ReLU(z) = max(0, z) = max(0, {z:.2f}) = {max(0, z):.2f}\")\n    elif activation == \"sigmoid\":\n        sig_z = 1 / (1 + np.exp(-z))\n        print(f\"a = Sigmoid(z) = 1 / (1 + e^(-z)) = 1 / (1 + e^(-{z:.2f})) = {sig_z:.2f}\")\n    elif activation == \"tanh\":\n        tanh_z = np.tanh(z)\n        print(f\"a = tanh(z) = tanh({z:.2f}) = {tanh_z:.2f}\")\n    else:\n        print(f\"a = z = {z:.2f}\")  # Lin\u00e9aire\n\n# Interface interactive pour le neurone\nneuron_output = widgets.interactive_output(\n    update_neuron_visualization,\n    {'w1': w1_slider, 'w2': w2_slider, 'b': b_slider, \n     'x1': x1_slider, 'x2': x2_slider, 'activation': activation_dropdown}\n)\n\n# Afficher les widgets\nprint(\"Utilisez les contr\u00f4les ci-dessous pour modifier les propri\u00e9t\u00e9s du neurone:\")\ndisplay(widgets.VBox([\n    widgets.HBox([x1_slider, x2_slider]),\n    widgets.HBox([w1_slider, w2_slider]),\n    widgets.HBox([b_slider, activation_dropdown])\n]))\ndisplay(neuron_output)\n\n# Partie 3: Exploration d'un r\u00e9seau simple\nprint(\"\\n--- De l'unique au r\u00e9seau ---\")\nprint(\"Dans cette partie, nous allons explorer un petit r\u00e9seau de neurones.\")\n\n# Fonction pour cr\u00e9er et visualiser un r\u00e9seau simple\ndef create_simple_network(hidden_units=3, activation='relu'):\n    # Cr\u00e9er un mod\u00e8le s\u00e9quentiel\n    model = Sequential([\n        Dense(hidden_units, activation=activation, input_shape=(2,)),\n        Dense(1, activation='sigmoid')\n    ])\n    \n    # Compiler le mod\u00e8le (bien que nous ne l'entra\u00eenerons pas)\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return model\n\n# Fonction pour visualiser un r\u00e9seau simple\ndef visualize_network(inputs, weights1=None, biases1=None, weights2=None, biases2=None, hidden_units=3, activation='relu'):\n    # Cr\u00e9er le mod\u00e8le si non fourni\n    model = create_simple_network(hidden_units, activation)\n    \n    # Si des poids sont fournis, les appliquer\n    if weights1 is not None and biases1 is not None and weights2 is not None and biases2 is not None:\n        model.layers[0].set_weights([weights1, biases1])\n        model.layers[1].set_weights([weights2, biases2])\n    \n    # Convertir les entr\u00e9es pour pr\u00e9diction\n    x = np.array([inputs])\n    \n    # Obtenir les activations interm\u00e9diaires\n    intermediate_layer_model = tf.keras.Model(inputs=model.input,\n                                             outputs=model.layers[0].output)\n    intermediate_activations = intermediate_layer_model.predict(x)[0]\n    \n    # Obtenir les activations de sortie\n    output_activation = model.predict(x)[0][0]\n    \n    # Extraire les poids et biais\n    weights1, biases1 = model.layers[0].get_weights()\n    weights2, biases2 = model.layers[1].get_weights()\n    \n    # Cr\u00e9er la figure pour visualiser le r\u00e9seau\n    plt.figure(figsize=(12, 8))\n    \n    # D\u00e9finir les positions des neurones\n    input_layer_y = np.array([0.2, 0.8])\n    hidden_layer_y = np.linspace(0.1, 0.9, hidden_units)\n    output_layer_y = np.array([0.5])\n    \n    input_layer_x = 0.1\n    hidden_layer_x = 0.5\n    output_layer_x = 0.9\n    \n    # Dessiner les neurones d'entr\u00e9e\n    for i, y in enumerate(input_layer_y):\n        plt.scatter(input_layer_x, y, s=200, c='blue', alpha=0.7)\n        plt.text(input_layer_x, y, f\"x{i+1}={inputs[i]:.2f}\", fontsize=12, ha='center', va='center', color='white')\n    \n    # Dessiner les neurones cach\u00e9s\n    for i, y in enumerate(hidden_layer_y):\n        # Calculer la somme pond\u00e9r\u00e9e\n        z = np.dot(inputs, weights1[:, i]) + biases1[i]\n        \n        # Appliquer l'activation\n        if activation == 'relu':\n            a = max(0, z)\n        elif activation == 'sigmoid':\n            a = 1 / (1 + np.exp(-z))\n        elif activation == 'tanh':\n            a = np.tanh(z)\n        else:\n            a = z\n        \n        # Couleur bas\u00e9e sur l'activation\n        color = plt.cm.viridis(a)\n        \n        plt.scatter(hidden_layer_x, y, s=200, c=[color], alpha=0.7)\n        plt.text(hidden_layer_x, y, f\"{a:.2f}\", fontsize=12, ha='center', va='center', color='white')\n    \n    # Dessiner le neurone de sortie\n    plt.scatter(output_layer_x, output_layer_y, s=200, c='red', alpha=0.7)\n    plt.text(output_layer_x, output_layer_y, f\"{output_activation:.2f}\", fontsize=12, ha='center', va='center', color='white')\n    \n    # Dessiner les connexions entre couches d'entr\u00e9e et cach\u00e9e\n    for i, y_in in enumerate(input_layer_y):\n        for j, y_hid in enumerate(hidden_layer_y):\n            # Couleur et \u00e9paisseur bas\u00e9es sur le poids\n            weight = weights1[i, j]\n            width = abs(weight) * 3\n            color = 'red' if weight &lt; 0 else 'green'\n            alpha = min(abs(weight), 1.0)\n            \n            plt.plot([input_layer_x, hidden_layer_x], [y_in, y_hid], \n                    c=color, linewidth=width, alpha=alpha)\n    \n    # Dessiner les connexions entre couche cach\u00e9e et sortie\n    for i, y_hid in enumerate(hidden_layer_y):\n        # Couleur et \u00e9paisseur bas\u00e9es sur le poids\n        weight = weights2[i, 0]\n        width = abs(weight) * 3\n        color = 'red' if weight &lt; 0 else 'green'\n        alpha = min(abs(weight), 1.0)\n        \n        plt.plot([hidden_layer_x, output_layer_x], [y_hid, output_layer_y], \n                c=color, linewidth=width, alpha=alpha)\n    \n    # \u00c9tiquettes\n    plt.text(input_layer_x, 0.03, \"Couche d'entr\u00e9e\", fontsize=14, ha='center')\n    plt.text(hidden_layer_x, 0.03, \"Couche cach\u00e9e\", fontsize=14, ha='center')\n    plt.text(output_layer_x, 0.03, \"Couche de sortie\", fontsize=14, ha='center')\n    \n    # Enlever les axes\n    plt.axis('off')\n    plt.title(f\"R\u00e9seau de neurones - Activation cach\u00e9e: {activation}\", fontsize=16)\n    plt.tight_layout()\n    plt.show()\n    \n    # Afficher les calculs d\u00e9taill\u00e9s\n    print(\"\\nCalculs d\u00e9taill\u00e9s pour chaque neurone de la couche cach\u00e9e:\")\n    for i in range(hidden_units):\n        z = np.dot(inputs, weights1[:, i]) + biases1[i]\n        print(f\"\\nNeurone cach\u00e9 {i+1}:\")\n        print(f\"z = (x\u2081 \u00d7 w\u2081,{i+1}) + (x\u2082 \u00d7 w\u2082,{i+1}) + b{i+1}\")\n        print(f\"z = ({inputs[0]:.2f} \u00d7 {weights1[0, i]:.2f}) + ({inputs[1]:.2f} \u00d7 {weights1[1, i]:.2f}) + {biases1[i]:.2f}\")\n        print(f\"z = {inputs[0] * weights1[0, i]:.2f} + {inputs[1] * weights1[1, i]:.2f} + {biases1[i]:.2f} = {z:.2f}\")\n        \n        if activation == 'relu':\n            a = max(0, z)\n            print(f\"a = ReLU(z) = max(0, {z:.2f}) = {a:.2f}\")\n        elif activation == 'sigmoid':\n            a = 1 / (1 + np.exp(-z))\n            print(f\"a = Sigmoid(z) = 1 / (1 + e^(-{z:.2f})) = {a:.2f}\")\n        elif activation == 'tanh':\n            a = np.tanh(z)\n            print(f\"a = tanh(z) = tanh({z:.2f}) = {a:.2f}\")\n        else:\n            a = z\n            print(f\"a = z = {z:.2f}\")\n    \n    print(\"\\nCalcul pour le neurone de sortie:\")\n    z_out = np.dot(intermediate_activations, weights2[:, 0]) + biases2[0]\n    print(f\"z = \u03a3(a_cach\u00e9 \u00d7 w_sortie) + b_sortie = {z_out:.2f}\")\n    print(f\"sortie = Sigmoid(z) = 1 / (1 + e^(-{z_out:.2f})) = {output_activation:.2f}\")\n    \n    return model, weights1, biases1, weights2, biases2\n\n# Fonction pour g\u00e9n\u00e9rer des poids al\u00e9atoires\ndef generate_random_weights(hidden_units=3):\n    # G\u00e9n\u00e9rer des poids al\u00e9atoires pour la premi\u00e8re couche\n    weights1 = np.random.normal(0, 1, (2, hidden_units))\n    biases1 = np.random.normal(0, 1, hidden_units)\n    \n    # G\u00e9n\u00e9rer des poids al\u00e9atoires pour la couche de sortie\n    weights2 = np.random.normal(0, 1, (hidden_units, 1))\n    biases2 = np.random.normal(0, 1, 1)\n    \n    return weights1, biases1, weights2, biases2\n\n# Cr\u00e9er des widgets interactifs pour le r\u00e9seau\nx1_net_slider = widgets.FloatSlider(value=0.5, min=0.0, max=1.0, step=0.05, description='Entr\u00e9e x\u2081:')\nx2_net_slider = widgets.FloatSlider(value=0.5, min=0.0, max=1.0, step=0.05, description='Entr\u00e9e x\u2082:')\nhidden_units_slider = widgets.IntSlider(value=3, min=1, max=5, description='Neurones cach\u00e9s:')\nactivation_net_dropdown = widgets.Dropdown(\n    options=['relu', 'sigmoid', 'tanh', 'linear'],\n    value='relu',\n    description='Activation:'\n)\nrandom_button = widgets.Button(description=\"Poids al\u00e9atoires\")\n\n# Variables pour stocker les poids courants\ncurrent_weights1, current_biases1, current_weights2, current_biases2 = generate_random_weights()\n\n# Fonction pour visualiser le r\u00e9seau\ndef update_network_visualization(x1, x2, hidden_units, activation):\n    global current_weights1, current_biases1, current_weights2, current_biases2\n    \n    # Ajuster les dimensions des poids si n\u00e9cessaire\n    if current_weights1.shape[1] != hidden_units:\n        current_weights1, current_biases1, current_weights2, current_biases2 = generate_random_weights(hidden_units)\n    \n    # Visualiser le r\u00e9seau\n    inputs = np.array([x1, x2])\n    _, w1, b1, w2, b2 = visualize_network(\n        inputs, current_weights1, current_biases1, current_weights2, current_biases2, \n        hidden_units, activation\n    )\n    \n    # Mettre \u00e0 jour les poids courants\n    current_weights1, current_biases1 = w1, b1\n    current_weights2, current_biases2 = w2, b2\n\n# Fonction pour g\u00e9n\u00e9rer de nouveaux poids al\u00e9atoires\ndef regenerate_weights(b):\n    global current_weights1, current_biases1, current_weights2, current_biases2\n    current_weights1, current_biases1, current_weights2, current_biases2 = generate_random_weights(\n        hidden_units_slider.value\n    )\n    # Mettre \u00e0 jour la visualisation\n    update_network_visualization(\n        x1_net_slider.value, x2_net_slider.value,\n        hidden_units_slider.value, activation_net_dropdown.value\n    )\n\n# Associer la fonction au bouton\nrandom_button.on_click(regenerate_weights)\n\n# Interface interactive pour le r\u00e9seau\nnetwork_output = widgets.interactive_output(\n    update_network_visualization,\n    {'x1': x1_net_slider, 'x2': x2_net_slider, \n     'hidden_units': hidden_units_slider, 'activation': activation_net_dropdown}\n)\n\n# Afficher les widgets pour le r\u00e9seau\nprint(\"\\nExplorez le comportement d'un r\u00e9seau simple:\")\ndisplay(widgets.VBox([\n    widgets.HBox([x1_net_slider, x2_net_slider]),\n    widgets.HBox([hidden_units_slider, activation_net_dropdown]),\n    random_button\n]))\ndisplay(network_output)\n\n# Partie 4: Visualisation de l'entra\u00eenement\nprint(\"\\n--- Visualisation de l'entra\u00eenement ---\")\nprint(\"Dans cette partie, nous allons observer l'\u00e9volution des poids pendant l'entra\u00eenement.\")\n\n# G\u00e9n\u00e9rer des donn\u00e9es XOR\ndef generate_xor_data(n_samples=100):\n    X = np.random.rand(n_samples, 2)\n    y = np.logical_xor(X[:, 0] &gt; 0.5, X[:, 1] &gt; 0.5).astype(np.float32)\n    return X, y\n\n# Fonction pour visualiser l'\u00e9volution de l'apprentissage\ndef visualize_training_animation(learning_rate=0.1, epochs=50, hidden_units=4):\n    # G\u00e9n\u00e9rer des donn\u00e9es\n    X_train, y_train = generate_xor_data(200)\n    \n    # Cr\u00e9er un mod\u00e8le\n    model = Sequential([\n        Dense(hidden_units, activation='relu', input_shape=(2,)),\n        Dense(1, activation='sigmoid')\n    ])\n    \n    # Compiler avec un optimiseur personnalis\u00e9 pour suivre l'\u00e9volution des poids\n    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n    \n    # Extraire les poids initiaux\n    weights_history = [model.get_weights()]\n    \n    # Fonction pour collecter les poids apr\u00e8s chaque \u00e9poque\n    class WeightHistory(tf.keras.callbacks.Callback):\n        def on_epoch_end(self, epoch, logs=None):\n            weights_history.append(self.model.get_weights())\n    \n    # Entra\u00eener le mod\u00e8le\n    history = model.fit(\n        X_train, y_train,\n        epochs=epochs,\n        batch_size=32,\n        verbose=0,\n        callbacks=[WeightHistory()]\n    )\n    \n    # Cr\u00e9er une figure pour l'animation\n    plt.figure(figsize=(15, 6))\n    \n    # Visualiser la fronti\u00e8re de d\u00e9cision\n    plt.subplot(1, 2, 1)\n    \n    # Cr\u00e9er une grille pour visualiser la fronti\u00e8re de d\u00e9cision\n    h = 0.01\n    x_min, x_max = 0, 1\n    y_min, y_max = 0, 1\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n    grid_points = np.c_[xx.ravel(), yy.ravel()]\n    \n    # Pr\u00e9dire sur la grille avec le mod\u00e8le final\n    Z = model.predict(grid_points)\n    Z = Z.reshape(xx.shape)\n    \n    # Tracer la fronti\u00e8re de d\u00e9cision finale\n    plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.coolwarm)\n    \n    # Tracer les points d'entra\u00eenement\n    scatter = plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, edgecolors='k', cmap=plt.cm.coolwarm)\n    \n    plt.title('Fronti\u00e8re de d\u00e9cision finale')\n    plt.xlabel('x\u2081')\n    plt.ylabel('x\u2082')\n    plt.legend(*scatter.legend_elements(), title=\"Classes\")\n    \n    # Visualiser l'\u00e9volution de la perte et de la pr\u00e9cision\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['loss'], label='Perte')\n    plt.plot(history.history['accuracy'], label='Pr\u00e9cision')\n    plt.title('\u00c9volution de l\\'entra\u00eenement')\n    plt.xlabel('\u00c9poque')\n    plt.ylabel('Valeur')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Afficher des d\u00e9tails sur l'entra\u00eenement\n    print(f\"Apprentissage termin\u00e9 apr\u00e8s {epochs} \u00e9poques:\")\n    print(f\"- Perte finale: {history.history['loss'][-1]:.4f}\")\n    print(f\"- Pr\u00e9cision finale: {history.history['accuracy'][-1]*100:.2f}%\")\n    \n    # Afficher l'\u00e9volution des poids\n    print(\"\\n\u00c9volution des poids:\")\n    \n    # Cr\u00e9er un slider pour parcourir les \u00e9poques\n    def show_weights_at_epoch(epoch):\n        weights = weights_history[epoch]\n        \n        plt.figure(figsize=(14, 6))\n        \n        # Visualiser les poids de la premi\u00e8re couche\n        plt.subplot(1, 2, 1)\n        w1 = weights[0]\n        plt.imshow(w1, aspect='auto', cmap='coolwarm')\n        plt.colorbar(label='Valeur du poids')\n        plt.title(f'Poids de la couche cach\u00e9e (\u00c9poque {epoch})')\n        plt.xlabel('Neurone cach\u00e9')\n        plt.ylabel('Entr\u00e9e')\n        plt.yticks([0, 1], ['x\u2081', 'x\u2082'])\n        \n        # Visualiser les poids de la couche de sortie\n        plt.subplot(1, 2, 2)\n        w2 = weights[2]\n        plt.bar(range(len(w2)), w2.flatten())\n        plt.title(f'Poids de la couche de sortie (\u00c9poque {epoch})')\n        plt.xlabel('Neurone cach\u00e9')\n        plt.ylabel('Poids vers la sortie')\n        plt.xticks(range(len(w2)))\n        \n        plt.tight_layout()\n        plt.show()\n        \n        # Afficher aussi la fronti\u00e8re de d\u00e9cision \u00e0 cette \u00e9poque\n        model_at_epoch = Sequential([\n            Dense(hidden_units, activation='relu', input_shape=(2,)),\n            Dense(1, activation='sigmoid')\n        ])\n        model_at_epoch.set_weights(weights)\n        \n        # Pr\u00e9dire sur la grille\n        Z = model_at_epoch.predict(grid_points)\n        Z = Z.reshape(xx.shape)\n        \n        plt.figure(figsize=(8, 6))\n        plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.coolwarm)\n        scatter = plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, edgecolors='k', cmap=plt.cm.coolwarm)\n        plt\n</pre> # Anatomie d'un r\u00e9seau de neurones # Exploration interactive du fonctionnement interne d'un r\u00e9seau de neurones  # Partie 1: Configuration initiale import numpy as np import matplotlib.pyplot as plt import tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense from google.colab import output output.enable_custom_widget_manager() import ipywidgets as widgets from IPython.display import display, clear_output from matplotlib.colors import LinearSegmentedColormap  print(\"Configuration termin\u00e9e!\")  # Partie 2: Exploration d'un neurone unique print(\"\\n--- Exploration d'un neurone unique ---\") print(\"Dans cette partie, nous allons observer le fonctionnement d'un neurone artificiel.\")  # Fonction pour calculer la sortie d'un neurone def neuron_output(x1, x2, w1, w2, b, activation=\"relu\"):     # Calcul de la somme pond\u00e9r\u00e9e     z = x1 * w1 + x2 * w2 + b          # Application de la fonction d'activation     if activation == \"relu\":         a = max(0, z)     elif activation == \"sigmoid\":         a = 1 / (1 + np.exp(-z))     elif activation == \"tanh\":         a = np.tanh(z)     else:         a = z  # Lin\u00e9aire          return z, a  # Fonction pour visualiser un neurone def visualize_neuron(x1, x2, w1, w2, b, activation=\"relu\"):     # Calculer la sortie     z, a = neuron_output(x1, x2, w1, w2, b, activation)          # Cr\u00e9er la figure     fig, axes = plt.subplots(1, 3, figsize=(18, 5))          # 1. Repr\u00e9sentation du neurone     ax = axes[0]     ax.set_xlim(-0.5, 2.5)     ax.set_ylim(-0.5, 2.5)          # Dessiner le neurone     circle = plt.Circle((1, 1), 0.4, fill=True, color='lightblue', alpha=0.7)     ax.add_artist(circle)          # Dessiner les entr\u00e9es     ax.plot(0, 0.7, 'ro', markersize=10)     ax.plot(0, 1.3, 'ro', markersize=10)          # Dessiner la sortie     ax.plot(2, 1, 'go', markersize=10)          # Ajouter les connexions     ax.arrow(0, 0.7, 0.6, 0.1, head_width=0.1, head_length=0.1, fc='black', ec='black', linewidth=2)     ax.arrow(0, 1.3, 0.6, -0.1, head_width=0.1, head_length=0.1, fc='black', ec='black', linewidth=2)     ax.arrow(1.4, 1, 0.6, 0, head_width=0.1, head_length=0.1, fc='black', ec='black', linewidth=2)          # Ajouter les textes     ax.text(-0.1, 0.7, f\"x\u2081 = {x1:.2f}\", fontsize=12, ha='right')     ax.text(-0.1, 1.3, f\"x\u2082 = {x2:.2f}\", fontsize=12, ha='right')     ax.text(1, 1, f\"z = {z:.2f}\\na = {a:.2f}\", fontsize=12, ha='center')     ax.text(0.5, 0.95, f\"w\u2081 = {w1:.2f}\", fontsize=10, rotation=15)     ax.text(0.5, 1.15, f\"w\u2082 = {w2:.2f}\", fontsize=10, rotation=-15)     ax.text(2.1, 1, f\"Sortie = {a:.2f}\", fontsize=12, ha='left')     ax.text(1, 0.5, f\"Biais = {b:.2f}\", fontsize=10)          ax.set_title(\"Neurone artificiel\", fontsize=14)     ax.set_axis_off()          # 2. Repr\u00e9sentation de la fonction d'activation     ax = axes[1]     x = np.linspace(-5, 5, 100)          if activation == \"relu\":         y = np.maximum(0, x)         title = \"Fonction d'activation: ReLU\"     elif activation == \"sigmoid\":         y = 1 / (1 + np.exp(-x))         title = \"Fonction d'activation: Sigmoid\"     elif activation == \"tanh\":         y = np.tanh(x)         title = \"Fonction d'activation: Tanh\"     else:         y = x         title = \"Fonction d'activation: Lin\u00e9aire\"          ax.plot(x, y, 'b-', linewidth=2)     ax.axhline(y=0, color='k', linestyle='-', alpha=0.3)     ax.axvline(x=0, color='k', linestyle='-', alpha=0.3)          # Marquer le point correspondant \u00e0 z     ax.plot(z, a, 'ro', markersize=8)     ax.plot([z, z], [0, a], 'r--', alpha=0.5)     ax.plot([0, z], [a, a], 'r--', alpha=0.5)          ax.set_xlim(-5, 5)     ax.set_ylim(-1.5, 1.5)     ax.set_xlabel(\"z (somme pond\u00e9r\u00e9e)\")     ax.set_ylabel(\"a (activation)\")     ax.set_title(title, fontsize=14)     ax.grid(True, alpha=0.3)          # 3. Visualisation de la fronti\u00e8re de d\u00e9cision     ax = axes[2]          # Cr\u00e9er des points pour former une grille     grid_size = 20     x1_values = np.linspace(0, 1, grid_size)     x2_values = np.linspace(0, 1, grid_size)     x1_grid, x2_grid = np.meshgrid(x1_values, x2_values)          # Calculer la sortie pour chaque point de la grille     z_grid = x1_grid * w1 + x2_grid * w2 + b          if activation == \"relu\":         a_grid = np.maximum(0, z_grid)     elif activation == \"sigmoid\":         a_grid = 1 / (1 + np.exp(-z_grid))     elif activation == \"tanh\":         a_grid = np.tanh(z_grid)     else:         a_grid = z_grid          # Cr\u00e9er une carte de couleur     cmap = plt.get_cmap('coolwarm')          # Tracer la heatmap     im = ax.imshow(a_grid, origin='lower', extent=[0, 1, 0, 1],                     cmap=cmap, vmin=0, vmax=1)     plt.colorbar(im, ax=ax, label=\"Activation\")          # Ajouter le point actuel     ax.plot(x1, x2, 'ko', markersize=8)          # Tracer la fronti\u00e8re de d\u00e9cision (a = 0.5)     if activation in [\"sigmoid\", \"tanh\"]:         threshold = 0.5         CS = ax.contour(x1_grid, x2_grid, a_grid, levels=[threshold],                           colors='k', linestyles='--')         ax.clabel(CS, inline=True, fontsize=10, fmt={threshold: \"a = 0.5\"})          ax.set_xlim(0, 1)     ax.set_ylim(0, 1)     ax.set_xlabel(\"x\u2081\")     ax.set_ylabel(\"x\u2082\")     ax.set_title(\"Carte d'activation\", fontsize=14)          plt.tight_layout()     plt.show()          return a  # Cr\u00e9er des widgets interactifs pour le neurone w1_slider = widgets.FloatSlider(value=1.0, min=-3.0, max=3.0, step=0.1, description='Poids w\u2081:') w2_slider = widgets.FloatSlider(value=1.0, min=-3.0, max=3.0, step=0.1, description='Poids w\u2082:') b_slider = widgets.FloatSlider(value=0.0, min=-3.0, max=3.0, step=0.1, description='Biais:') x1_slider = widgets.FloatSlider(value=0.5, min=0.0, max=1.0, step=0.05, description='Entr\u00e9e x\u2081:') x2_slider = widgets.FloatSlider(value=0.5, min=0.0, max=1.0, step=0.05, description='Entr\u00e9e x\u2082:') activation_dropdown = widgets.Dropdown(     options=['relu', 'sigmoid', 'tanh', 'linear'],     value='relu',     description='Activation:' )  # Fonction pour mettre \u00e0 jour la visualisation def update_neuron_visualization(w1, w2, b, x1, x2, activation):     clear_output(wait=True)     output = visualize_neuron(x1, x2, w1, w2, b, activation)     print(f\"Sortie du neurone: {output:.4f}\")          # Expliquer le calcul     z = x1 * w1 + x2 * w2 + b     print(f\"\\nCalcul d\u00e9taill\u00e9:\")     print(f\"z = (x\u2081 \u00d7 w\u2081) + (x\u2082 \u00d7 w\u2082) + b\")     print(f\"z = ({x1:.2f} \u00d7 {w1:.2f}) + ({x2:.2f} \u00d7 {w2:.2f}) + {b:.2f}\")     print(f\"z = {x1*w1:.2f} + {x2*w2:.2f} + {b:.2f}\")     print(f\"z = {z:.2f}\")          if activation == \"relu\":         print(f\"a = ReLU(z) = max(0, z) = max(0, {z:.2f}) = {max(0, z):.2f}\")     elif activation == \"sigmoid\":         sig_z = 1 / (1 + np.exp(-z))         print(f\"a = Sigmoid(z) = 1 / (1 + e^(-z)) = 1 / (1 + e^(-{z:.2f})) = {sig_z:.2f}\")     elif activation == \"tanh\":         tanh_z = np.tanh(z)         print(f\"a = tanh(z) = tanh({z:.2f}) = {tanh_z:.2f}\")     else:         print(f\"a = z = {z:.2f}\")  # Lin\u00e9aire  # Interface interactive pour le neurone neuron_output = widgets.interactive_output(     update_neuron_visualization,     {'w1': w1_slider, 'w2': w2_slider, 'b': b_slider,       'x1': x1_slider, 'x2': x2_slider, 'activation': activation_dropdown} )  # Afficher les widgets print(\"Utilisez les contr\u00f4les ci-dessous pour modifier les propri\u00e9t\u00e9s du neurone:\") display(widgets.VBox([     widgets.HBox([x1_slider, x2_slider]),     widgets.HBox([w1_slider, w2_slider]),     widgets.HBox([b_slider, activation_dropdown]) ])) display(neuron_output)  # Partie 3: Exploration d'un r\u00e9seau simple print(\"\\n--- De l'unique au r\u00e9seau ---\") print(\"Dans cette partie, nous allons explorer un petit r\u00e9seau de neurones.\")  # Fonction pour cr\u00e9er et visualiser un r\u00e9seau simple def create_simple_network(hidden_units=3, activation='relu'):     # Cr\u00e9er un mod\u00e8le s\u00e9quentiel     model = Sequential([         Dense(hidden_units, activation=activation, input_shape=(2,)),         Dense(1, activation='sigmoid')     ])          # Compiler le mod\u00e8le (bien que nous ne l'entra\u00eenerons pas)     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])          return model  # Fonction pour visualiser un r\u00e9seau simple def visualize_network(inputs, weights1=None, biases1=None, weights2=None, biases2=None, hidden_units=3, activation='relu'):     # Cr\u00e9er le mod\u00e8le si non fourni     model = create_simple_network(hidden_units, activation)          # Si des poids sont fournis, les appliquer     if weights1 is not None and biases1 is not None and weights2 is not None and biases2 is not None:         model.layers[0].set_weights([weights1, biases1])         model.layers[1].set_weights([weights2, biases2])          # Convertir les entr\u00e9es pour pr\u00e9diction     x = np.array([inputs])          # Obtenir les activations interm\u00e9diaires     intermediate_layer_model = tf.keras.Model(inputs=model.input,                                              outputs=model.layers[0].output)     intermediate_activations = intermediate_layer_model.predict(x)[0]          # Obtenir les activations de sortie     output_activation = model.predict(x)[0][0]          # Extraire les poids et biais     weights1, biases1 = model.layers[0].get_weights()     weights2, biases2 = model.layers[1].get_weights()          # Cr\u00e9er la figure pour visualiser le r\u00e9seau     plt.figure(figsize=(12, 8))          # D\u00e9finir les positions des neurones     input_layer_y = np.array([0.2, 0.8])     hidden_layer_y = np.linspace(0.1, 0.9, hidden_units)     output_layer_y = np.array([0.5])          input_layer_x = 0.1     hidden_layer_x = 0.5     output_layer_x = 0.9          # Dessiner les neurones d'entr\u00e9e     for i, y in enumerate(input_layer_y):         plt.scatter(input_layer_x, y, s=200, c='blue', alpha=0.7)         plt.text(input_layer_x, y, f\"x{i+1}={inputs[i]:.2f}\", fontsize=12, ha='center', va='center', color='white')          # Dessiner les neurones cach\u00e9s     for i, y in enumerate(hidden_layer_y):         # Calculer la somme pond\u00e9r\u00e9e         z = np.dot(inputs, weights1[:, i]) + biases1[i]                  # Appliquer l'activation         if activation == 'relu':             a = max(0, z)         elif activation == 'sigmoid':             a = 1 / (1 + np.exp(-z))         elif activation == 'tanh':             a = np.tanh(z)         else:             a = z                  # Couleur bas\u00e9e sur l'activation         color = plt.cm.viridis(a)                  plt.scatter(hidden_layer_x, y, s=200, c=[color], alpha=0.7)         plt.text(hidden_layer_x, y, f\"{a:.2f}\", fontsize=12, ha='center', va='center', color='white')          # Dessiner le neurone de sortie     plt.scatter(output_layer_x, output_layer_y, s=200, c='red', alpha=0.7)     plt.text(output_layer_x, output_layer_y, f\"{output_activation:.2f}\", fontsize=12, ha='center', va='center', color='white')          # Dessiner les connexions entre couches d'entr\u00e9e et cach\u00e9e     for i, y_in in enumerate(input_layer_y):         for j, y_hid in enumerate(hidden_layer_y):             # Couleur et \u00e9paisseur bas\u00e9es sur le poids             weight = weights1[i, j]             width = abs(weight) * 3             color = 'red' if weight &lt; 0 else 'green'             alpha = min(abs(weight), 1.0)                          plt.plot([input_layer_x, hidden_layer_x], [y_in, y_hid],                      c=color, linewidth=width, alpha=alpha)          # Dessiner les connexions entre couche cach\u00e9e et sortie     for i, y_hid in enumerate(hidden_layer_y):         # Couleur et \u00e9paisseur bas\u00e9es sur le poids         weight = weights2[i, 0]         width = abs(weight) * 3         color = 'red' if weight &lt; 0 else 'green'         alpha = min(abs(weight), 1.0)                  plt.plot([hidden_layer_x, output_layer_x], [y_hid, output_layer_y],                  c=color, linewidth=width, alpha=alpha)          # \u00c9tiquettes     plt.text(input_layer_x, 0.03, \"Couche d'entr\u00e9e\", fontsize=14, ha='center')     plt.text(hidden_layer_x, 0.03, \"Couche cach\u00e9e\", fontsize=14, ha='center')     plt.text(output_layer_x, 0.03, \"Couche de sortie\", fontsize=14, ha='center')          # Enlever les axes     plt.axis('off')     plt.title(f\"R\u00e9seau de neurones - Activation cach\u00e9e: {activation}\", fontsize=16)     plt.tight_layout()     plt.show()          # Afficher les calculs d\u00e9taill\u00e9s     print(\"\\nCalculs d\u00e9taill\u00e9s pour chaque neurone de la couche cach\u00e9e:\")     for i in range(hidden_units):         z = np.dot(inputs, weights1[:, i]) + biases1[i]         print(f\"\\nNeurone cach\u00e9 {i+1}:\")         print(f\"z = (x\u2081 \u00d7 w\u2081,{i+1}) + (x\u2082 \u00d7 w\u2082,{i+1}) + b{i+1}\")         print(f\"z = ({inputs[0]:.2f} \u00d7 {weights1[0, i]:.2f}) + ({inputs[1]:.2f} \u00d7 {weights1[1, i]:.2f}) + {biases1[i]:.2f}\")         print(f\"z = {inputs[0] * weights1[0, i]:.2f} + {inputs[1] * weights1[1, i]:.2f} + {biases1[i]:.2f} = {z:.2f}\")                  if activation == 'relu':             a = max(0, z)             print(f\"a = ReLU(z) = max(0, {z:.2f}) = {a:.2f}\")         elif activation == 'sigmoid':             a = 1 / (1 + np.exp(-z))             print(f\"a = Sigmoid(z) = 1 / (1 + e^(-{z:.2f})) = {a:.2f}\")         elif activation == 'tanh':             a = np.tanh(z)             print(f\"a = tanh(z) = tanh({z:.2f}) = {a:.2f}\")         else:             a = z             print(f\"a = z = {z:.2f}\")          print(\"\\nCalcul pour le neurone de sortie:\")     z_out = np.dot(intermediate_activations, weights2[:, 0]) + biases2[0]     print(f\"z = \u03a3(a_cach\u00e9 \u00d7 w_sortie) + b_sortie = {z_out:.2f}\")     print(f\"sortie = Sigmoid(z) = 1 / (1 + e^(-{z_out:.2f})) = {output_activation:.2f}\")          return model, weights1, biases1, weights2, biases2  # Fonction pour g\u00e9n\u00e9rer des poids al\u00e9atoires def generate_random_weights(hidden_units=3):     # G\u00e9n\u00e9rer des poids al\u00e9atoires pour la premi\u00e8re couche     weights1 = np.random.normal(0, 1, (2, hidden_units))     biases1 = np.random.normal(0, 1, hidden_units)          # G\u00e9n\u00e9rer des poids al\u00e9atoires pour la couche de sortie     weights2 = np.random.normal(0, 1, (hidden_units, 1))     biases2 = np.random.normal(0, 1, 1)          return weights1, biases1, weights2, biases2  # Cr\u00e9er des widgets interactifs pour le r\u00e9seau x1_net_slider = widgets.FloatSlider(value=0.5, min=0.0, max=1.0, step=0.05, description='Entr\u00e9e x\u2081:') x2_net_slider = widgets.FloatSlider(value=0.5, min=0.0, max=1.0, step=0.05, description='Entr\u00e9e x\u2082:') hidden_units_slider = widgets.IntSlider(value=3, min=1, max=5, description='Neurones cach\u00e9s:') activation_net_dropdown = widgets.Dropdown(     options=['relu', 'sigmoid', 'tanh', 'linear'],     value='relu',     description='Activation:' ) random_button = widgets.Button(description=\"Poids al\u00e9atoires\")  # Variables pour stocker les poids courants current_weights1, current_biases1, current_weights2, current_biases2 = generate_random_weights()  # Fonction pour visualiser le r\u00e9seau def update_network_visualization(x1, x2, hidden_units, activation):     global current_weights1, current_biases1, current_weights2, current_biases2          # Ajuster les dimensions des poids si n\u00e9cessaire     if current_weights1.shape[1] != hidden_units:         current_weights1, current_biases1, current_weights2, current_biases2 = generate_random_weights(hidden_units)          # Visualiser le r\u00e9seau     inputs = np.array([x1, x2])     _, w1, b1, w2, b2 = visualize_network(         inputs, current_weights1, current_biases1, current_weights2, current_biases2,          hidden_units, activation     )          # Mettre \u00e0 jour les poids courants     current_weights1, current_biases1 = w1, b1     current_weights2, current_biases2 = w2, b2  # Fonction pour g\u00e9n\u00e9rer de nouveaux poids al\u00e9atoires def regenerate_weights(b):     global current_weights1, current_biases1, current_weights2, current_biases2     current_weights1, current_biases1, current_weights2, current_biases2 = generate_random_weights(         hidden_units_slider.value     )     # Mettre \u00e0 jour la visualisation     update_network_visualization(         x1_net_slider.value, x2_net_slider.value,         hidden_units_slider.value, activation_net_dropdown.value     )  # Associer la fonction au bouton random_button.on_click(regenerate_weights)  # Interface interactive pour le r\u00e9seau network_output = widgets.interactive_output(     update_network_visualization,     {'x1': x1_net_slider, 'x2': x2_net_slider,       'hidden_units': hidden_units_slider, 'activation': activation_net_dropdown} )  # Afficher les widgets pour le r\u00e9seau print(\"\\nExplorez le comportement d'un r\u00e9seau simple:\") display(widgets.VBox([     widgets.HBox([x1_net_slider, x2_net_slider]),     widgets.HBox([hidden_units_slider, activation_net_dropdown]),     random_button ])) display(network_output)  # Partie 4: Visualisation de l'entra\u00eenement print(\"\\n--- Visualisation de l'entra\u00eenement ---\") print(\"Dans cette partie, nous allons observer l'\u00e9volution des poids pendant l'entra\u00eenement.\")  # G\u00e9n\u00e9rer des donn\u00e9es XOR def generate_xor_data(n_samples=100):     X = np.random.rand(n_samples, 2)     y = np.logical_xor(X[:, 0] &gt; 0.5, X[:, 1] &gt; 0.5).astype(np.float32)     return X, y  # Fonction pour visualiser l'\u00e9volution de l'apprentissage def visualize_training_animation(learning_rate=0.1, epochs=50, hidden_units=4):     # G\u00e9n\u00e9rer des donn\u00e9es     X_train, y_train = generate_xor_data(200)          # Cr\u00e9er un mod\u00e8le     model = Sequential([         Dense(hidden_units, activation='relu', input_shape=(2,)),         Dense(1, activation='sigmoid')     ])          # Compiler avec un optimiseur personnalis\u00e9 pour suivre l'\u00e9volution des poids     optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)     model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])          # Extraire les poids initiaux     weights_history = [model.get_weights()]          # Fonction pour collecter les poids apr\u00e8s chaque \u00e9poque     class WeightHistory(tf.keras.callbacks.Callback):         def on_epoch_end(self, epoch, logs=None):             weights_history.append(self.model.get_weights())          # Entra\u00eener le mod\u00e8le     history = model.fit(         X_train, y_train,         epochs=epochs,         batch_size=32,         verbose=0,         callbacks=[WeightHistory()]     )          # Cr\u00e9er une figure pour l'animation     plt.figure(figsize=(15, 6))          # Visualiser la fronti\u00e8re de d\u00e9cision     plt.subplot(1, 2, 1)          # Cr\u00e9er une grille pour visualiser la fronti\u00e8re de d\u00e9cision     h = 0.01     x_min, x_max = 0, 1     y_min, y_max = 0, 1     xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))     grid_points = np.c_[xx.ravel(), yy.ravel()]          # Pr\u00e9dire sur la grille avec le mod\u00e8le final     Z = model.predict(grid_points)     Z = Z.reshape(xx.shape)          # Tracer la fronti\u00e8re de d\u00e9cision finale     plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.coolwarm)          # Tracer les points d'entra\u00eenement     scatter = plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, edgecolors='k', cmap=plt.cm.coolwarm)          plt.title('Fronti\u00e8re de d\u00e9cision finale')     plt.xlabel('x\u2081')     plt.ylabel('x\u2082')     plt.legend(*scatter.legend_elements(), title=\"Classes\")          # Visualiser l'\u00e9volution de la perte et de la pr\u00e9cision     plt.subplot(1, 2, 2)     plt.plot(history.history['loss'], label='Perte')     plt.plot(history.history['accuracy'], label='Pr\u00e9cision')     plt.title('\u00c9volution de l\\'entra\u00eenement')     plt.xlabel('\u00c9poque')     plt.ylabel('Valeur')     plt.legend()          plt.tight_layout()     plt.show()          # Afficher des d\u00e9tails sur l'entra\u00eenement     print(f\"Apprentissage termin\u00e9 apr\u00e8s {epochs} \u00e9poques:\")     print(f\"- Perte finale: {history.history['loss'][-1]:.4f}\")     print(f\"- Pr\u00e9cision finale: {history.history['accuracy'][-1]*100:.2f}%\")          # Afficher l'\u00e9volution des poids     print(\"\\n\u00c9volution des poids:\")          # Cr\u00e9er un slider pour parcourir les \u00e9poques     def show_weights_at_epoch(epoch):         weights = weights_history[epoch]                  plt.figure(figsize=(14, 6))                  # Visualiser les poids de la premi\u00e8re couche         plt.subplot(1, 2, 1)         w1 = weights[0]         plt.imshow(w1, aspect='auto', cmap='coolwarm')         plt.colorbar(label='Valeur du poids')         plt.title(f'Poids de la couche cach\u00e9e (\u00c9poque {epoch})')         plt.xlabel('Neurone cach\u00e9')         plt.ylabel('Entr\u00e9e')         plt.yticks([0, 1], ['x\u2081', 'x\u2082'])                  # Visualiser les poids de la couche de sortie         plt.subplot(1, 2, 2)         w2 = weights[2]         plt.bar(range(len(w2)), w2.flatten())         plt.title(f'Poids de la couche de sortie (\u00c9poque {epoch})')         plt.xlabel('Neurone cach\u00e9')         plt.ylabel('Poids vers la sortie')         plt.xticks(range(len(w2)))                  plt.tight_layout()         plt.show()                  # Afficher aussi la fronti\u00e8re de d\u00e9cision \u00e0 cette \u00e9poque         model_at_epoch = Sequential([             Dense(hidden_units, activation='relu', input_shape=(2,)),             Dense(1, activation='sigmoid')         ])         model_at_epoch.set_weights(weights)                  # Pr\u00e9dire sur la grille         Z = model_at_epoch.predict(grid_points)         Z = Z.reshape(xx.shape)                  plt.figure(figsize=(8, 6))         plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.coolwarm)         scatter = plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, edgecolors='k', cmap=plt.cm.coolwarm)         plt"},{"location":"ressources/notebooks/deep-learning/","title":"Deep learning","text":"In\u00a0[\u00a0]: Copied! <pre># Notebook A: Classification avec Machine Learning classique\n# Classification des chiffres manuscrits avec Random Forest\n\n# Partie 1: Importation des biblioth\u00e8ques\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nimport time\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport seaborn as sns\nfrom sklearn.pipeline import Pipeline\nfrom google.colab import output\noutput.enable_custom_widget_manager()\nimport ipywidgets as widgets\n\n# Partie 2: Chargement et exploration des donn\u00e9es\nprint(\"Chargement du jeu de donn\u00e9es MNIST...\")\n# Utilisation du jeu de donn\u00e9es MNIST int\u00e9gr\u00e9 \u00e0 sklearn\nfrom sklearn.datasets import fetch_openml\nmnist = fetch_openml('mnist_784', version=1, as_frame=False)\nX, y = mnist[\"data\"], mnist[\"target\"]\nX = X / 255.0  # Normalisation des valeurs de pixels entre 0 et 1\ny = y.astype(np.uint8)  # Conversion des labels en entiers\n\n# Exploration des donn\u00e9es\nprint(f\"Dimensions du jeu de donn\u00e9es: {X.shape}\")\nprint(f\"Nombre de classes: {len(np.unique(y))}\")\n\n# Affichage de quelques exemples\nplt.figure(figsize=(10, 5))\nfor i in range(10):\n    plt.subplot(2, 5, i + 1)\n    plt.imshow(X[i].reshape(28, 28), cmap='gray')\n    plt.title(f\"Label: {y[i]}\")\n    plt.axis('off')\nplt.tight_layout()\nplt.suptitle(\"Exemples de chiffres manuscrits\", y=1.05)\nplt.show()\n\n# Partie 3: Pr\u00e9paration des donn\u00e9es pour Machine Learning classique\n\nprint(\"\\n--- Pr\u00e9paration des donn\u00e9es pour Random Forest ---\")\nprint(\"Pour le Machine Learning classique, nous devons souvent extraire des caract\u00e9ristiques manuellement.\")\n\n# R\u00e9duction de dimension avec PCA pour acc\u00e9l\u00e9rer l'entra\u00eenement\nprint(\"Application d'une r\u00e9duction de dimension (PCA)...\")\nn_components = 50  # R\u00e9duire de 784 \u00e0 50 caract\u00e9ristiques\n\n# S\u00e9paration en ensembles d'entra\u00eenement et de test\n# Utilisation d'un \u00e9chantillon r\u00e9duit pour acc\u00e9l\u00e9rer la d\u00e9monstration\nX_sample = X[:10000]\ny_sample = y[:10000]\n\nX_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)\n\nprint(f\"Taille de l'ensemble d'entra\u00eenement: {X_train.shape}\")\nprint(f\"Taille de l'ensemble de test: {X_test.shape}\")\n\n# Cr\u00e9ation d'un pipeline d'extraction de caract\u00e9ristiques\nfeature_pipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('pca', PCA(n_components=n_components))\n])\n\n# Application aux donn\u00e9es\nprint(\"Extraction de caract\u00e9ristiques...\")\nX_train_features = feature_pipeline.fit_transform(X_train)\nX_test_features = feature_pipeline.transform(X_test)\n\nprint(f\"Dimensions apr\u00e8s extraction de caract\u00e9ristiques: {X_train_features.shape}\")\n\n# Partie 4: Entra\u00eenement du mod\u00e8le Random Forest\n\nprint(\"\\n--- Entra\u00eenement du mod\u00e8le Random Forest ---\")\n\n# Param\u00e8tres du mod\u00e8le - vous pouvez les modifier\nn_estimators = 100  # Nombre d'arbres\nmax_depth = 10      # Profondeur maximale des arbres\nmin_samples_split = 2  # Nombre minimum d'\u00e9chantillons requis pour diviser un n\u0153ud\n\n# Cr\u00e9ation du mod\u00e8le\nrf_model = RandomForestClassifier(\n    n_estimators=n_estimators,\n    max_depth=max_depth,\n    min_samples_split=min_samples_split,\n    random_state=42,\n    n_jobs=-1  # Utiliser tous les c\u0153urs disponibles\n)\n\n# Mesure du temps d'entra\u00eenement\nstart_time = time.time()\nprint(\"Entra\u00eenement du mod\u00e8le en cours...\")\nrf_model.fit(X_train_features, y_train)\nend_time = time.time()\ntraining_time = end_time - start_time\n\nprint(f\"Temps d'entra\u00eenement: {training_time:.2f} secondes\")\n\n# Partie 5: \u00c9valuation du mod\u00e8le\n\nprint(\"\\n--- \u00c9valuation du mod\u00e8le Random Forest ---\")\n\n# Pr\u00e9dictions sur l'ensemble de test\ny_pred = rf_model.predict(X_test_features)\n\n# Calcul des m\u00e9triques\naccuracy = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\nclass_report = classification_report(y_test, y_pred)\n\nprint(f\"Pr\u00e9cision globale: {accuracy*100:.2f}%\")\nprint(\"\\nMatrice de confusion:\")\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Pr\u00e9dictions')\nplt.ylabel('Valeurs r\u00e9elles')\nplt.title('Matrice de confusion')\nplt.show()\n\nprint(\"\\nRapport de classification:\")\nprint(class_report)\n\n# Partie 6: Visualisation des erreurs\n\nprint(\"\\n--- Analyse des erreurs ---\")\n\n# Identifier les erreurs\nerror_indices = np.where(y_pred != y_test)[0]\nn_errors = min(10, len(error_indices))  # Afficher max 10 erreurs\n\nif n_errors &gt; 0:\n    plt.figure(figsize=(12, 4))\n    for i, idx in enumerate(error_indices[:n_errors]):\n        plt.subplot(2, 5, i + 1)\n        # R\u00e9cup\u00e9rer l'image originale\n        img = X_test[idx].reshape(28, 28)\n        plt.imshow(img, cmap='gray')\n        plt.title(f\"R\u00e9el: {y_test[idx]}\\nPr\u00e9dit: {y_pred[idx]}\")\n        plt.axis('off')\n    plt.tight_layout()\n    plt.suptitle(\"Exemples d'erreurs de classification\", y=1.05)\n    plt.show()\nelse:\n    print(\"Aucune erreur trouv\u00e9e dans l'\u00e9chantillon de test!\")\n\n# Partie 7: Importance des caract\u00e9ristiques\n\nprint(\"\\n--- Importance des caract\u00e9ristiques ---\")\n# Visualiser l'importance des composantes principales\nfeature_importance = rf_model.feature_importances_\nsorted_idx = np.argsort(feature_importance)[::-1]\n\nplt.figure(figsize=(10, 5))\nplt.bar(range(20), feature_importance[sorted_idx[:20]])\nplt.xticks(range(20), [f\"Feat {i}\" for i in sorted_idx[:20]], rotation=90)\nplt.xlabel('Composantes principales')\nplt.ylabel('Importance')\nplt.title('Top 20 des composantes principales les plus importantes')\nplt.tight_layout()\nplt.show()\n\nprint(\"Les caract\u00e9ristiques les plus importantes sont les composantes principales qui capturent le plus de variance dans les donn\u00e9es.\")\n\n# Partie 8: D\u00e9fi de g\u00e9n\u00e9ralisation\n\nprint(\"\\n--- D\u00e9fi de g\u00e9n\u00e9ralisation ---\")\nprint(\"Nous allons maintenant tester le mod\u00e8le sur des chiffres l\u00e9g\u00e8rement modifi\u00e9s pour \u00e9valuer sa capacit\u00e9 de g\u00e9n\u00e9ralisation.\")\n\n# Fonction pour ajouter du bruit aux images\ndef add_noise(images, noise_level=0.2):\n    noisy_images = images.copy()\n    noise = np.random.normal(0, noise_level, images.shape)\n    noisy_images = noisy_images + noise\n    # Assurer que les valeurs restent entre 0 et 1\n    noisy_images = np.clip(noisy_images, 0, 1)\n    return noisy_images\n\n# Fonction pour appliquer une rotation aux images\ndef rotate_images(images, max_angle=15):\n    from scipy.ndimage import rotate\n    rotated_images = np.zeros_like(images)\n    for i, img in enumerate(images):\n        angle = np.random.uniform(-max_angle, max_angle)\n        img_2d = img.reshape(28, 28)\n        rotated = rotate(img_2d, angle, reshape=False)\n        rotated_images[i] = rotated.flatten()\n    return rotated_images\n\n# Cr\u00e9er un jeu de donn\u00e9es modifi\u00e9\nprint(\"Cr\u00e9ation d'un jeu de donn\u00e9es avec des chiffres modifi\u00e9s...\")\n\n# Utiliser la partie restante des donn\u00e9es pour ce test\nX_new = X[10000:12000]\ny_new = y[10000:12000]\n\n# Appliquer des transformations\nX_new_noisy = add_noise(X_new, noise_level=0.2)\nX_new_rotated = rotate_images(X_new, max_angle=15)\n\n# Visualiser quelques exemples\nplt.figure(figsize=(12, 8))\nfor i in range(5):\n    # Original\n    plt.subplot(3, 5, i + 1)\n    plt.imshow(X_new[i].reshape(28, 28), cmap='gray')\n    plt.title(f\"Original: {y_new[i]}\")\n    plt.axis('off')\n    \n    # Avec bruit\n    plt.subplot(3, 5, i + 6)\n    plt.imshow(X_new_noisy[i].reshape(28, 28), cmap='gray')\n    plt.title(\"Avec bruit\")\n    plt.axis('off')\n    \n    # Avec rotation\n    plt.subplot(3, 5, i + 11)\n    plt.imshow(X_new_rotated[i].reshape(28, 28), cmap='gray')\n    plt.title(\"Avec rotation\")\n    plt.axis('off')\n\nplt.tight_layout()\nplt.suptitle(\"Exemples de chiffres modifi\u00e9s\", y=1.02)\nplt.show()\n\n# \u00c9valuer le mod\u00e8le sur les donn\u00e9es modifi\u00e9es\nprint(\"\\n\u00c9valuation sur les donn\u00e9es avec bruit:\")\nX_new_noisy_features = feature_pipeline.transform(X_new_noisy)\ny_new_noisy_pred = rf_model.predict(X_new_noisy_features)\naccuracy_noisy = accuracy_score(y_new, y_new_noisy_pred)\nprint(f\"Pr\u00e9cision sur donn\u00e9es bruit\u00e9es: {accuracy_noisy*100:.2f}%\")\n\nprint(\"\\n\u00c9valuation sur les donn\u00e9es avec rotation:\")\nX_new_rotated_features = feature_pipeline.transform(X_new_rotated)\ny_new_rotated_pred = rf_model.predict(X_new_rotated_features)\naccuracy_rotated = accuracy_score(y_new, y_new_rotated_pred)\nprint(f\"Pr\u00e9cision sur donn\u00e9es pivot\u00e9es: {accuracy_rotated*100:.2f}%\")\n\nprint(\"\\nComparaison avec la pr\u00e9cision originale:\")\nprint(f\"Pr\u00e9cision sur donn\u00e9es originales: {accuracy*100:.2f}%\")\nprint(f\"Pr\u00e9cision sur donn\u00e9es bruit\u00e9es: {accuracy_noisy*100:.2f}%\")\nprint(f\"Pr\u00e9cision sur donn\u00e9es pivot\u00e9es: {accuracy_rotated*100:.2f}%\")\n\n# Partie 9: Conclusions et r\u00e9flexion\n\nprint(\"\\n--- Conclusions sur le Machine Learning classique ---\")\nprint(\"\"\"\nPoints forts du Random Forest:\n- Entra\u00eenement relativement rapide\n- Bonnes performances sur les donn\u00e9es originales\n- Interpr\u00e9tabilit\u00e9 (importance des caract\u00e9ristiques)\n\nLimites:\n- N\u00e9cessite une extraction manuelle de caract\u00e9ristiques (PCA dans notre cas)\n- Sensibilit\u00e9 aux transformations des donn\u00e9es (bruit, rotation)\n- Difficult\u00e9 \u00e0 capturer des motifs complexes sans feature engineering appropri\u00e9\n\nQuestions pour la r\u00e9flexion:\n1. Pourquoi avons-nous besoin de r\u00e9duire la dimensionnalit\u00e9 pour le Random Forest?\n2. Comment pourrait-on am\u00e9liorer la robustesse aux transformations?\n3. Quelles autres caract\u00e9ristiques pourraient \u00eatre extraites manuellement pour am\u00e9liorer les performances?\n\"\"\")\n\n# Partie 10: Widget interactif pour tester le mod\u00e8le\n\nprint(\"\\n--- Testez le mod\u00e8le vous-m\u00eame ---\")\n\ndef test_model(digit_idx):\n    if digit_idx &lt; len(X_test):\n        # Afficher l'image\n        img = X_test[digit_idx].reshape(28, 28)\n        plt.figure(figsize=(6, 6))\n        plt.imshow(img, cmap='gray')\n        plt.title(f\"Chiffre \u00e0 classifier\")\n        plt.axis('off')\n        plt.show()\n        \n        # Faire la pr\u00e9diction\n        features = feature_pipeline.transform([X_test[digit_idx]])\n        prediction = rf_model.predict(features)[0]\n        real_label = y_test[digit_idx]\n        \n        print(f\"Pr\u00e9diction du mod\u00e8le Random Forest: {prediction}\")\n        print(f\"\u00c9tiquette r\u00e9elle: {real_label}\")\n        print(f\"Pr\u00e9diction {'correcte' if prediction == real_label else 'incorrecte'}\")\n    else:\n        print(\"Index hors limites!\")\n\n# Cr\u00e9er un slider pour s\u00e9lectionner un chiffre \u00e0 tester\ndigit_selector = widgets.IntSlider(\n    value=0,\n    min=0,\n    max=len(X_test)-1,\n    step=1,\n    description='Index:',\n    continuous_update=False\n)\n\n# Bouton pour ex\u00e9cuter le test\ntest_button = widgets.Button(description=\"Tester\")\noutput = widgets.Output()\n\ndef on_button_clicked(b):\n    with output:\n        output.clear_output()\n        test_model(digit_selector.value)\n\ntest_button.on_click(on_button_clicked)\n\n# Afficher les widgets\ndisplay(widgets.HBox([digit_selector, test_button]))\ndisplay(output)\n\nprint(\"Utilisez le slider pour s\u00e9lectionner un index et cliquez sur 'Tester' pour classifier le chiffre correspondant.\")\n</pre> # Notebook A: Classification avec Machine Learning classique # Classification des chiffres manuscrits avec Random Forest  # Partie 1: Importation des biblioth\u00e8ques import numpy as np import pandas as pd import matplotlib.pyplot as plt from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score, confusion_matrix, classification_report import time from sklearn.preprocessing import StandardScaler from sklearn.decomposition import PCA import seaborn as sns from sklearn.pipeline import Pipeline from google.colab import output output.enable_custom_widget_manager() import ipywidgets as widgets  # Partie 2: Chargement et exploration des donn\u00e9es print(\"Chargement du jeu de donn\u00e9es MNIST...\") # Utilisation du jeu de donn\u00e9es MNIST int\u00e9gr\u00e9 \u00e0 sklearn from sklearn.datasets import fetch_openml mnist = fetch_openml('mnist_784', version=1, as_frame=False) X, y = mnist[\"data\"], mnist[\"target\"] X = X / 255.0  # Normalisation des valeurs de pixels entre 0 et 1 y = y.astype(np.uint8)  # Conversion des labels en entiers  # Exploration des donn\u00e9es print(f\"Dimensions du jeu de donn\u00e9es: {X.shape}\") print(f\"Nombre de classes: {len(np.unique(y))}\")  # Affichage de quelques exemples plt.figure(figsize=(10, 5)) for i in range(10):     plt.subplot(2, 5, i + 1)     plt.imshow(X[i].reshape(28, 28), cmap='gray')     plt.title(f\"Label: {y[i]}\")     plt.axis('off') plt.tight_layout() plt.suptitle(\"Exemples de chiffres manuscrits\", y=1.05) plt.show()  # Partie 3: Pr\u00e9paration des donn\u00e9es pour Machine Learning classique  print(\"\\n--- Pr\u00e9paration des donn\u00e9es pour Random Forest ---\") print(\"Pour le Machine Learning classique, nous devons souvent extraire des caract\u00e9ristiques manuellement.\")  # R\u00e9duction de dimension avec PCA pour acc\u00e9l\u00e9rer l'entra\u00eenement print(\"Application d'une r\u00e9duction de dimension (PCA)...\") n_components = 50  # R\u00e9duire de 784 \u00e0 50 caract\u00e9ristiques  # S\u00e9paration en ensembles d'entra\u00eenement et de test # Utilisation d'un \u00e9chantillon r\u00e9duit pour acc\u00e9l\u00e9rer la d\u00e9monstration X_sample = X[:10000] y_sample = y[:10000]  X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)  print(f\"Taille de l'ensemble d'entra\u00eenement: {X_train.shape}\") print(f\"Taille de l'ensemble de test: {X_test.shape}\")  # Cr\u00e9ation d'un pipeline d'extraction de caract\u00e9ristiques feature_pipeline = Pipeline([     ('scaler', StandardScaler()),     ('pca', PCA(n_components=n_components)) ])  # Application aux donn\u00e9es print(\"Extraction de caract\u00e9ristiques...\") X_train_features = feature_pipeline.fit_transform(X_train) X_test_features = feature_pipeline.transform(X_test)  print(f\"Dimensions apr\u00e8s extraction de caract\u00e9ristiques: {X_train_features.shape}\")  # Partie 4: Entra\u00eenement du mod\u00e8le Random Forest  print(\"\\n--- Entra\u00eenement du mod\u00e8le Random Forest ---\")  # Param\u00e8tres du mod\u00e8le - vous pouvez les modifier n_estimators = 100  # Nombre d'arbres max_depth = 10      # Profondeur maximale des arbres min_samples_split = 2  # Nombre minimum d'\u00e9chantillons requis pour diviser un n\u0153ud  # Cr\u00e9ation du mod\u00e8le rf_model = RandomForestClassifier(     n_estimators=n_estimators,     max_depth=max_depth,     min_samples_split=min_samples_split,     random_state=42,     n_jobs=-1  # Utiliser tous les c\u0153urs disponibles )  # Mesure du temps d'entra\u00eenement start_time = time.time() print(\"Entra\u00eenement du mod\u00e8le en cours...\") rf_model.fit(X_train_features, y_train) end_time = time.time() training_time = end_time - start_time  print(f\"Temps d'entra\u00eenement: {training_time:.2f} secondes\")  # Partie 5: \u00c9valuation du mod\u00e8le  print(\"\\n--- \u00c9valuation du mod\u00e8le Random Forest ---\")  # Pr\u00e9dictions sur l'ensemble de test y_pred = rf_model.predict(X_test_features)  # Calcul des m\u00e9triques accuracy = accuracy_score(y_test, y_pred) conf_matrix = confusion_matrix(y_test, y_pred) class_report = classification_report(y_test, y_pred)  print(f\"Pr\u00e9cision globale: {accuracy*100:.2f}%\") print(\"\\nMatrice de confusion:\") plt.figure(figsize=(8, 6)) sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues') plt.xlabel('Pr\u00e9dictions') plt.ylabel('Valeurs r\u00e9elles') plt.title('Matrice de confusion') plt.show()  print(\"\\nRapport de classification:\") print(class_report)  # Partie 6: Visualisation des erreurs  print(\"\\n--- Analyse des erreurs ---\")  # Identifier les erreurs error_indices = np.where(y_pred != y_test)[0] n_errors = min(10, len(error_indices))  # Afficher max 10 erreurs  if n_errors &gt; 0:     plt.figure(figsize=(12, 4))     for i, idx in enumerate(error_indices[:n_errors]):         plt.subplot(2, 5, i + 1)         # R\u00e9cup\u00e9rer l'image originale         img = X_test[idx].reshape(28, 28)         plt.imshow(img, cmap='gray')         plt.title(f\"R\u00e9el: {y_test[idx]}\\nPr\u00e9dit: {y_pred[idx]}\")         plt.axis('off')     plt.tight_layout()     plt.suptitle(\"Exemples d'erreurs de classification\", y=1.05)     plt.show() else:     print(\"Aucune erreur trouv\u00e9e dans l'\u00e9chantillon de test!\")  # Partie 7: Importance des caract\u00e9ristiques  print(\"\\n--- Importance des caract\u00e9ristiques ---\") # Visualiser l'importance des composantes principales feature_importance = rf_model.feature_importances_ sorted_idx = np.argsort(feature_importance)[::-1]  plt.figure(figsize=(10, 5)) plt.bar(range(20), feature_importance[sorted_idx[:20]]) plt.xticks(range(20), [f\"Feat {i}\" for i in sorted_idx[:20]], rotation=90) plt.xlabel('Composantes principales') plt.ylabel('Importance') plt.title('Top 20 des composantes principales les plus importantes') plt.tight_layout() plt.show()  print(\"Les caract\u00e9ristiques les plus importantes sont les composantes principales qui capturent le plus de variance dans les donn\u00e9es.\")  # Partie 8: D\u00e9fi de g\u00e9n\u00e9ralisation  print(\"\\n--- D\u00e9fi de g\u00e9n\u00e9ralisation ---\") print(\"Nous allons maintenant tester le mod\u00e8le sur des chiffres l\u00e9g\u00e8rement modifi\u00e9s pour \u00e9valuer sa capacit\u00e9 de g\u00e9n\u00e9ralisation.\")  # Fonction pour ajouter du bruit aux images def add_noise(images, noise_level=0.2):     noisy_images = images.copy()     noise = np.random.normal(0, noise_level, images.shape)     noisy_images = noisy_images + noise     # Assurer que les valeurs restent entre 0 et 1     noisy_images = np.clip(noisy_images, 0, 1)     return noisy_images  # Fonction pour appliquer une rotation aux images def rotate_images(images, max_angle=15):     from scipy.ndimage import rotate     rotated_images = np.zeros_like(images)     for i, img in enumerate(images):         angle = np.random.uniform(-max_angle, max_angle)         img_2d = img.reshape(28, 28)         rotated = rotate(img_2d, angle, reshape=False)         rotated_images[i] = rotated.flatten()     return rotated_images  # Cr\u00e9er un jeu de donn\u00e9es modifi\u00e9 print(\"Cr\u00e9ation d'un jeu de donn\u00e9es avec des chiffres modifi\u00e9s...\")  # Utiliser la partie restante des donn\u00e9es pour ce test X_new = X[10000:12000] y_new = y[10000:12000]  # Appliquer des transformations X_new_noisy = add_noise(X_new, noise_level=0.2) X_new_rotated = rotate_images(X_new, max_angle=15)  # Visualiser quelques exemples plt.figure(figsize=(12, 8)) for i in range(5):     # Original     plt.subplot(3, 5, i + 1)     plt.imshow(X_new[i].reshape(28, 28), cmap='gray')     plt.title(f\"Original: {y_new[i]}\")     plt.axis('off')          # Avec bruit     plt.subplot(3, 5, i + 6)     plt.imshow(X_new_noisy[i].reshape(28, 28), cmap='gray')     plt.title(\"Avec bruit\")     plt.axis('off')          # Avec rotation     plt.subplot(3, 5, i + 11)     plt.imshow(X_new_rotated[i].reshape(28, 28), cmap='gray')     plt.title(\"Avec rotation\")     plt.axis('off')  plt.tight_layout() plt.suptitle(\"Exemples de chiffres modifi\u00e9s\", y=1.02) plt.show()  # \u00c9valuer le mod\u00e8le sur les donn\u00e9es modifi\u00e9es print(\"\\n\u00c9valuation sur les donn\u00e9es avec bruit:\") X_new_noisy_features = feature_pipeline.transform(X_new_noisy) y_new_noisy_pred = rf_model.predict(X_new_noisy_features) accuracy_noisy = accuracy_score(y_new, y_new_noisy_pred) print(f\"Pr\u00e9cision sur donn\u00e9es bruit\u00e9es: {accuracy_noisy*100:.2f}%\")  print(\"\\n\u00c9valuation sur les donn\u00e9es avec rotation:\") X_new_rotated_features = feature_pipeline.transform(X_new_rotated) y_new_rotated_pred = rf_model.predict(X_new_rotated_features) accuracy_rotated = accuracy_score(y_new, y_new_rotated_pred) print(f\"Pr\u00e9cision sur donn\u00e9es pivot\u00e9es: {accuracy_rotated*100:.2f}%\")  print(\"\\nComparaison avec la pr\u00e9cision originale:\") print(f\"Pr\u00e9cision sur donn\u00e9es originales: {accuracy*100:.2f}%\") print(f\"Pr\u00e9cision sur donn\u00e9es bruit\u00e9es: {accuracy_noisy*100:.2f}%\") print(f\"Pr\u00e9cision sur donn\u00e9es pivot\u00e9es: {accuracy_rotated*100:.2f}%\")  # Partie 9: Conclusions et r\u00e9flexion  print(\"\\n--- Conclusions sur le Machine Learning classique ---\") print(\"\"\" Points forts du Random Forest: - Entra\u00eenement relativement rapide - Bonnes performances sur les donn\u00e9es originales - Interpr\u00e9tabilit\u00e9 (importance des caract\u00e9ristiques)  Limites: - N\u00e9cessite une extraction manuelle de caract\u00e9ristiques (PCA dans notre cas) - Sensibilit\u00e9 aux transformations des donn\u00e9es (bruit, rotation) - Difficult\u00e9 \u00e0 capturer des motifs complexes sans feature engineering appropri\u00e9  Questions pour la r\u00e9flexion: 1. Pourquoi avons-nous besoin de r\u00e9duire la dimensionnalit\u00e9 pour le Random Forest? 2. Comment pourrait-on am\u00e9liorer la robustesse aux transformations? 3. Quelles autres caract\u00e9ristiques pourraient \u00eatre extraites manuellement pour am\u00e9liorer les performances? \"\"\")  # Partie 10: Widget interactif pour tester le mod\u00e8le  print(\"\\n--- Testez le mod\u00e8le vous-m\u00eame ---\")  def test_model(digit_idx):     if digit_idx &lt; len(X_test):         # Afficher l'image         img = X_test[digit_idx].reshape(28, 28)         plt.figure(figsize=(6, 6))         plt.imshow(img, cmap='gray')         plt.title(f\"Chiffre \u00e0 classifier\")         plt.axis('off')         plt.show()                  # Faire la pr\u00e9diction         features = feature_pipeline.transform([X_test[digit_idx]])         prediction = rf_model.predict(features)[0]         real_label = y_test[digit_idx]                  print(f\"Pr\u00e9diction du mod\u00e8le Random Forest: {prediction}\")         print(f\"\u00c9tiquette r\u00e9elle: {real_label}\")         print(f\"Pr\u00e9diction {'correcte' if prediction == real_label else 'incorrecte'}\")     else:         print(\"Index hors limites!\")  # Cr\u00e9er un slider pour s\u00e9lectionner un chiffre \u00e0 tester digit_selector = widgets.IntSlider(     value=0,     min=0,     max=len(X_test)-1,     step=1,     description='Index:',     continuous_update=False )  # Bouton pour ex\u00e9cuter le test test_button = widgets.Button(description=\"Tester\") output = widgets.Output()  def on_button_clicked(b):     with output:         output.clear_output()         test_model(digit_selector.value)  test_button.on_click(on_button_clicked)  # Afficher les widgets display(widgets.HBox([digit_selector, test_button])) display(output)  print(\"Utilisez le slider pour s\u00e9lectionner un index et cliquez sur 'Tester' pour classifier le chiffre correspondant.\")"},{"location":"ressources/notebooks/hello-world-dl/","title":"Hello world dl","text":"In\u00a0[2]: Copied! <pre>{\n \"cells\": [\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"# \ud83d\ude80 Hello World du Deep Learning\\n\",\n    \"\\n\",\n    \"## Reconnaissance de chiffres manuscrits avec TensorFlow et Keras\\n\",\n    \"\\n\",\n    \"### Objectifs de ce notebook\\n\",\n    \"\\n\",\n    \"- Charger et pr\u00e9parer un jeu de donn\u00e9es de chiffres manuscrits\\n\",\n    \"- Cr\u00e9er un r\u00e9seau de neurones simple\\n\",\n    \"- Entra\u00eener le mod\u00e8le\\n\",\n    \"- Visualiser les r\u00e9sultats\\n\",\n    \"- Tester le mod\u00e8le avec vos propres dessins\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"source\": [\n    \"# Importation des biblioth\u00e8ques n\u00e9cessaires\\n\",\n    \"import numpy as np\\n\",\n    \"import matplotlib.pyplot as plt\\n\",\n    \"import tensorflow as tf\\n\",\n    \"from tensorflow import keras\\n\",\n    \"from tensorflow.keras import layers\\n\",\n    \"\\n\",\n    \"# V\u00e9rification de la version de TensorFlow\\n\",\n    \"print(f\\\"TensorFlow version: {tf.__version__}\\\")\\n\",\n    \"print(f\\\"Keras version: {keras.__version__}\\\")\\n\",\n    \"\\n\",\n    \"# V\u00e9rification du GPU (si disponible)\\n\",\n    \"print(\\\"GPU disponible :\\\", tf.test.is_gpu_available())\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"source\": [\n    \"# Chargement du dataset MNIST\\n\",\n    \"(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\\n\",\n    \"\\n\",\n    \"# Pr\u00e9traitement des donn\u00e9es\\n\",\n    \"X_train = X_train.reshape((60000, 28, 28, 1)) / 255.0\\n\",\n    \"X_test = X_test.reshape((10000, 28, 28, 1)) / 255.0\\n\",\n    \"\\n\",\n    \"# Conversion des labels en cat\u00e9gories\\n\",\n    \"y_train = keras.utils.to_categorical(y_train)\\n\",\n    \"y_test = keras.utils.to_categorical(y_test)\\n\",\n    \"\\n\",\n    \"# Affichage de quelques exemples\\n\",\n    \"plt.figure(figsize=(10, 2))\\n\",\n    \"for i in range(10):\\n\",\n    \"    plt.subplot(1, 10, i+1)\\n\",\n    \"    plt.imshow(X_train[i].reshape(28, 28), cmap='gray')\\n\",\n    \"    plt.axis('off')\\n\",\n    \"plt.suptitle(\\\"Exemples de chiffres manuscrits\\\")\\n\",\n    \"plt.show()\\n\",\n    \"\\n\",\n    \"print(f\\\"Nombre d'exemples d'entra\u00eenement : {X_train.shape[0]}\\\")\\n\",\n    \"print(f\\\"Nombre d'exemples de test : {X_test.shape[0]}\\\")\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"source\": [\n    \"# Cr\u00e9ation du mod\u00e8le de r\u00e9seau de neurones\\n\",\n    \"model = keras.Sequential([\\n\",\n    \"    # Couche de convolution\\n\",\n    \"    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\\n\",\n    \"    layers.MaxPooling2D((2, 2)),\\n\",\n    \"    \\n\",\n    \"    # Couche de convolution suppl\u00e9mentaire\\n\",\n    \"    layers.Conv2D(64, (3, 3), activation='relu'),\\n\",\n    \"    layers.MaxPooling2D((2, 2)),\\n\",\n    \"    \\n\",\n    \"    # Aplatissement\\n\",\n    \"    layers.Flatten(),\\n\",\n    \"    \\n\",\n    \"    # Couche dense\\n\",\n    \"    layers.Dense(64, activation='relu'),\\n\",\n    \"    \\n\",\n    \"    # Couche de sortie\\n\",\n    \"    layers.Dense(10, activation='softmax')\\n\",\n    \"])\\n\",\n    \"\\n\",\n    \"# Compilation du mod\u00e8le\\n\",\n    \"model.compile(\\n\",\n    \"    optimizer='adam',\\n\",\n    \"    loss='categorical_crossentropy',\\n\",\n    \"    metrics=['accuracy']\\n\",\n    \")\\n\",\n    \"\\n\",\n    \"# Affichage du r\u00e9sum\u00e9 du mod\u00e8le\\n\",\n    \"model.summary()\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\\n\",\n   \"execution_count\": null,\\n\",\n   \"metadata\": {},\\n\",\n   \"source\": [\n    \"# Entra\u00eenement du mod\u00e8le\\n\",\n    \"# Note : Nombre d'\u00e9poques r\u00e9duit pour la d\u00e9monstration\\n\",\n    \"history = model.fit(\\n\",\n    \"    X_train, y_train,\\n\",\n    \"    epochs=5,\\n\",\n    \"    batch_size=64,\\n\",\n    \"    validation_split=0.2,\\n\",\n    \"    verbose=1\\n\",\n    \")\\n\",\n    \"\\n\",\n    \"# \u00c9valuation du mod\u00e8le\\n\",\n    \"test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\\n\",\n    \"print(f\\\"\\\\nPr\u00e9cision sur l'ensemble de test : {test_accuracy*100:.2f}%\\\")\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\\n\",\n   \"execution_count\": null,\\n\",\n   \"metadata\": {},\\n\",\n   \"source\": [\n    \"# Visualisation de la pr\u00e9cision et de la perte\\n\",\n    \"plt.figure(figsize=(12, 4))\\n\",\n    \"\\n\",\n    \"# Pr\u00e9cision\\n\",\n    \"plt.subplot(1, 2, 1)\\n\",\n    \"plt.plot(history.history['accuracy'], label='Pr\u00e9cision entra\u00eenement')\\n\",\n    \"plt.plot(history.history['val_accuracy'], label='Pr\u00e9cision validation')\\n\",\n    \"plt.title('Pr\u00e9cision du mod\u00e8le')\\n\",\n    \"plt.xlabel('\u00c9poque')\\n\",\n    \"plt.ylabel('Pr\u00e9cision')\\n\",\n    \"plt.legend()\\n\",\n    \"\\n\",\n    \"# Perte\\n\",\n    \"plt.subplot(1, 2, 2)\\n\",\n    \"plt.plot(history.history['loss'], label='Perte entra\u00eenement')\\n\",\n    \"plt.plot(history.history['val_loss'], label='Perte validation')\\n\",\n    \"plt.title('Perte du mod\u00e8le')\\n\",\n    \"plt.xlabel('\u00c9poque')\\n\",\n    \"plt.ylabel('Perte')\\n\",\n    \"plt.legend()\\n\",\n    \"\\n\",\n    \"plt.tight_layout()\\n\",\n    \"plt.show()\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\\n\",\n   \"execution_count\": null,\\n\",\n   \"metadata\": {},\\n\",\n   \"source\": [\n    \"# Pr\u00e9dictions et visualisation\\n\",\n    \"# Pr\u00e9dire sur quelques images de test\\n\",\n    \"predictions = model.predict(X_test[:10])\\n\",\n    \"\\n\",\n    \"plt.figure(figsize=(15, 6))\\n\",\n    \"for i in range(10):\\n\",\n    \"    plt.subplot(2, 10, i+1)\\n\",\n    \"    plt.imshow(X_test[i].reshape(28, 28), cmap='gray')\\n\",\n    \"    plt.axis('off')\\n\",\n    \"    \\n\",\n    \"    plt.subplot(2, 10, i+11)\\n\",\n    \"    plt.bar(range(10), predictions[i])\\n\",\n    \"    plt.title(f\\\"Pr\u00e9diction: {np.argmax(predictions[i])}\\\")\\n\",\n    \"    plt.xticks(range(10))\\n\",\n    \"    plt.ylim(0, 1)\\n\",\n    \"\\n\",\n    \"plt.suptitle(\\\"Pr\u00e9dictions du mod\u00e8le\\\")\\n\",\n    \"plt.tight_layout()\\n\",\n    \"plt.show()\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\\n\",\n   \"metadata\": {},\\n\",\n   \"source\": [\n    \"## \ud83e\udd14 Questions de r\u00e9flexion\\n\",\n    \"\\n\",\n    \"1. Que se passe-t-il si vous augmentez le nombre d'\u00e9poques ?\\n\",\n    \"2. Comment changeriez-vous l'architecture du r\u00e9seau pour am\u00e9liorer les performances ?\\n\",\n    \"3. Quelles diff\u00e9rences observez-vous entre la pr\u00e9cision d'entra\u00eenement et de validation ?\\n\",\n    \"\\n\",\n    \"## \ud83d\ude80 D\u00e9fis\\n\",\n    \"\\n\",\n    \"- Essayez de modifier le nombre de neurones dans les couches denses\\n\",\n    \"- Changez la fonction d'activation dans certaines couches\\n\",\n    \"- Ajoutez une couche de dropout pour r\u00e9duire le surapprentissage\"\n   ]\n  }\n ],\n \"metadata\": {\n  \"kernelspec\": {\n   \"display_name\": \"Python 3\",\n   \"language\": \"python\",\n   \"name\": \"python3\"\n  },\n  \"language_info\": {\n   \"name\": \"python\",\n   \"version\": \"3.8.0\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 2\n}\n</pre> {  \"cells\": [   {    \"cell_type\": \"markdown\",    \"metadata\": {},    \"source\": [     \"# \ud83d\ude80 Hello World du Deep Learning\\n\",     \"\\n\",     \"## Reconnaissance de chiffres manuscrits avec TensorFlow et Keras\\n\",     \"\\n\",     \"### Objectifs de ce notebook\\n\",     \"\\n\",     \"- Charger et pr\u00e9parer un jeu de donn\u00e9es de chiffres manuscrits\\n\",     \"- Cr\u00e9er un r\u00e9seau de neurones simple\\n\",     \"- Entra\u00eener le mod\u00e8le\\n\",     \"- Visualiser les r\u00e9sultats\\n\",     \"- Tester le mod\u00e8le avec vos propres dessins\"    ]   },   {    \"cell_type\": \"code\",    \"execution_count\": null,    \"metadata\": {},    \"source\": [     \"# Importation des biblioth\u00e8ques n\u00e9cessaires\\n\",     \"import numpy as np\\n\",     \"import matplotlib.pyplot as plt\\n\",     \"import tensorflow as tf\\n\",     \"from tensorflow import keras\\n\",     \"from tensorflow.keras import layers\\n\",     \"\\n\",     \"# V\u00e9rification de la version de TensorFlow\\n\",     \"print(f\\\"TensorFlow version: {tf.__version__}\\\")\\n\",     \"print(f\\\"Keras version: {keras.__version__}\\\")\\n\",     \"\\n\",     \"# V\u00e9rification du GPU (si disponible)\\n\",     \"print(\\\"GPU disponible :\\\", tf.test.is_gpu_available())\"    ]   },   {    \"cell_type\": \"code\",    \"execution_count\": null,    \"metadata\": {},    \"source\": [     \"# Chargement du dataset MNIST\\n\",     \"(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\\n\",     \"\\n\",     \"# Pr\u00e9traitement des donn\u00e9es\\n\",     \"X_train = X_train.reshape((60000, 28, 28, 1)) / 255.0\\n\",     \"X_test = X_test.reshape((10000, 28, 28, 1)) / 255.0\\n\",     \"\\n\",     \"# Conversion des labels en cat\u00e9gories\\n\",     \"y_train = keras.utils.to_categorical(y_train)\\n\",     \"y_test = keras.utils.to_categorical(y_test)\\n\",     \"\\n\",     \"# Affichage de quelques exemples\\n\",     \"plt.figure(figsize=(10, 2))\\n\",     \"for i in range(10):\\n\",     \"    plt.subplot(1, 10, i+1)\\n\",     \"    plt.imshow(X_train[i].reshape(28, 28), cmap='gray')\\n\",     \"    plt.axis('off')\\n\",     \"plt.suptitle(\\\"Exemples de chiffres manuscrits\\\")\\n\",     \"plt.show()\\n\",     \"\\n\",     \"print(f\\\"Nombre d'exemples d'entra\u00eenement : {X_train.shape[0]}\\\")\\n\",     \"print(f\\\"Nombre d'exemples de test : {X_test.shape[0]}\\\")\"    ]   },   {    \"cell_type\": \"code\",    \"execution_count\": null,    \"metadata\": {},    \"source\": [     \"# Cr\u00e9ation du mod\u00e8le de r\u00e9seau de neurones\\n\",     \"model = keras.Sequential([\\n\",     \"    # Couche de convolution\\n\",     \"    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\\n\",     \"    layers.MaxPooling2D((2, 2)),\\n\",     \"    \\n\",     \"    # Couche de convolution suppl\u00e9mentaire\\n\",     \"    layers.Conv2D(64, (3, 3), activation='relu'),\\n\",     \"    layers.MaxPooling2D((2, 2)),\\n\",     \"    \\n\",     \"    # Aplatissement\\n\",     \"    layers.Flatten(),\\n\",     \"    \\n\",     \"    # Couche dense\\n\",     \"    layers.Dense(64, activation='relu'),\\n\",     \"    \\n\",     \"    # Couche de sortie\\n\",     \"    layers.Dense(10, activation='softmax')\\n\",     \"])\\n\",     \"\\n\",     \"# Compilation du mod\u00e8le\\n\",     \"model.compile(\\n\",     \"    optimizer='adam',\\n\",     \"    loss='categorical_crossentropy',\\n\",     \"    metrics=['accuracy']\\n\",     \")\\n\",     \"\\n\",     \"# Affichage du r\u00e9sum\u00e9 du mod\u00e8le\\n\",     \"model.summary()\"    ]   },   {    \"cell_type\": \"code\",\\n\",    \"execution_count\": null,\\n\",    \"metadata\": {},\\n\",    \"source\": [     \"# Entra\u00eenement du mod\u00e8le\\n\",     \"# Note : Nombre d'\u00e9poques r\u00e9duit pour la d\u00e9monstration\\n\",     \"history = model.fit(\\n\",     \"    X_train, y_train,\\n\",     \"    epochs=5,\\n\",     \"    batch_size=64,\\n\",     \"    validation_split=0.2,\\n\",     \"    verbose=1\\n\",     \")\\n\",     \"\\n\",     \"# \u00c9valuation du mod\u00e8le\\n\",     \"test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\\n\",     \"print(f\\\"\\\\nPr\u00e9cision sur l'ensemble de test : {test_accuracy*100:.2f}%\\\")\"    ]   },   {    \"cell_type\": \"code\",\\n\",    \"execution_count\": null,\\n\",    \"metadata\": {},\\n\",    \"source\": [     \"# Visualisation de la pr\u00e9cision et de la perte\\n\",     \"plt.figure(figsize=(12, 4))\\n\",     \"\\n\",     \"# Pr\u00e9cision\\n\",     \"plt.subplot(1, 2, 1)\\n\",     \"plt.plot(history.history['accuracy'], label='Pr\u00e9cision entra\u00eenement')\\n\",     \"plt.plot(history.history['val_accuracy'], label='Pr\u00e9cision validation')\\n\",     \"plt.title('Pr\u00e9cision du mod\u00e8le')\\n\",     \"plt.xlabel('\u00c9poque')\\n\",     \"plt.ylabel('Pr\u00e9cision')\\n\",     \"plt.legend()\\n\",     \"\\n\",     \"# Perte\\n\",     \"plt.subplot(1, 2, 2)\\n\",     \"plt.plot(history.history['loss'], label='Perte entra\u00eenement')\\n\",     \"plt.plot(history.history['val_loss'], label='Perte validation')\\n\",     \"plt.title('Perte du mod\u00e8le')\\n\",     \"plt.xlabel('\u00c9poque')\\n\",     \"plt.ylabel('Perte')\\n\",     \"plt.legend()\\n\",     \"\\n\",     \"plt.tight_layout()\\n\",     \"plt.show()\"    ]   },   {    \"cell_type\": \"code\",\\n\",    \"execution_count\": null,\\n\",    \"metadata\": {},\\n\",    \"source\": [     \"# Pr\u00e9dictions et visualisation\\n\",     \"# Pr\u00e9dire sur quelques images de test\\n\",     \"predictions = model.predict(X_test[:10])\\n\",     \"\\n\",     \"plt.figure(figsize=(15, 6))\\n\",     \"for i in range(10):\\n\",     \"    plt.subplot(2, 10, i+1)\\n\",     \"    plt.imshow(X_test[i].reshape(28, 28), cmap='gray')\\n\",     \"    plt.axis('off')\\n\",     \"    \\n\",     \"    plt.subplot(2, 10, i+11)\\n\",     \"    plt.bar(range(10), predictions[i])\\n\",     \"    plt.title(f\\\"Pr\u00e9diction: {np.argmax(predictions[i])}\\\")\\n\",     \"    plt.xticks(range(10))\\n\",     \"    plt.ylim(0, 1)\\n\",     \"\\n\",     \"plt.suptitle(\\\"Pr\u00e9dictions du mod\u00e8le\\\")\\n\",     \"plt.tight_layout()\\n\",     \"plt.show()\"    ]   },   {    \"cell_type\": \"markdown\",\\n\",    \"metadata\": {},\\n\",    \"source\": [     \"## \ud83e\udd14 Questions de r\u00e9flexion\\n\",     \"\\n\",     \"1. Que se passe-t-il si vous augmentez le nombre d'\u00e9poques ?\\n\",     \"2. Comment changeriez-vous l'architecture du r\u00e9seau pour am\u00e9liorer les performances ?\\n\",     \"3. Quelles diff\u00e9rences observez-vous entre la pr\u00e9cision d'entra\u00eenement et de validation ?\\n\",     \"\\n\",     \"## \ud83d\ude80 D\u00e9fis\\n\",     \"\\n\",     \"- Essayez de modifier le nombre de neurones dans les couches denses\\n\",     \"- Changez la fonction d'activation dans certaines couches\\n\",     \"- Ajoutez une couche de dropout pour r\u00e9duire le surapprentissage\"    ]   }  ],  \"metadata\": {   \"kernelspec\": {    \"display_name\": \"Python 3\",    \"language\": \"python\",    \"name\": \"python3\"   },   \"language_info\": {    \"name\": \"python\",    \"version\": \"3.8.0\"   }  },  \"nbformat\": 4,  \"nbformat_minor\": 2 } <pre>\n  Cell In[2], line 106\n    \"cell_type\": \"code\",\\n\",\n                         ^\nSyntaxError: unexpected character after line continuation character\n</pre>"},{"location":"ressources/notebooks/hello-world-dl/","title":"\ud83d\ude80 Hello World du Deep Learning","text":""},{"location":"ressources/notebooks/hello-world-dl/#reconnaissance-de-chiffres-manuscrits-avec-tensorflow-et-keras","title":"Reconnaissance de chiffres manuscrits avec TensorFlow et Keras","text":""},{"location":"ressources/notebooks/hello-world-dl/#objectifs-de-ce-notebook","title":"Objectifs de ce notebook","text":"<ul> <li>Charger et pr\u00e9parer un jeu de donn\u00e9es de chiffres manuscrits</li> <li>Cr\u00e9er un r\u00e9seau de neurones simple</li> <li>Entra\u00eener le mod\u00e8le</li> <li>Visualiser les r\u00e9sultats</li> <li>Tester le mod\u00e8le avec vos propres dessins</li> </ul> <p>```python</p>"},{"location":"ressources/notebooks/hello-world-dl/#importation-des-bibliotheques-necessaires","title":"Importation des biblioth\u00e8ques n\u00e9cessaires","text":"<p>import numpy as np import matplotlib.pyplot as plt import tensorflow as tf from tensorflow import keras from tensorflow.keras import layers</p>"},{"location":"ressources/notebooks/hello-world-dl/#verification-de-la-version-de-tensorflow","title":"V\u00e9rification de la version de TensorFlow","text":"<p>print(f\"TensorFlow version: {tf.version}\") print(f\"Keras version: {keras.version}\")</p>"},{"location":"ressources/notebooks/hello-world-dl/#verification-du-gpu-si-disponible","title":"V\u00e9rification du GPU (si disponible)","text":"<p>print(\"GPU disponible :\", tf.test.is_gpu_available())</p>"},{"location":"ressources/notebooks/machine-learning-classique/","title":"Machine learning classique","text":"In\u00a0[\u00a0]: Copied! <pre>{\n \"cells\": [\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"# Classification avec Machine Learning classique\\n\",\n    \"\\n\",\n    \"Ce notebook illustre comment utiliser un algorithme de Machine Learning classique (Random Forest) pour classifier des chiffres manuscrits (dataset MNIST).\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Import des biblioth\u00e8ques n\u00e9cessaires\\n\",\n    \"import numpy as np\\n\",\n    \"import matplotlib.pyplot as plt\\n\",\n    \"import time\\n\",\n    \"from sklearn.ensemble import RandomForestClassifier\\n\",\n    \"from sklearn.model_selection import train_test_split\\n\",\n    \"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\\n\",\n    \"from sklearn.decomposition import PCA\\n\",\n    \"import seaborn as sns\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Chargement et pr\u00e9paration des donn\u00e9es MNIST\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Charger le dataset MNIST depuis scikit-learn\\n\",\n    \"from sklearn.datasets import fetch_openml\\n\",\n    \"mnist = fetch_openml('mnist_784', version=1, as_frame=False)\\n\",\n    \"X, y = mnist[\\\"data\\\"], mnist[\\\"target\\\"]\\n\",\n    \"X = X / 255.0  # Normalisation des valeurs de pixels entre 0 et 1\\n\",\n    \"y = y.astype(np.uint8)  # Conversion des labels en entiers\\n\",\n    \"\\n\",\n    \"# Afficher les dimensions des donn\u00e9es\\n\",\n    \"print(f\\\"X shape: {X.shape}\\\")\\n\",\n    \"print(f\\\"y shape: {y.shape}\\\")\\n\",\n    \"print(f\\\"Classes: {np.unique(y)}\\\")\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Visualisation de quelques exemples\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Afficher quelques exemples d'images\\n\",\n    \"plt.figure(figsize=(10, 5))\\n\",\n    \"for i in range(10):\\n\",\n    \"    plt.subplot(2, 5, i+1)\\n\",\n    \"    plt.imshow(X[i].reshape(28, 28), cmap='gray')\\n\",\n    \"    plt.title(f\\\"Label: {y[i]}\\\")\\n\",\n    \"    plt.axis('off')\\n\",\n    \"plt.tight_layout()\\n\",\n    \"plt.show()\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## R\u00e9duction de dimension pour le Machine Learning classique\\n\",\n    \"\\n\",\n    \"Pour acc\u00e9l\u00e9rer le traitement avec les algorithmes classiques, nous allons r\u00e9duire la dimensionnalit\u00e9 des donn\u00e9es avec PCA.\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Utiliser un sous-ensemble des donn\u00e9es pour la d\u00e9monstration\\n\",\n    \"X_sample = X[:10000]\\n\",\n    \"y_sample = y[:10000]\\n\",\n    \"\\n\",\n    \"# R\u00e9duction de dimension avec PCA\\n\",\n    \"n_components = 50  # R\u00e9duire de 784 \u00e0 50 dimensions\\n\",\n    \"pca = PCA(n_components=n_components)\\n\",\n    \"X_reduced = pca.fit_transform(X_sample)\\n\",\n    \"\\n\",\n    \"print(f\\\"Forme originale: {X_sample.shape}\\\")\\n\",\n    \"print(f\\\"Forme apr\u00e8s PCA: {X_reduced.shape}\\\")\\n\",\n    \"print(f\\\"Variance expliqu\u00e9e: {sum(pca.explained_variance_ratio_)*100:.2f}%\\\")\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## S\u00e9paration en ensembles d'entra\u00eenement et de test\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Division en ensembles d'entra\u00eenement et de test\\n\",\n    \"X_train, X_test, y_train, y_test = train_test_split(\\n\",\n    \"    X_reduced, y_sample, test_size=0.2, random_state=42\\n\",\n    \")\\n\",\n    \"\\n\",\n    \"print(f\\\"X_train shape: {X_train.shape}\\\")\\n\",\n    \"print(f\\\"X_test shape: {X_test.shape}\\\")\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Cr\u00e9ation et entra\u00eenement du mod\u00e8le Random Forest\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Cr\u00e9er un mod\u00e8le Random Forest\\n\",\n    \"n_estimators = 100  # Nombre d'arbres\\n\",\n    \"max_depth = 15      # Profondeur maximale des arbres\\n\",\n    \"\\n\",\n    \"rf_model = RandomForestClassifier(\\n\",\n    \"    n_estimators=n_estimators,\\n\",\n    \"    max_depth=max_depth,\\n\",\n    \"    random_state=42,\\n\",\n    \"    n_jobs=-1  # Utiliser tous les c\u0153urs disponibles\\n\",\n    \")\\n\",\n    \"\\n\",\n    \"# Mesurer le temps d'entra\u00eenement\\n\",\n    \"start_time = time.time()\\n\",\n    \"print(\\\"Entra\u00eenement du mod\u00e8le Random Forest...\\\")\\n\",\n    \"rf_model.fit(X_train, y_train)\\n\",\n    \"end_time = time.time()\\n\",\n    \"training_time = end_time - start_time\\n\",\n    \"\\n\",\n    \"print(f\\\"Temps d'entra\u00eenement: {training_time:.2f} secondes\\\")\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## \u00c9valuation du mod\u00e8le\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# \u00c9valuer le mod\u00e8le sur les donn\u00e9es de test\\n\",\n</pre> {  \"cells\": [   {    \"cell_type\": \"markdown\",    \"metadata\": {},    \"source\": [     \"# Classification avec Machine Learning classique\\n\",     \"\\n\",     \"Ce notebook illustre comment utiliser un algorithme de Machine Learning classique (Random Forest) pour classifier des chiffres manuscrits (dataset MNIST).\"    ]   },   {    \"cell_type\": \"code\",    \"execution_count\": null,    \"metadata\": {},    \"outputs\": [],    \"source\": [     \"# Import des biblioth\u00e8ques n\u00e9cessaires\\n\",     \"import numpy as np\\n\",     \"import matplotlib.pyplot as plt\\n\",     \"import time\\n\",     \"from sklearn.ensemble import RandomForestClassifier\\n\",     \"from sklearn.model_selection import train_test_split\\n\",     \"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\\n\",     \"from sklearn.decomposition import PCA\\n\",     \"import seaborn as sns\"    ]   },   {    \"cell_type\": \"markdown\",    \"metadata\": {},    \"source\": [     \"## Chargement et pr\u00e9paration des donn\u00e9es MNIST\"    ]   },   {    \"cell_type\": \"code\",    \"execution_count\": null,    \"metadata\": {},    \"outputs\": [],    \"source\": [     \"# Charger le dataset MNIST depuis scikit-learn\\n\",     \"from sklearn.datasets import fetch_openml\\n\",     \"mnist = fetch_openml('mnist_784', version=1, as_frame=False)\\n\",     \"X, y = mnist[\\\"data\\\"], mnist[\\\"target\\\"]\\n\",     \"X = X / 255.0  # Normalisation des valeurs de pixels entre 0 et 1\\n\",     \"y = y.astype(np.uint8)  # Conversion des labels en entiers\\n\",     \"\\n\",     \"# Afficher les dimensions des donn\u00e9es\\n\",     \"print(f\\\"X shape: {X.shape}\\\")\\n\",     \"print(f\\\"y shape: {y.shape}\\\")\\n\",     \"print(f\\\"Classes: {np.unique(y)}\\\")\"    ]   },   {    \"cell_type\": \"markdown\",    \"metadata\": {},    \"source\": [     \"## Visualisation de quelques exemples\"    ]   },   {    \"cell_type\": \"code\",    \"execution_count\": null,    \"metadata\": {},    \"outputs\": [],    \"source\": [     \"# Afficher quelques exemples d'images\\n\",     \"plt.figure(figsize=(10, 5))\\n\",     \"for i in range(10):\\n\",     \"    plt.subplot(2, 5, i+1)\\n\",     \"    plt.imshow(X[i].reshape(28, 28), cmap='gray')\\n\",     \"    plt.title(f\\\"Label: {y[i]}\\\")\\n\",     \"    plt.axis('off')\\n\",     \"plt.tight_layout()\\n\",     \"plt.show()\"    ]   },   {    \"cell_type\": \"markdown\",    \"metadata\": {},    \"source\": [     \"## R\u00e9duction de dimension pour le Machine Learning classique\\n\",     \"\\n\",     \"Pour acc\u00e9l\u00e9rer le traitement avec les algorithmes classiques, nous allons r\u00e9duire la dimensionnalit\u00e9 des donn\u00e9es avec PCA.\"    ]   },   {    \"cell_type\": \"code\",    \"execution_count\": null,    \"metadata\": {},    \"outputs\": [],    \"source\": [     \"# Utiliser un sous-ensemble des donn\u00e9es pour la d\u00e9monstration\\n\",     \"X_sample = X[:10000]\\n\",     \"y_sample = y[:10000]\\n\",     \"\\n\",     \"# R\u00e9duction de dimension avec PCA\\n\",     \"n_components = 50  # R\u00e9duire de 784 \u00e0 50 dimensions\\n\",     \"pca = PCA(n_components=n_components)\\n\",     \"X_reduced = pca.fit_transform(X_sample)\\n\",     \"\\n\",     \"print(f\\\"Forme originale: {X_sample.shape}\\\")\\n\",     \"print(f\\\"Forme apr\u00e8s PCA: {X_reduced.shape}\\\")\\n\",     \"print(f\\\"Variance expliqu\u00e9e: {sum(pca.explained_variance_ratio_)*100:.2f}%\\\")\"    ]   },   {    \"cell_type\": \"markdown\",    \"metadata\": {},    \"source\": [     \"## S\u00e9paration en ensembles d'entra\u00eenement et de test\"    ]   },   {    \"cell_type\": \"code\",    \"execution_count\": null,    \"metadata\": {},    \"outputs\": [],    \"source\": [     \"# Division en ensembles d'entra\u00eenement et de test\\n\",     \"X_train, X_test, y_train, y_test = train_test_split(\\n\",     \"    X_reduced, y_sample, test_size=0.2, random_state=42\\n\",     \")\\n\",     \"\\n\",     \"print(f\\\"X_train shape: {X_train.shape}\\\")\\n\",     \"print(f\\\"X_test shape: {X_test.shape}\\\")\"    ]   },   {    \"cell_type\": \"markdown\",    \"metadata\": {},    \"source\": [     \"## Cr\u00e9ation et entra\u00eenement du mod\u00e8le Random Forest\"    ]   },   {    \"cell_type\": \"code\",    \"execution_count\": null,    \"metadata\": {},    \"outputs\": [],    \"source\": [     \"# Cr\u00e9er un mod\u00e8le Random Forest\\n\",     \"n_estimators = 100  # Nombre d'arbres\\n\",     \"max_depth = 15      # Profondeur maximale des arbres\\n\",     \"\\n\",     \"rf_model = RandomForestClassifier(\\n\",     \"    n_estimators=n_estimators,\\n\",     \"    max_depth=max_depth,\\n\",     \"    random_state=42,\\n\",     \"    n_jobs=-1  # Utiliser tous les c\u0153urs disponibles\\n\",     \")\\n\",     \"\\n\",     \"# Mesurer le temps d'entra\u00eenement\\n\",     \"start_time = time.time()\\n\",     \"print(\\\"Entra\u00eenement du mod\u00e8le Random Forest...\\\")\\n\",     \"rf_model.fit(X_train, y_train)\\n\",     \"end_time = time.time()\\n\",     \"training_time = end_time - start_time\\n\",     \"\\n\",     \"print(f\\\"Temps d'entra\u00eenement: {training_time:.2f} secondes\\\")\"    ]   },   {    \"cell_type\": \"markdown\",    \"metadata\": {},    \"source\": [     \"## \u00c9valuation du mod\u00e8le\"    ]   },   {    \"cell_type\": \"code\",    \"execution_count\": null,    \"metadata\": {},    \"outputs\": [],    \"source\": [     \"# \u00c9valuer le mod\u00e8le sur les donn\u00e9es de test\\n\","},{"location":"seance1/","title":"S\u00e9ance 1 : Introduction au Deep Learning par l'exp\u00e9rimentation","text":""},{"location":"seance1/#objectifs-de-la-seance","title":"Objectifs de la s\u00e9ance","text":"<p>\u00c0 l'issue de cette s\u00e9ance, vous serez capable de :</p> <ul> <li>Manipuler concr\u00e8tement un r\u00e9seau de neurones simple</li> <li>Comprendre les diff\u00e9rences entre Machine Learning classique et Deep Learning</li> <li>Expliquer le fonctionnement de base d'un r\u00e9seau de neurones</li> <li>Appliquer des techniques d'am\u00e9lioration d'un mod\u00e8le de Deep Learning</li> </ul>"},{"location":"seance1/#programme-4h","title":"Programme (4h)","text":"<p>Cette s\u00e9ance se d\u00e9roule en quatre phases distinctes, chacune con\u00e7ue pour vous faire d\u00e9couvrir le Deep Learning par la pratique plut\u00f4t que par la th\u00e9orie.</p>"},{"location":"seance1/#phase-1-mise-en-situation-pratique-1h","title":"Phase 1 : Mise en situation pratique (1h)","text":"<p>D\u00e9couvrez le Deep Learning \u00e0 travers des exemples concrets, sans vous pr\u00e9occuper de la th\u00e9orie pour le moment.</p> <ul> <li>D\u00e9monstrations d'applications concr\u00e8tes (GitHub Copilot, reconnaissance d'objets...)</li> <li>Premier contact avec un r\u00e9seau de neurones simple</li> <li>Challenge d'exp\u00e9rimentation guid\u00e9e sur un mod\u00e8le MNIST</li> </ul>"},{"location":"seance1/#phase-2-decouverte-des-concepts-1h30","title":"Phase 2 : D\u00e9couverte des concepts (1h30)","text":"<p>Comparez les approches du Machine Learning classique et du Deep Learning pour comprendre leurs diff\u00e9rences fondamentales.</p> <ul> <li>Atelier \"Bo\u00eete noire\" : exploration parall\u00e8le des deux approches</li> <li>D\u00e9fi de g\u00e9n\u00e9ralisation sur des donn\u00e9es modifi\u00e9es</li> <li>Exploration interactive d'un neurone et d'un r\u00e9seau simple</li> </ul> <p>Notebooks associ\u00e9s : - Machine Learning classique - Deep Learning - Anatomie d'un r\u00e9seau</p> <p>Ressource \u00e0 compl\u00e9ter : Tableau comparatif ML vs DL</p>"},{"location":"seance1/#phase-3-mini-projet-collaboratif-1h","title":"Phase 3 : Mini-projet collaboratif (1h)","text":"<p>Mettez en pratique vos connaissances en am\u00e9liorant un mod\u00e8le de Deep Learning en \u00e9quipe.</p> <ul> <li>Challenge d'am\u00e9lioration d'un mod\u00e8le CNN pour MNIST</li> <li>Exp\u00e9rimentation avec diff\u00e9rentes architectures et hyperparam\u00e8tres</li> <li>Partage des r\u00e9sultats et des d\u00e9couvertes</li> </ul> <p>Notebook associ\u00e9 : Template du mod\u00e8le \u00e0 am\u00e9liorer</p>"},{"location":"seance1/#phase-4-evaluation-et-synthese-30min","title":"Phase 4 : \u00c9valuation et synth\u00e8se (30min)","text":"<p>Consolidez vos connaissances et \u00e9valuez votre compr\u00e9hension de mani\u00e8re autonome.</p> <ul> <li>QCM sur les concepts fondamentaux</li> <li>Synth\u00e8se personnelle \u00e0 r\u00e9diger</li> <li>Sch\u00e9ma conceptuel \u00e0 compl\u00e9ter</li> </ul> <p>Ressources : - QCM d'\u00e9valuation - Sch\u00e9ma \u00e0 compl\u00e9ter</p>"},{"location":"seance1/#competences-bts-sio-slam-developpees","title":"Comp\u00e9tences BTS SIO SLAM d\u00e9velopp\u00e9es","text":"<p>Cette s\u00e9ance vous permet d'acqu\u00e9rir plusieurs comp\u00e9tences du r\u00e9f\u00e9rentiel BTS SIO SLAM :</p> Comp\u00e9tence Description Activit\u00e9s associ\u00e9es B1.3 Gestion des donn\u00e9es Manipulation des datasets d'images B2.2 Conception et d\u00e9veloppement Am\u00e9lioration des mod\u00e8les de Deep Learning B2.3 Conception et d\u00e9veloppement d'IHM Analyse des interfaces de notebooks interactifs B3.2 V\u00e9rification et validation \u00c9valuation de la performance des mod\u00e8les"},{"location":"seance1/#prerequis","title":"Pr\u00e9requis","text":"<p>Pour cette s\u00e9ance, vous aurez besoin de :</p> <ul> <li>Un ordinateur avec connexion internet</li> <li>Un compte Google pour acc\u00e9der \u00e0 Google Colab</li> <li>Des connaissances de base en Python</li> </ul>"},{"location":"seance1/#support-technique","title":"Support technique","text":"<p>Si vous rencontrez des difficult\u00e9s :</p> <ol> <li>Consultez la FAQ disponible ici</li> <li>Demandez de l'aide \u00e0 vos camarades</li> <li>Sollicitez l'enseignant pour les probl\u00e8mes persistants</li> </ol>"},{"location":"seance1/#preparation-a-la-seance-suivante","title":"Pr\u00e9paration \u00e0 la s\u00e9ance suivante","text":"<p>La prochaine s\u00e9ance portera sur les applications professionnelles des diff\u00e9rents types de r\u00e9seaux neuronaux. Pour vous y pr\u00e9parer, nous vous recommandons de :</p> <ul> <li>R\u00e9viser les concepts vus aujourd'hui</li> <li>Consulter le glossaire du Deep Learning</li> </ul> <p>Pr\u00eat \u00e0 plonger dans le monde du Deep Learning ? Commen\u00e7ons par la mise en situation pratique !</p>"},{"location":"seance1/structure/","title":"Structure","text":"<p>seance1/ \u2502 \u251c\u2500\u2500 index.md                                       # Page principale de la s\u00e9ance 1 \u2502 \u251c\u2500\u2500 partie1-mise-en-situation/                     # Phase 1: Mise en situation pratique \u2502   \u251c\u2500\u2500 partie1-mise-en-situation.md               # Guide de la mise en situation \u2502   \u251c\u2500\u2500 hello-world-dl.ipynb                       # Notebook \"Hello World du Deep Learning\" \u2502   \u251c\u2500\u2500 presentation-slides.pdf                    # Slides de pr\u00e9sentation des exemples \u2502   \u2514\u2500\u2500 images/                                    # Images pour les d\u00e9monstrations \u2502 \u251c\u2500\u2500 partie2-decouverte-concepts/                   # Phase 2: D\u00e9couverte des concepts \u2502   \u251c\u2500\u2500 partie2-decouverte-concepts.md             # Guide pour la d\u00e9couverte des concepts \u2502   \u251c\u2500\u2500 notebooks/ \u2502   \u2502   \u251c\u2500\u2500 machine-learning-classique.ipynb       # Notebook ML classique \u2502   \u2502   \u2514\u2500\u2500 deep-learning.ipynb                    # Notebook Deep Learning \u2502   \u251c\u2500\u2500 fiche-comparaison-ml-dl.pdf                # Fiche \u00e0 compl\u00e9ter pour la comparaison \u2502   \u2514\u2500\u2500 datasets/                                  # Datasets pour les exp\u00e9rimentations \u2502 \u251c\u2500\u2500 partie3-mini-projet/                           # Phase 3: Mini-projet collaboratif \u2502   \u251c\u2500\u2500 partie3-mini-projet.md                     # Guide du mini-projet \u2502   \u251c\u2500\u2500 model-template.ipynb                       # Notebook template du mod\u00e8le \u2502   \u2514\u2500\u2500 challenge-instructions.pdf                 # Instructions du challenge \u2502 \u251c\u2500\u2500 partie4-debrief/                               # Phase 4: D\u00e9brief et conceptualisation \u2502   \u251c\u2500\u2500 partie4-debrief.md                         # Guide du d\u00e9brief \u2502   \u2514\u2500\u2500 glossaire-dl-interactif.pdf                # Glossaire interactif \u00e0 compl\u00e9ter \u2502 \u251c\u2500\u2500 tp-guid\u00e9/                                      # TP guid\u00e9 sur les r\u00e9seaux de neurones \u2502   \u251c\u2500\u2500 anatomie-reseau.ipynb                      # Notebook sur l'anatomie d'un r\u00e9seau \u2502   \u2514\u2500\u2500 schema-reseau-annoter.pdf                  # Sch\u00e9ma \u00e0 annoter \u2502 \u2514\u2500\u2500 ressources/                                    # Ressources communes     \u251c\u2500\u2500 fiches/     \u2502   \u251c\u2500\u2500 qcm-evaluation.md                   # QCM d'\u00e9valuation     \u2502   \u251c\u2500\u2500 schema-a-completer.md               # Sch\u00e9ma conceptuel \u00e0 compl\u00e9ter     \u2502   \u251c\u2500\u2500 fiche-observations.pdf                 # Fiche d'observations     \u2502   \u251c\u2500\u2500 comparaison-ml-dl.pdf                  # Fiche de comparaison ML vs DL     \u2502   \u2514\u2500\u2500 glossaire-dl.pdf                       # Glossaire du Deep Learning     \u2514\u2500\u2500 images/         \u251c\u2500\u2500 convolution-principle.png              # Image explicative des convolutions         \u251c\u2500\u2500 rnn-principle.png                      # Image explicative des RNN         \u2514\u2500\u2500 autres images explicatives...</p>"},{"location":"seance1/partie1-mise-en-situation/dataset-MNIST/","title":"dataset MNIST","text":"<p>Challenge d'exp\u00e9rimentation guid\u00e9e sur un mod\u00e8le MNIST</p> <p>Suivez les instructions dans le notebook pour :</p> <ul> <li>Charger le dataset MNIST (chiffres manuscrits)</li> <li>Construire un r\u00e9seau de neurones simple</li> <li>Entra\u00eener le mod\u00e8le et observer son apprentissage</li> <li>Tester le mod\u00e8le sur de nouvelles images</li> </ul> <p>Compl\u00e9tez la fiche d'observations au fur et \u00e0 mesure.</p>"},{"location":"seance1/partie1-mise-en-situation/dataset-MNIST/#instructions-etape-par-etape","title":"Instructions \u00e9tape par \u00e9tape","text":""},{"location":"seance1/partie1-mise-en-situation/dataset-MNIST/#exploration-des-donnees-5-min","title":"Exploration des donn\u00e9es (5 min)","text":"<ul> <li>Ex\u00e9cutez les cellules d'importation et de chargement des donn\u00e9es</li> <li>Observez quelques exemples d'images de chiffres manuscrits</li> <li>Notez la taille du dataset et le format des images</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/dataset-MNIST/#construction-du-modele-10-min","title":"Construction du mod\u00e8le (10 min)","text":"<ul> <li>Identifiez la cellule qui d\u00e9finit l'architecture du r\u00e9seau</li> <li>Observez la structure : couche d'entr\u00e9e, couche cach\u00e9e, couche de sortie</li> <li>Notez les dimensions et les fonctions d'activation</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/dataset-MNIST/#entrainement-du-modele-10-min","title":"Entra\u00eenement du mod\u00e8le (10 min)","text":"<ul> <li>Lancez l'entra\u00eenement en ex\u00e9cutant la cellule correspondante</li> <li>Observez l'\u00e9volution de la pr\u00e9cision et de la perte (loss)</li> <li>Notez le temps d'entra\u00eenement</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/dataset-MNIST/#test-du-modele-5-min","title":"Test du mod\u00e8le (5 min)","text":"<ul> <li>Testez le mod\u00e8le sur les donn\u00e9es de validation</li> <li>Observez la matrice de confusion (quelles classes sont confondues)</li> <li>Si disponible, utilisez l'interface de dessin pour tester vos propres chiffres</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/dataset-MNIST/#challenge-dexperimentation-15-min","title":"Challenge d'exp\u00e9rimentation (15 min)","text":"<p>\u00c0 vous de jouer ! Modifiez le mod\u00e8le et observez les effets sur ses performances.</p>"},{"location":"seance1/partie1-mise-en-situation/dataset-MNIST/#experience-1-variation-du-nombre-depoques","title":"Exp\u00e9rience 1 : Variation du nombre d'\u00e9poques","text":"<ul> <li>Modifiez la variable <code>epochs</code> \u00e0 5, 10 puis 20</li> <li>Observez l'impact sur la pr\u00e9cision et le temps d'entra\u00eenement</li> <li>Question : Y a-t-il un nombre optimal d'\u00e9poques ?</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/dataset-MNIST/#experience-2-modification-de-larchitecture","title":"Exp\u00e9rience 2 : Modification de l'architecture","text":"<ul> <li>Changez le nombre de neurones dans la couche cach\u00e9e (32, 64, 128, 256)</li> <li>Ajoutez une seconde couche cach\u00e9e (un exemple est fourni en commentaire)</li> <li>Question : Une architecture plus complexe donne-t-elle toujours de meilleurs r\u00e9sultats ?</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/dataset-MNIST/#experience-3-changement-de-la-fonction-dactivation","title":"Exp\u00e9rience 3 : Changement de la fonction d'activation","text":"<ul> <li>Testez diff\u00e9rentes fonctions d'activation ('relu', 'sigmoid', 'tanh')</li> <li>Observez l'impact sur la vitesse d'apprentissage et la pr\u00e9cision finale</li> <li>Question : Quelle fonction d'activation semble la plus adapt\u00e9e pour ce probl\u00e8me ?</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/dataset-MNIST/#conclusion-et-transition-5-min","title":"Conclusion et transition (5 min)","text":"<ul> <li>Sauvegardez votre notebook avec vos exp\u00e9rimentations</li> <li>Compl\u00e9tez enti\u00e8rement votre fiche d'observations</li> <li>Pr\u00e9parez-vous \u00e0 partager vos d\u00e9couvertes</li> </ul> <p>Ce que nous venons d'observer :</p> <ul> <li>Les r\u00e9seaux de neurones apprennent \u00e0 partir d'exemples</li> <li>Leurs performances d\u00e9pendent de nombreux param\u00e8tres ajustables</li> <li>Le processus d'entra\u00eenement am\u00e9liore progressivement la pr\u00e9cision</li> </ul> <p>Dans la prochaine phase, nous allons comparer cette approche avec le Machine Learning classique et comprendre plus en d\u00e9tail le fonctionnement des r\u00e9seaux de neurones.</p> <p>Continuer vers la Phase 2 : D\u00e9couverte des concepts</p>"},{"location":"seance1/partie1-mise-en-situation/dataset-MNIST/#annexe-contenu-du-notebook-hello-world-du-deep-learning","title":"Annexe : Contenu du notebook \"Hello World du Deep Learning\"","text":"<p>Le notebook que vous allez explorer contient les sections suivantes :</p>"},{"location":"seance1/partie1-mise-en-situation/dataset-MNIST/#1-importation-des-bibliotheques","title":"1. Importation des biblioth\u00e8ques","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.utils import to_categorical\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report\n</code></pre>"},{"location":"seance1/partie1-mise-en-situation/dataset-MNIST/#2-chargement-et-preparation-des-donnees","title":"2. Chargement et pr\u00e9paration des donn\u00e9es","text":"<p>Nous utilisons le dataset MNIST, qui contient 70 000 images de chiffres manuscrits en niveaux de gris (28x28 pixels).</p> <pre><code># Chargement des donn\u00e9es\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# Affichage des dimensions\nprint(f\"Donn\u00e9es d'entra\u00eenement: {x_train.shape} images, labels: {y_train.shape}\")\nprint(f\"Donn\u00e9es de test: {x_test.shape} images, labels: {y_test.shape}\")\n</code></pre> <p>Visualisation des exemples d'images :</p> <pre><code># Afficher 5 exemples d'images\nplt.figure(figsize=(10, 2))\nfor i in range(5):\n    plt.subplot(1, 5, i+1)\n    plt.imshow(x_train[i], cmap='gray')\n    plt.title(f\"Label: {y_train[i]}\")\n    plt.axis('off')\nplt.tight_layout()\nplt.show()\n</code></pre> <p>Pr\u00e9paration des donn\u00e9es pour l'entra\u00eenement :</p> <pre><code># Normalisation des pixels (de 0-255 \u00e0 0-1)\nx_train = x_train.astype(\"float32\") / 255\nx_test = x_test.astype(\"float32\") / 255\n\n# Reshape des images en vecteurs (28x28 -&gt; 784)\nx_train = x_train.reshape(60000, 784)\nx_test = x_test.reshape(10000, 784)\n\n# One-hot encoding des labels (transformer les chiffres en vecteurs)\ny_train = to_categorical(y_train, 10)\ny_test = to_categorical(y_test, 10)\n\nprint(\"Forme des donn\u00e9es apr\u00e8s pr\u00e9paration:\")\nprint(f\"x_train: {x_train.shape}\")\nprint(f\"y_train: {y_train.shape}\")\n</code></pre>"},{"location":"seance1/partie1-mise-en-situation/dataset-MNIST/#3-construction-du-modele","title":"3. Construction du mod\u00e8le","text":"<p>Nous allons cr\u00e9er un r\u00e9seau de neurones simple avec : - Une couche d'entr\u00e9e (784 neurones pour les 784 pixels) - Une couche cach\u00e9e (64 neurones) - Une couche de sortie (10 neurones pour les 10 chiffres)</p> <pre><code># Construction du mod\u00e8le\nmodel = keras.Sequential([\n    # Couche d'entr\u00e9e -&gt; couche cach\u00e9e\n    layers.Dense(64, activation=\"relu\", input_shape=(784,)),\n\n    # Couche cach\u00e9e -&gt; couche de sortie\n    layers.Dense(10, activation=\"softmax\")\n])\n\n# R\u00e9sum\u00e9 du mod\u00e8le\nmodel.summary()\n</code></pre> <p>Compilation du mod\u00e8le avec les param\u00e8tres d'entra\u00eenement :</p> <pre><code># Compilation du mod\u00e8le\nmodel.compile(\n    optimizer=\"adam\",\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n</code></pre>"},{"location":"seance1/partie1-mise-en-situation/dataset-MNIST/#4-entrainement-du-modele","title":"4. Entra\u00eenement du mod\u00e8le","text":"<pre><code># D\u00e9finition des param\u00e8tres d'entra\u00eenement\nbatch_size = 128\nepochs = 5\n\n# Entra\u00eenement du mod\u00e8le\nhistory = model.fit(\n    x_train, y_train,\n    batch_size=batch_size,\n    epochs=epochs,\n    validation_split=0.1,\n    verbose=1\n)\n</code></pre> <p>Visualisation de l'\u00e9volution de l'entra\u00eenement :</p> <pre><code># Visualisation de l'\u00e9volution de l'entra\u00eenement\nplt.figure(figsize=(12, 4))\n\n# \u00c9volution de la pr\u00e9cision\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Entra\u00eenement')\nplt.plot(history.history['val_accuracy'], label='Validation')\nplt.title('Pr\u00e9cision')\nplt.xlabel('\u00c9poque')\nplt.ylabel('Pr\u00e9cision')\nplt.legend()\n\n# \u00c9volution de la perte\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Entra\u00eenement')\nplt.plot(history.history['val_loss'], label='Validation')\nplt.title('Perte (Loss)')\nplt.xlabel('\u00c9poque')\nplt.ylabel('Perte')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"seance1/partie1-mise-en-situation/dataset-MNIST/#5-evaluation-du-modele","title":"5. \u00c9valuation du mod\u00e8le","text":"<pre><code># \u00c9valuation sur les donn\u00e9es de test\ntest_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\nprint(f\"Pr\u00e9cision sur les donn\u00e9es de test: {test_acc:.4f}\")\n</code></pre> <p>Examen d\u00e9taill\u00e9 des pr\u00e9dictions :</p> <pre><code># Faire des pr\u00e9dictions\ny_pred = model.predict(x_test)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_true_classes = np.argmax(y_test, axis=1)\n\n# Matrice de confusion\nplt.figure(figsize=(10, 8))\ncm = confusion_matrix(y_true_classes, y_pred_classes)\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Pr\u00e9diction')\nplt.ylabel('R\u00e9alit\u00e9')\nplt.title('Matrice de confusion')\nplt.show()\n\n# Rapport de classification\nprint(\"Rapport de classification :\")\nprint(classification_report(y_true_classes, y_pred_classes))\n</code></pre>"},{"location":"seance1/partie1-mise-en-situation/dataset-MNIST/#6-visualisation-des-predictions","title":"6. Visualisation des pr\u00e9dictions","text":"<pre><code># S\u00e9lectionner quelques exemples al\u00e9atoires\nnum_examples = 5\nexample_indices = np.random.choice(len(x_test), num_examples, replace=False)\n\nplt.figure(figsize=(15, 3))\nfor i, idx in enumerate(example_indices):\n    # Afficher l'image\n    plt.subplot(1, num_examples, i+1)\n    img = x_test[idx].reshape(28, 28)\n    plt.imshow(img, cmap='gray')\n\n    # Pr\u00e9diction\n    pred = y_pred[idx]\n    pred_class = np.argmax(pred)\n    true_class = y_true_classes[idx]\n\n    # Titre avec pr\u00e9diction et confiance\n    title = f\"Pr\u00e9dit: {pred_class}\\n\"\n    title += f\"R\u00e9el: {true_class}\\n\"\n    title += f\"Confiance: {pred[pred_class]:.2f}\"\n    plt.title(title, color=(\"green\" if pred_class == true_class else \"red\"))\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"seance1/partie1-mise-en-situation/dataset-MNIST/#7-experimentations","title":"7. Exp\u00e9rimentations","text":"<pre><code># Modifier le nombre d'\u00e9poques\n# epochs = 10  # Essayez avec 5, 10, 20 \u00e9poques\n\n# Modifier l'architecture du r\u00e9seau\n\"\"\"\nmodel = keras.Sequential([\n    # Couche d'entr\u00e9e -&gt; premi\u00e8re couche cach\u00e9e\n    layers.Dense(128, activation=\"relu\", input_shape=(784,)),\n\n    # Deuxi\u00e8me couche cach\u00e9e (ajout d'une couche)\n    layers.Dense(64, activation=\"relu\"),\n\n    # Couche cach\u00e9e -&gt; couche de sortie\n    layers.Dense(10, activation=\"softmax\")\n])\n\"\"\"\n\n# Changer la fonction d'activation\n\"\"\"\nmodel = keras.Sequential([\n    # Essayez avec 'relu', 'sigmoid', 'tanh'\n    layers.Dense(64, activation=\"tanh\", input_shape=(784,)),\n    layers.Dense(10, activation=\"softmax\")\n])\n\"\"\"\n</code></pre>"},{"location":"seance1/partie1-mise-en-situation/dataset-MNIST/#8-interface-de-dessin-interactive","title":"8. Interface de dessin interactive","text":"<p>Le notebook inclut une interface de dessin permettant de tester le mod\u00e8le avec vos propres dessins de chiffres (disponible dans Google Colab).</p>"},{"location":"seance1/partie1-mise-en-situation/demonstrations/","title":"Applications du Deep Learning","text":""},{"location":"seance1/partie1-mise-en-situation/demonstrations/#demonstrations-pratiques","title":"D\u00e9monstrations pratiques","text":""},{"location":"seance1/partie1-mise-en-situation/demonstrations/#demonstration-1-github-copilot","title":"D\u00e9monstration 1 : GitHub Copilot","text":"<p>GitHub Copilot utilise le Deep Learning pour g\u00e9n\u00e9rer des suggestions de code. Observez comment il peut : - Entra\u00een\u00e9 sur des millions de d\u00e9p\u00f4ts GitHub publics - Utilise un mod\u00e8le de langage bas\u00e9 sur des r\u00e9seaux neuronaux - Analyse le contexte (code existant, commentaires, nom des fonctions) - G\u00e9n\u00e8re des suggestions pertinentes</p>"},{"location":"seance1/partie1-mise-en-situation/demonstrations/#github-copilot-exemples","title":"GitHub Copilot - Exemples","text":"<p>Exemple 1 : G\u00e9n\u00e9ration \u00e0 partir d'un commentaire <pre><code># Fonction qui calcule la factorielle d'un nombre n de fa\u00e7on r\u00e9cursive\ndef factorielle(n):\n    if n &lt;= 1:\n        return 1\n    else:\n        return n * factorielle(n-1)\n</code></pre></p> <p>Exemple 2 : Compl\u00e9tion de code existant <pre><code>def trier_par_age(personnes):\n    # Trie la liste de personnes par \u00e2ge croissant\n    return sorted(personnes, key=lambda personne: personne['age'])\n</code></pre></p>"},{"location":"seance1/partie1-mise-en-situation/demonstrations/#github-copilot-exemples-suite","title":"GitHub Copilot - Exemples (suite)","text":"<p>Exemple 3 : G\u00e9n\u00e9ration de tests <pre><code># Tests unitaires pour la fonction factorielle\ndef test_factorielle():\n    assert factorielle(0) == 1\n    assert factorielle(1) == 1\n    assert factorielle(5) == 120\n    assert factorielle(10) == 3628800\n</code></pre></p>"},{"location":"seance1/partie1-mise-en-situation/demonstrations/#reflexion-impact-sur-le-developpement-logiciel","title":"R\u00e9flexion : Impact sur le d\u00e9veloppement logiciel","text":"<ul> <li>Comment ces outils changent-ils la nature du travail de d\u00e9veloppeur ?</li> <li>Quelles comp\u00e9tences deviennent plus importantes ?</li> <li>Limites et risques potentiels ?</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/demonstrations/#demonstration-2-reconnaissance-dobjets","title":"D\u00e9monstration 2 : Reconnaissance d'objets","text":"<p>Une application de Deep Learning peut identifier des objets dans des photos ou vid\u00e9os en temps r\u00e9el :</p> <ul> <li>Nous allons utiliser l'application Teachable Machine </li> <li>Observez la d\u00e9tection en temps r\u00e9el des objets pr\u00e9sents dans la salle</li> <li>Notez le niveau de confiance (pourcentage) pour chaque pr\u00e9diction</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/demonstrations/#comment-ca-fonctionne","title":"Comment \u00e7a fonctionne ?","text":"<ul> <li>Utilise des r\u00e9seaux neuronaux convolutifs (CNN)</li> <li>Entra\u00een\u00e9 sur des millions d'images labellis\u00e9es</li> <li>D\u00e9tecte les caract\u00e9ristiques visuelles \u00e0 diff\u00e9rents niveaux d'abstraction</li> <li>Identifie et localise les objets dans l'image</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/demonstrations/#reconnaissance-dobjets-observation","title":"Reconnaissance d'objets - Observation","text":""},{"location":"seance1/partie1-mise-en-situation/demonstrations/#ce-que-nous-allons-observer","title":"Ce que nous allons observer","text":"<ul> <li>Reconnaissance en temps r\u00e9el</li> <li>Niveau de confiance des pr\u00e9dictions</li> <li>Robustesse face aux variations (angle, \u00e9clairage)</li> </ul> <ul> <li>Le mod\u00e8le identifie plusieurs objets simultan\u00e9ment</li> <li>Chaque objet est encadr\u00e9 et \u00e9tiquet\u00e9</li> <li>Un score de confiance est associ\u00e9 \u00e0 chaque pr\u00e9diction</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/demonstrations/#quest-ce-que-la-convolution","title":"Qu'est-ce que la convolution ?","text":"<ul> <li>Le filtre se d\u00e9place sur l'image et effectue des calculs \u00e0 chaque position</li> <li>Chaque case du filtre est multipli\u00e9e par la case correspondante de l'image</li> <li>Les r\u00e9sultats sont additionn\u00e9s pour obtenir une seule valeur</li> <li>Cette op\u00e9ration se r\u00e9p\u00e8te pour cr\u00e9er une nouvelle \"carte de caract\u00e9ristiques\"</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/demonstrations/#fonctionnement-interne-dun-cnn","title":"Fonctionnement interne d'un CNN","text":"<ol> <li>Convolution : application de filtres pour d\u00e9tecter des caract\u00e9ristiques</li> <li>Pooling : r\u00e9duction de la dimension spatiale</li> <li>Activation : introduction de non-lin\u00e9arit\u00e9 (ReLU)</li> <li>Classification : couches enti\u00e8rement connect\u00e9es pour la pr\u00e9diction</li> </ol> <p>Ces op\u00e9rations permettent d'extraire automatiquement des caract\u00e9ristiques de plus en plus abstraites.</p>"},{"location":"seance1/partie1-mise-en-situation/demonstrations/#comment-un-cnn-reconnait-les-images","title":"Comment un CNN reconna\u00eet les images","text":"<ul> <li>L'ordinateur analyse l'image \u00e9tape par \u00e9tape, comme notre cerveau</li> <li>Il d\u00e9tecte d'abord les contours simples, puis les formes</li> <li>Il combine ces informations pour comprendre ce qu'il \"voit\"</li> <li>De simples pixels \u00e0 une identification compl\u00e8te</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/demonstrations/#demonstration-3-generation-de-texte","title":"D\u00e9monstration 3 : G\u00e9n\u00e9ration de texte","text":"<p>Les mod\u00e8les de langage utilisent des r\u00e9seaux neuronaux pour g\u00e9n\u00e9rer du texte coh\u00e9rent : - outil populaire pour l'exp\u00e9rimentation et l'analyse de donn\u00e9es - Nous allons utiliser un mod\u00e8le simplifi\u00e9 de g\u00e9n\u00e9ration de texte - Donnez une amorce (d\u00e9but de phrase ou paragraphe) - Observez comment le mod\u00e8le compl\u00e8te le texte de mani\u00e8re coh\u00e9rente - Essayez avec diff\u00e9rents styles : formel, informel, technique, cr\u00e9atif</p>"},{"location":"seance1/partie1-mise-en-situation/demonstrations/#comment-ca-fonctionne_1","title":"Comment \u00e7a fonctionne ?","text":"<ul> <li>Utilise des mod\u00e8les de langage comme GPT ou Mistral</li> <li>Entra\u00een\u00e9 sur d'\u00e9normes corpus de texte</li> <li>Apprend les patterns statistiques du langage</li> </ul> <p>Cette technologie repose sur des mod\u00e8les de type Transformer qui utilisent des m\u00e9canismes d'attention pour : 1. Analyser les relations entre les mots et leur contexte 2. Pr\u00e9dire les tokens (mots/parties de mots) les plus probables 3. Construire progressivement un texte coh\u00e9rent</p>"},{"location":"seance1/partie1-mise-en-situation/demonstrations/#generation-de-texte-observation","title":"G\u00e9n\u00e9ration de texte - Observation","text":""},{"location":"seance1/partie1-mise-en-situation/demonstrations/#ce-que-nous-allons-observer_1","title":"Ce que nous allons observer","text":"<ul> <li>Compl\u00e9tion de texte \u00e0 partir d'une amorce</li> <li>Adaptation au style et au contexte</li> <li>Coh\u00e9rence \u00e0 court et moyen terme</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/demonstrations/#interfaces-de-demonstration","title":"Interfaces de d\u00e9monstration","text":"<ul> <li>Demo Mistral AI : https://mistral.ai/</li> <li>GPT-3.5/Claude via Poe : https://poe.com/</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/demonstrations/#exemples-damorces-a-tester","title":"Exemples d'amorces \u00e0 tester","text":"<p>Exemple 1 : Style technique (informatique) <pre><code>Les r\u00e9seaux de neurones convolutifs sont particuli\u00e8rement efficaces pour \n</code></pre></p> <p>Exemple 2 : Style cr\u00e9atif (narration) <pre><code>Dans les profondeurs de l'oc\u00e9an, un \u00e9trange ph\u00e9nom\u00e8ne lumineux attira l'attention des chercheurs qui\n</code></pre></p>"},{"location":"seance1/partie1-mise-en-situation/demonstrations/#exemples-damorces-a-tester-suite","title":"Exemples d'amorces \u00e0 tester (suite)","text":"<p>Exemple 3 : Style formel (business) <pre><code>L'int\u00e9gration de l'intelligence artificielle dans le processus client permet aux entreprises de\n</code></pre></p> <p>Exemple 4 : Style instructif (tutoriel) <pre><code>Pour d\u00e9velopper une application web en React, suivez ces \u00e9tapes :\n</code></pre></p>"},{"location":"seance1/partie1-mise-en-situation/demonstrations/#points-a-observer-pendant-la-demonstration","title":"Points \u00e0 observer pendant la d\u00e9monstration","text":"<ol> <li>Coh\u00e9rence contextuelle : Comment le mod\u00e8le maintient le sujet et le contexte</li> <li>Adaptation au style : Comment le ton et le vocabulaire s'adaptent \u00e0 l'amorce</li> <li>Connaissances int\u00e9gr\u00e9es : Informations factuelles que le mod\u00e8le peut restituer</li> <li>Limitations : Moments o\u00f9 le mod\u00e8le peut g\u00e9n\u00e9rer des informations incorrectes</li> </ol>"},{"location":"seance1/partie1-mise-en-situation/demonstrations/#application-en-developpement-slam","title":"Application en d\u00e9veloppement SLAM","text":"<p>En tant que d\u00e9veloppeurs, vous pourriez int\u00e9grer cette technologie pour : - G\u00e9n\u00e9rer automatiquement des descriptions de produits - Cr\u00e9er des assistants virtuels pour guider les utilisateurs - Produire des r\u00e9sum\u00e9s de documents techniques - Proposer des suggestions de r\u00e9ponses dans une application de service client</p>"},{"location":"seance1/partie1-mise-en-situation/demonstrations/#ce-que-ces-applications-ont-en-commun","title":"Ce que ces applications ont en commun","text":"<ul> <li>Bas\u00e9es sur des architectures de r\u00e9seaux neuronaux avanc\u00e9es</li> <li>Entra\u00een\u00e9es sur d'\u00e9normes volumes de donn\u00e9es</li> <li>Capables d'extraire automatiquement des patterns complexes</li> <li>Produisent des r\u00e9sultats qui semblent \"intelligents\"</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/fiche-observations-bts-sio/","title":"Fiche d'observations - Deep Learning pour BTS SIO SLAM","text":"<p>Nom et pr\u00e9nom : _________</p> <p>Date : _____</p>"},{"location":"seance1/partie1-mise-en-situation/fiche-observations-bts-sio/#1-configuration-et-environnement-de-developpement","title":"1. Configuration et environnement de d\u00e9veloppement","text":"<ul> <li>Framework utilis\u00e9 : TensorFlow/Keras</li> <li>Version de TensorFlow : ____</li> <li>GPU disponible ? \u2b1c Oui  \u2b1c Non</li> <li>Temps d'ex\u00e9cution approximatif : ____</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/fiche-observations-bts-sio/#2-jeu-de-donnees-mnist","title":"2. Jeu de donn\u00e9es MNIST","text":"<ul> <li>Nombre d'images d'entra\u00eenement : ____</li> <li>Nombre d'images de test : ____</li> <li>Dimensions de chaque image : ____</li> <li>Nombre de classes : ____</li> </ul> <p>Quel pr\u00e9traitement a \u00e9t\u00e9 appliqu\u00e9 aux donn\u00e9es ? (cochez les cases)</p> <ul> <li>\u2b1c Redimensionnement</li> <li>\u2b1c Normalisation</li> <li>\u2b1c Encodage one-hot des labels</li> <li>\u2b1c Restructuration (reshape)</li> </ul> <p>Pourquoi normalise-t-on les valeurs des pixels ?</p>"},{"location":"seance1/partie1-mise-en-situation/fiche-observations-bts-sio/#3-architecture-du-modele","title":"3. Architecture du mod\u00e8le","text":""},{"location":"seance1/partie1-mise-en-situation/fiche-observations-bts-sio/#couches-du-modele-completez-le-tableau","title":"Couches du mod\u00e8le (compl\u00e9tez le tableau)","text":"Type de couche Nombre de filtres/neurones Taille du noyau Fonction d'activation Input - - - Conv2D MaxPooling2D - - Conv2D MaxPooling2D - - Flatten - - - Dense - Dense (sortie) - <p>Nombre total de param\u00e8tres : ____</p> <p>R\u00f4le de chaque type de couche :</p> <ul> <li>Conv2D : _______</li> <li>MaxPooling2D : ________</li> <li>Flatten : ____________</li> <li>Dense : ________</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/fiche-observations-bts-sio/#4-compilation-et-entrainement","title":"4. Compilation et entra\u00eenement","text":""},{"location":"seance1/partie1-mise-en-situation/fiche-observations-bts-sio/#parametres-de-compilation","title":"Param\u00e8tres de compilation","text":"<ul> <li>Fonction de perte : ____</li> <li>Optimiseur : ____</li> <li>M\u00e9trique(s) : ____</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/fiche-observations-bts-sio/#parametres-dentrainement","title":"Param\u00e8tres d'entra\u00eenement","text":"<ul> <li>Nombre d'\u00e9poques : ____</li> <li>Taille du batch : ____</li> <li>Proportion de validation : ____</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/fiche-observations-bts-sio/#5-performances-du-modele","title":"5. Performances du mod\u00e8le","text":"<ul> <li>Pr\u00e9cision sur l'ensemble d'entra\u00eenement : __%</li> <li>Pr\u00e9cision sur l'ensemble de validation : __%</li> <li>Pr\u00e9cision sur l'ensemble de test : __%</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/fiche-observations-bts-sio/#6-analyse-des-courbes-dapprentissage","title":"6. Analyse des courbes d'apprentissage","text":"<p>Observations sur la courbe de pr\u00e9cision :</p> <p>Observations sur la courbe de perte :</p> <p>Y a-t-il des signes de surapprentissage (overfitting) ? Si oui, lesquels ?</p>"},{"location":"seance1/partie1-mise-en-situation/fiche-observations-bts-sio/#7-test-avec-vos-propres-dessins","title":"7. Test avec vos propres dessins","text":"Chiffre dessin\u00e9 Pr\u00e9diction Confiance Correct ? \u2b1c Oui \u2b1c Non \u2b1c Oui \u2b1c Non \u2b1c Oui \u2b1c Non <p>Quelles difficult\u00e9s avez-vous rencontr\u00e9es lors de vos tests ?</p>"},{"location":"seance1/partie1-mise-en-situation/fiche-observations-bts-sio/#8-experimentations-et-optimisations","title":"8. Exp\u00e9rimentations et optimisations","text":""},{"location":"seance1/partie1-mise-en-situation/fiche-observations-bts-sio/#experimentation-1-________","title":"Exp\u00e9rimentation 1 : ________","text":"<p>Modifications apport\u00e9es :</p> <p>R\u00e9sultats observ\u00e9s : - Nouvelle pr\u00e9cision : __% - Impact sur le temps d'entra\u00eenement : ____ - Autres observations : ________</p>"},{"location":"seance1/partie1-mise-en-situation/fiche-observations-bts-sio/#experimentation-2-________","title":"Exp\u00e9rimentation 2 : ________","text":"<p>Modifications apport\u00e9es :</p> <p>R\u00e9sultats observ\u00e9s : - Nouvelle pr\u00e9cision : __% - Impact sur le temps d'entra\u00eenement : ____ - Autres observations : ________</p>"},{"location":"seance1/partie1-mise-en-situation/fiche-observations-bts-sio/#9-application-a-votre-projet-final-chatbot-pedagogique","title":"9. Application \u00e0 votre projet final (chatbot p\u00e9dagogique)","text":"<p>Comment pourriez-vous utiliser ce que vous avez appris aujourd'hui dans votre projet de chatbot p\u00e9dagogique sur le Deep Learning ?</p> <p>Quelles fonctionnalit\u00e9s de votre chatbot pourraient \u00eatre am\u00e9lior\u00e9es par les r\u00e9seaux de neurones convolutifs ?</p>"},{"location":"seance1/partie1-mise-en-situation/fiche-observations-bts-sio/#10-questions-et-concepts-a-approfondir","title":"10. Questions et concepts \u00e0 approfondir","text":"<p>Listez 3 concepts du Deep Learning que vous aimeriez approfondir apr\u00e8s cette s\u00e9ance : 1. _________ 2. ________ 3. __________</p> <p>Quelles questions vous posez-vous encore sur le Deep Learning ?</p>"},{"location":"seance1/partie1-mise-en-situation/fiche-observations-bts-sio/#bilan-de-la-seance-auto-evaluation","title":"Bilan de la s\u00e9ance (auto-\u00e9valuation)","text":"<p>Sur une \u00e9chelle de 1 \u00e0 5, \u00e9valuez votre compr\u00e9hension :</p> Concept 1 (Pas compris) 2 3 4 5 (Parfaitement compris) Structure d'un r\u00e9seau de neurones convolutif \u2b1c \u2b1c \u2b1c \u2b1c \u2b1c Pr\u00e9traitement des donn\u00e9es \u2b1c \u2b1c \u2b1c \u2b1c \u2b1c Entra\u00eenement d'un mod\u00e8le \u2b1c \u2b1c \u2b1c \u2b1c \u2b1c Analyse des performances \u2b1c \u2b1c \u2b1c \u2b1c \u2b1c Utilisation pratique du mod\u00e8le \u2b1c \u2b1c \u2b1c \u2b1c \u2b1c <p>Ce que j'ai trouv\u00e9 le plus int\u00e9ressant :</p> <p>Ce que j'ai trouv\u00e9 le plus difficile :</p>"},{"location":"seance1/partie1-mise-en-situation/guide_utilisation_colab/","title":"Guide d'utilisation de Google Colab","text":""},{"location":"seance1/partie1-mise-en-situation/guide_utilisation_colab/#introduction-a-google-colab","title":"Introduction \u00e0 Google Colab","text":"<p>Google Colab (ou Colaboratory) est un environnement de notebook Jupyter h\u00e9berg\u00e9 par Google. Il permet d'ex\u00e9cuter du code Python dans votre navigateur et est particuli\u00e8rement adapt\u00e9 au machine learning, \u00e0 l'analyse de donn\u00e9es et \u00e0 l'\u00e9ducation.</p>"},{"location":"seance1/partie1-mise-en-situation/guide_utilisation_colab/#avantages-de-google-colab","title":"Avantages de Google Colab","text":"<ul> <li>Gratuit : pas besoin d'installer Python ou des biblioth\u00e8ques sur votre ordinateur</li> <li>Puissant : acc\u00e8s \u00e0 des GPU et TPU gratuits</li> <li>Collaboratif : facilit\u00e9 de partage et de travail en \u00e9quipe</li> <li>Pr\u00eat \u00e0 l'emploi : biblioth\u00e8ques populaires d\u00e9j\u00e0 install\u00e9es (TensorFlow, PyTorch, etc.)</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/guide_utilisation_colab/#acceder-a-google-colab","title":"Acc\u00e9der \u00e0 Google Colab","text":"<ol> <li>Allez sur colab.research.google.com</li> <li>Connectez-vous avec votre compte Google</li> <li>Sur la page d'accueil, vous pouvez:</li> <li>Cr\u00e9er un nouveau notebook</li> <li>Ouvrir un notebook existant</li> <li>Acc\u00e9der \u00e0 des tutoriels</li> </ol>"},{"location":"seance1/partie1-mise-en-situation/guide_utilisation_colab/#interface-de-colab","title":"Interface de Colab","text":"<p>L'interface de Colab est compos\u00e9e de:</p> <ol> <li>Barre de menu : Fichier, \u00c9dition, Affichage, etc.</li> <li>Barre d'outils : actions rapides</li> <li>Panneau de cellules : o\u00f9 vous \u00e9crivez et ex\u00e9cutez votre code</li> <li>Panneau lat\u00e9ral : pour acc\u00e9der aux fichiers, tableaux, etc.</li> </ol>"},{"location":"seance1/partie1-mise-en-situation/guide_utilisation_colab/#types-de-cellules","title":"Types de cellules","text":"<p>Dans Colab, il existe deux types principaux de cellules:</p> <ul> <li>Cellules de code : pour ex\u00e9cuter du code Python</li> <li>Cellules de texte : pour \u00e9crire des commentaires en Markdown</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/guide_utilisation_colab/#cellules-de-code","title":"Cellules de code","text":"<pre><code># Exemple de cellule de code\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\n\nplt.plot(x, y)\nplt.title(\"Fonction sinus\")\nplt.show()\n</code></pre>"},{"location":"seance1/partie1-mise-en-situation/guide_utilisation_colab/#cellules-de-texte-markdown","title":"Cellules de texte (Markdown)","text":"<p>Les cellules de texte utilisent la syntaxe Markdown:</p> <pre><code># Titre principal\n## Sous-titre\n\nTexte normal avec **texte en gras** et *texte en italique*.\n\nListe \u00e0 puces:\n- Item 1\n- Item 2\n\n\u00c9quation math\u00e9matique: $y = mx + b$\n</code></pre>"},{"location":"seance1/partie1-mise-en-situation/guide_utilisation_colab/#executer-du-code","title":"Ex\u00e9cuter du code","text":"<p>Pour ex\u00e9cuter une cellule: - Cliquez sur le bouton \u25b6\ufe0f \u00e0 gauche de la cellule - Ou utilisez le raccourci clavier <code>Shift+Enter</code></p> <p>Le r\u00e9sultat s'affiche directement sous la cellule.</p>"},{"location":"seance1/partie1-mise-en-situation/guide_utilisation_colab/#raccourcis-clavier-utiles","title":"Raccourcis clavier utiles","text":"<ul> <li><code>Ctrl+Enter</code> : Ex\u00e9cuter la cellule</li> <li><code>Shift+Enter</code> : Ex\u00e9cuter la cellule et passer \u00e0 la suivante</li> <li><code>Alt+Enter</code> : Ex\u00e9cuter la cellule et ins\u00e9rer une nouvelle cellule en dessous</li> <li><code>Ctrl+M D</code> : Supprimer la cellule</li> <li><code>Ctrl+M A</code> : Ins\u00e9rer une cellule au-dessus</li> <li><code>Ctrl+M B</code> : Ins\u00e9rer une cellule en-dessous</li> <li><code>Ctrl+M M</code> : Transformer en cellule Markdown</li> <li><code>Ctrl+M Y</code> : Transformer en cellule de code</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/guide_utilisation_colab/#utiliser-le-gputpu","title":"Utiliser le GPU/TPU","text":"<p>Pour acc\u00e9l\u00e9rer l'ex\u00e9cution de votre code:</p> <ol> <li>Cliquez sur <code>Modifier</code> &gt; <code>Param\u00e8tres du notebook</code></li> <li>Sous <code>Acc\u00e9l\u00e9rateur mat\u00e9riel</code>, s\u00e9lectionnez <code>GPU</code> ou <code>TPU</code></li> <li>Cliquez sur <code>Enregistrer</code></li> </ol>"},{"location":"seance1/partie1-mise-en-situation/guide_utilisation_colab/#installer-des-bibliotheques","title":"Installer des biblioth\u00e8ques","text":"<p>Colab poss\u00e8de d\u00e9j\u00e0 de nombreuses biblioth\u00e8ques install\u00e9es, mais vous pouvez en ajouter d'autres:</p> <pre><code>!pip install nom_de_la_biblioth\u00e8que\n</code></pre> <p>Exemple: <pre><code>!pip install transformers\n</code></pre></p> <p>Apr\u00e8s l'installation, red\u00e9marrez l'environnement d'ex\u00e9cution: 1. <code>Ex\u00e9cution</code> &gt; <code>Red\u00e9marrer l'environnement d'ex\u00e9cution...</code></p>"},{"location":"seance1/partie1-mise-en-situation/guide_utilisation_colab/#gerer-les-fichiers","title":"G\u00e9rer les fichiers","text":""},{"location":"seance1/partie1-mise-en-situation/guide_utilisation_colab/#importer-des-fichiers","title":"Importer des fichiers","text":"<ol> <li>Cliquez sur l'ic\u00f4ne \ud83d\udcc2 dans le panneau lat\u00e9ral gauche</li> <li>Cliquez sur <code>Importer</code> pour t\u00e9l\u00e9charger un fichier</li> </ol> <p>Ou via le code: <pre><code>from google.colab import files\nuploaded = files.upload()\n</code></pre></p>"},{"location":"seance1/partie1-mise-en-situation/guide_utilisation_colab/#acceder-aux-fichiers-de-google-drive","title":"Acc\u00e9der aux fichiers de Google Drive","text":"<pre><code>from google.colab import drive\ndrive.mount('/content/drive')\n\n# Acc\u00e9der aux fichiers dans Drive\n!ls \"/content/drive/My Drive\"\n</code></pre>"},{"location":"seance1/partie1-mise-en-situation/guide_utilisation_colab/#telecharger-des-fichiers","title":"T\u00e9l\u00e9charger des fichiers","text":"<pre><code>from google.colab import files\nfiles.download('nom_du_fichier.ext')\n</code></pre>"},{"location":"seance1/partie1-mise-en-situation/guide_utilisation_colab/#enregistrer-votre-travail","title":"Enregistrer votre travail","text":"<p>Colab enregistre automatiquement votre travail dans Google Drive, mais vous pouvez aussi:</p> <ol> <li><code>Fichier</code> &gt; <code>Enregistrer une copie dans Drive</code></li> <li><code>Fichier</code> &gt; <code>T\u00e9l\u00e9charger</code> &gt; <code>T\u00e9l\u00e9charger .ipynb</code></li> </ol>"},{"location":"seance1/partie1-mise-en-situation/guide_utilisation_colab/#partager-un-notebook","title":"Partager un notebook","text":"<ol> <li>Cliquez sur <code>Partager</code> en haut \u00e0 droite</li> <li>Entrez les adresses e-mail ou obtenez un lien de partage</li> <li>D\u00e9finissez les autorisations d'acc\u00e8s (Lecteur ou \u00c9diteur)</li> </ol>"},{"location":"seance1/partie1-mise-en-situation/guide_utilisation_colab/#depannage-courant","title":"D\u00e9pannage courant","text":""},{"location":"seance1/partie1-mise-en-situation/guide_utilisation_colab/#erreur-cuda-out-of-memory","title":"Erreur \"CUDA out of memory\"","text":"<ul> <li>Red\u00e9marrez l'environnement d'ex\u00e9cution (Ex\u00e9cution &gt; Red\u00e9marrer...)</li> <li>R\u00e9duisez la taille de votre mod\u00e8le ou de vos donn\u00e9es</li> <li>Utilisez un lot (batch) plus petit</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/guide_utilisation_colab/#deconnexion-apres-inactivite","title":"D\u00e9connexion apr\u00e8s inactivit\u00e9","text":"<ul> <li>Colab se d\u00e9connecte apr\u00e8s environ 90 minutes d'inactivit\u00e9</li> <li>Utilisez <code>Outils</code> &gt; <code>Param\u00e8tres</code> &gt; <code>Param\u00e8tres avanc\u00e9s</code> &gt; <code>D\u00e9sactiver l'interruption apr\u00e8s inactivit\u00e9</code></li> </ul>"},{"location":"seance1/partie1-mise-en-situation/guide_utilisation_colab/#limites-de-temps-dexecution","title":"Limites de temps d'ex\u00e9cution","text":"<ul> <li>Les sessions sont limit\u00e9es \u00e0 environ 12 heures</li> <li>Pour des calculs plus longs, enregistrez p\u00e9riodiquement votre travail</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/guide_utilisation_colab/#perte-de-variables","title":"Perte de variables","text":"<ul> <li>Si vous ex\u00e9cutez les cellules dans un ordre diff\u00e9rent, certaines variables peuvent \u00eatre perdues</li> <li>Mieux vaut ex\u00e9cuter les cellules dans l'ordre s\u00e9quentiel</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/guide_utilisation_colab/#astuces-pour-les-tps-de-deep-learning","title":"Astuces pour les TPs de Deep Learning","text":"<ol> <li> <p>V\u00e9rifiez l'acc\u00e9l\u00e9rateur mat\u00e9riel avant de commencer un entra\u00eenement lourd    <pre><code>import tensorflow as tf\nprint(\"GPU disponible:\", tf.config.list_physical_devices('GPU'))\n</code></pre></p> </li> <li> <p>Sauvegardez vos mod\u00e8les r\u00e9guli\u00e8rement    <pre><code>model.save('mon_modele.h5')\n</code></pre></p> </li> <li> <p>Visualisez vos donn\u00e9es avant l'entra\u00eenement    <pre><code>import matplotlib.pyplot as plt\nplt.imshow(X_train[0])\nplt.show()\n</code></pre></p> </li> <li> <p>Utilisez tqdm pour les barres de progression    <pre><code>!pip install tqdm\nfrom tqdm.notebook import tqdm\n\nfor epoch in tqdm(range(100)):\n    # votre boucle d'entra\u00eenement\n</code></pre></p> </li> <li> <p>Profitez de TensorBoard <pre><code>%load_ext tensorboard\n%tensorboard --logdir logs\n</code></pre></p> </li> </ol>"},{"location":"seance1/partie1-mise-en-situation/guide_utilisation_colab/#ressources-supplementaires","title":"Ressources suppl\u00e9mentaires","text":"<ul> <li>Documentation officielle de Google Colab</li> <li>Tutoriels TensorFlow dans Colab</li> <li>Tutoriels PyTorch dans Colab</li> </ul> <p>Bonne exploration et bon apprentissage du Deep Learning avec Google Colab !</p>"},{"location":"seance1/partie1-mise-en-situation/partie1-mise-en-situation/","title":"Phase 1 : Mise en situation pratique (1h)","text":""},{"location":"seance1/partie1-mise-en-situation/partie1-mise-en-situation/#objectif","title":"Objectif","text":"<p>D\u00e9couvrir le Deep Learning par la pratique et l'observation, sans vous pr\u00e9occuper des aspects th\u00e9oriques qui seront abord\u00e9s plus tard.</p>"},{"location":"seance1/partie1-mise-en-situation/partie1-mise-en-situation/#introduction-par-lexemple-15-min","title":"Introduction par l'exemple (15 min)","text":"<ul> <li> <p>D\u00e9monstration 1 : GitHub Copilot (5 min)</p> </li> <li> <p>D\u00e9monstration 2 : Reconnaissance d'objets en temps r\u00e9el (5 min)</p> </li> <li> <p>D\u00e9monstration 3 : G\u00e9n\u00e9ration de texte (5 min)</p> </li> </ul>"},{"location":"seance1/partie1-mise-en-situation/partie1-mise-en-situation/#prise-en-main-immediate-30-min","title":"Prise en main imm\u00e9diate (30 min)","text":""},{"location":"seance1/partie1-mise-en-situation/partie1-mise-en-situation/#premier-contact-avec-un-reseau-de-neurones","title":"Premier contact avec un r\u00e9seau de neurones","text":"<p>Colab est un service Jupyter Notebook h\u00e9berg\u00e9 qui ne n\u00e9cessite aucune configuration et offre un acc\u00e8s gratuit aux ressources de calcul, notamment aux GPU et aux TPU. Colab est particuli\u00e8rement adapt\u00e9 \u00e0 l'apprentissage automatique, \u00e0 la science des donn\u00e9es et \u00e0 l'\u00e9ducation.</p>"},{"location":"seance1/partie1-mise-en-situation/partie1-mise-en-situation/#instructions-detaillees","title":"Instructions d\u00e9taill\u00e9es","text":""},{"location":"seance1/partie1-mise-en-situation/partie1-mise-en-situation/#1-creer-un-nouveau-notebook-colab","title":"1. Cr\u00e9er un nouveau notebook Colab","text":"<p>Allez sur Google Colab Cliquez sur \"Fichier\" &gt; \"Nouveau notebook\"</p>"},{"location":"seance1/partie1-mise-en-situation/partie1-mise-en-situation/#2-copier-coller-les-cellules-de-code","title":"2. Copier-coller les cellules de code","text":"<p>Dans votre nouveau notebook, vous allez cr\u00e9er 9 cellules en copiant-collant les blocs ci-dessous. Pour chaque cellule :</p> <p>Cliquez sur \"+\" Collez le contenu dans la nouvelle cellule Ex\u00e9cutez la cellule en cliquant sur le bouton \u25b6\ufe0f ou avec Ctrl+Entr\u00e9e Observez les r\u00e9sultats et notez vos observations dans la fiche</p>"},{"location":"seance1/partie1-mise-en-situation/partie1-mise-en-situation/#3-contenu-des-cellules-a-creer","title":"3. Contenu des cellules \u00e0 cr\u00e9er","text":"<p>Le fichier premier_contact_reseau_neurones.md contient toutes les cellules de code \u00e0 copier. Suivez ces cellules dans l'ordre:</p> <ul> <li>Introduction (cellule Markdown)</li> <li>Configuration (cellule Code)</li> <li>Chargement des donn\u00e9es (cellule Code)</li> <li>Cr\u00e9ation du mod\u00e8le (cellule Code)</li> <li>Entra\u00eenement (cellule Code)</li> <li>Visualisation (cellule Code)</li> <li>Pr\u00e9dictions (cellule Code)</li> <li>Dessin interactif (cellule Code)</li> <li>Exp\u00e9rimentation (cellule Markdown)</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/partie1-mise-en-situation/#4-remplir-la-fiche-dobservations","title":"4. Remplir la fiche d'observations","text":"<ul> <li>Notez les r\u00e9sultats obtenus \u00e0 chaque \u00e9tape</li> <li>R\u00e9alisez les exp\u00e9rimentations sugg\u00e9r\u00e9es</li> <li>Compl\u00e9tez l'auto-\u00e9valuation</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/partie1-mise-en-situation/#5-exploration-personnelle","title":"5. Exploration personnelle","text":"<ul> <li>Modifiez l'architecture du r\u00e9seau (nombre de filtres, nombre de couches)</li> <li>Changez les param\u00e8tres d'entra\u00eenement (\u00e9poques, taille de batch)</li> <li>Testez le mod\u00e8le avec vos propres dessins</li> <li>Notez l'impact de ces changements</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/partie1-mise-en-situation/#6-rendu-final","title":"6. Rendu final","text":"<p>\u00c0 la fin de la s\u00e9ance, remettez :</p> <ul> <li>Votre notebook Colab compl\u00e9t\u00e9 (partagez le lien ou exportez en .ipynb)</li> <li>Votre fiche d'observations remplie</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/partie1-mise-en-situation/#en-cas-de-difficultes","title":"En cas de difficult\u00e9s","text":"<ul> <li>R\u00e9f\u00e9rez-vous au guide d'utilisation de Google Colab fourni</li> <li>Assurez-vous que les cellules sont ex\u00e9cut\u00e9es dans l'ordre</li> <li>Si une erreur appara\u00eet, lisez attentivement le message et v\u00e9rifiez votre code</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/partie1-mise-en-situation/#fichiers-fournis","title":"Fichiers fournis","text":"<ul> <li>premier_contact_reseau_neurones.md : Contient toutes les cellules de code \u00e0 copier-coller</li> <li>fiche-observations-bts-sio.md : Document \u00e0 remplir pendant l'exercice</li> <li>guide_utilisation_colab.md : Aide pour les d\u00e9butants sur Google Colab</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/premier_contact_reseau_neurones/","title":"Premier contact reseau neurones","text":""},{"location":"seance1/partie1-mise-en-situation/premier_contact_reseau_neurones/#cellules-corrigees-pour-le-notebook","title":"Cellules corrig\u00e9es pour le notebook","text":""},{"location":"seance1/partie1-mise-en-situation/premier_contact_reseau_neurones/#cellule-1-introduction-markdown","title":"Cellule 1 (Introduction - Markdown)","text":"<pre><code># \ud83d\ude80 Hello World du Deep Learning\n\n## Reconnaissance de chiffres manuscrits avec TensorFlow et Keras\n\n### Objectifs de ce notebook\n\n- Charger et pr\u00e9parer un jeu de donn\u00e9es de chiffres manuscrits\n- Cr\u00e9er un r\u00e9seau de neurones simple\n- Entra\u00eener le mod\u00e8le\n- Visualiser les r\u00e9sultats\n- Tester le mod\u00e8le avec vos propres dessins\n\n### BTS SIO SLAM - D\u00e9couverte du Deep Learning\n</code></pre>"},{"location":"seance1/partie1-mise-en-situation/premier_contact_reseau_neurones/#cellule-2-configuration-code","title":"Cellule 2 (Configuration - Code)","text":"<pre><code># Importation des biblioth\u00e8ques n\u00e9cessaires\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n# V\u00e9rification de la version de TensorFlow\nprint(f\"TensorFlow version: {tf.__version__}\")\nprint(f\"Keras version: {keras.__version__}\")\n\n# V\u00e9rification du GPU (m\u00e9thode recommand\u00e9e)\nprint(\"GPU disponible :\", len(tf.config.list_physical_devices('GPU')) &gt; 0)\n</code></pre>"},{"location":"seance1/partie1-mise-en-situation/premier_contact_reseau_neurones/#cellule-3-chargement-des-donnees-code","title":"Cellule 3 (Chargement des donn\u00e9es - Code)","text":"<pre><code># Chargement du dataset MNIST\n(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n\n# Pr\u00e9traitement des donn\u00e9es\nX_train = X_train.reshape((60000, 28, 28, 1)) / 255.0\nX_test = X_test.reshape((10000, 28, 28, 1)) / 255.0\n\n# Conversion des labels en cat\u00e9gories\ny_train = keras.utils.to_categorical(y_train)\ny_test = keras.utils.to_categorical(y_test)\n\n# Affichage de quelques exemples\nplt.figure(figsize=(10, 2))\nfor i in range(10):\n    plt.subplot(1, 10, i+1)\n    plt.imshow(X_train[i].reshape(28, 28), cmap='gray')\n    plt.axis('off')\nplt.suptitle(\"Exemples de chiffres manuscrits\")\nplt.show()\n\nprint(f\"Nombre d'exemples d'entra\u00eenement : {X_train.shape[0]}\")\nprint(f\"Nombre d'exemples de test : {X_test.shape[0]}\")\nprint(f\"Dimensions d'une image : {X_train.shape[1:3]}\")\nprint(f\"Valeurs des pixels apr\u00e8s normalisation : de 0 \u00e0 1\")\n</code></pre>"},{"location":"seance1/partie1-mise-en-situation/premier_contact_reseau_neurones/#cellule-4-creation-du-modele-code","title":"Cellule 4 (Cr\u00e9ation du mod\u00e8le - Code)","text":"<pre><code># Cr\u00e9ation du mod\u00e8le de r\u00e9seau de neurones\n# On utilise Input comme premi\u00e8re couche (recommand\u00e9)\ninputs = keras.Input(shape=(28, 28, 1))\n\n# Couche de convolution\nx = layers.Conv2D(32, (3, 3), activation='relu')(inputs)\nx = layers.MaxPooling2D((2, 2))(x)\n\n# Couche de convolution suppl\u00e9mentaire\nx = layers.Conv2D(64, (3, 3), activation='relu')(x)\nx = layers.MaxPooling2D((2, 2))(x)\n\n# Aplatissement\nx = layers.Flatten()(x)\n\n# Couche dense\nx = layers.Dense(64, activation='relu')(x)\n\n# Couche de sortie\noutputs = layers.Dense(10, activation='softmax')(x)\n\n# Cr\u00e9ation du mod\u00e8le\nmodel = keras.Model(inputs, outputs, name=\"mnist_model\")\n\n# Compilation du mod\u00e8le\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# Affichage du r\u00e9sum\u00e9 du mod\u00e8le\nmodel.summary()\n</code></pre>"},{"location":"seance1/partie1-mise-en-situation/premier_contact_reseau_neurones/#cellule-5-entrainement-code","title":"Cellule 5 (Entra\u00eenement - Code)","text":"<pre><code># Entra\u00eenement du mod\u00e8le\n# Note : Nombre d'\u00e9poques r\u00e9duit pour la d\u00e9monstration\nhistory = model.fit(\n    X_train, y_train,\n    epochs=5,\n    batch_size=64,\n    validation_split=0.2,\n    verbose=1\n)\n\n# \u00c9valuation du mod\u00e8le\ntest_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\nprint(f\"\\nPr\u00e9cision sur l'ensemble de test : {test_accuracy*100:.2f}%\")\n</code></pre>"},{"location":"seance1/partie1-mise-en-situation/premier_contact_reseau_neurones/#cellule-6-visualisation-code","title":"Cellule 6 (Visualisation - Code)","text":"<pre><code># Visualisation de la pr\u00e9cision et de la perte\nplt.figure(figsize=(12, 4))\n\n# Pr\u00e9cision\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Pr\u00e9cision entra\u00eenement')\nplt.plot(history.history['val_accuracy'], label='Pr\u00e9cision validation')\nplt.title('Pr\u00e9cision du mod\u00e8le')\nplt.xlabel('\u00c9poque')\nplt.ylabel('Pr\u00e9cision')\nplt.legend()\n\n# Perte\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Perte entra\u00eenement')\nplt.plot(history.history['val_loss'], label='Perte validation')\nplt.title('Perte du mod\u00e8le')\nplt.xlabel('\u00c9poque')\nplt.ylabel('Perte')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"seance1/partie1-mise-en-situation/premier_contact_reseau_neurones/#cellule-7-predictions-code","title":"Cellule 7 (Pr\u00e9dictions - Code)","text":"<pre><code># Pr\u00e9dictions et visualisation\n# Pr\u00e9dire sur quelques images de test\npredictions = model.predict(X_test[:10])\n\nplt.figure(figsize=(15, 6))\nfor i in range(10):\n    plt.subplot(2, 10, i+1)\n    plt.imshow(X_test[i].reshape(28, 28), cmap='gray')\n    plt.title(f\"R\u00e9el: {np.argmax(y_test[i])}\")\n    plt.axis('off')\n\n    plt.subplot(2, 10, i+11)\n    plt.bar(range(10), predictions[i])\n    plt.title(f\"Pr\u00e9dit: {np.argmax(predictions[i])}\")\n    plt.xticks(range(10))\n    plt.ylim(0, 1)\n\nplt.suptitle(\"Pr\u00e9dictions du mod\u00e8le\")\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"seance1/partie1-mise-en-situation/premier_contact_reseau_neurones/#cellule-8-dessin-interactif-code","title":"Cellule 8 (Dessin interactif - Code)","text":"<pre><code># Interface interactive pour dessiner et pr\u00e9dire\n# Cette cellule permet de dessiner un chiffre directement dans Colab\nfrom google.colab import output\nimport ipywidgets as widgets\nfrom IPython.display import display\nimport io\nimport base64\nfrom PIL import Image\nimport numpy as np\n\n# Fonction pour cr\u00e9er un canvas HTML\ndef create_canvas():\n    canvas_html = \"\"\"\n    &lt;canvas id=\"canvas\" width=\"280\" height=\"280\" style=\"border: 2px solid black; background-color: white;\"&gt;&lt;/canvas&gt;\n    &lt;div style=\"margin-top: 10px;\"&gt;\n      &lt;button id=\"predict_button\" style=\"padding: 5px 10px; background-color: #4CAF50; color: white; border: none; border-radius: 4px; cursor: pointer;\"&gt;Pr\u00e9dire&lt;/button&gt;\n      &lt;button id=\"clear_button\" style=\"margin-left: 10px; padding: 5px 10px; background-color: #f44336; color: white; border: none; border-radius: 4px; cursor: pointer;\"&gt;Effacer&lt;/button&gt;\n    &lt;/div&gt;\n    &lt;div id=\"result\" style=\"margin-top: 10px; font-weight: bold;\"&gt;&lt;/div&gt;\n\n    &lt;script&gt;\n      var canvas = document.getElementById('canvas');\n      var ctx = canvas.getContext('2d');\n      var isDrawing = false;\n\n      // Configurer le style de dessin\n      ctx.lineWidth = 15;\n      ctx.lineCap = 'round';\n      ctx.lineJoin = 'round';\n      ctx.strokeStyle = 'black';\n\n      // G\u00e9rer les \u00e9v\u00e9nements de dessin\n      canvas.addEventListener('mousedown', function(e) {\n        isDrawing = true;\n        ctx.beginPath();\n        ctx.moveTo(e.clientX - canvas.getBoundingClientRect().left, e.clientY - canvas.getBoundingClientRect().top);\n      });\n\n      canvas.addEventListener('mousemove', function(e) {\n        if (isDrawing) {\n          ctx.lineTo(e.clientX - canvas.getBoundingClientRect().left, e.clientY - canvas.getBoundingClientRect().top);\n          ctx.stroke();\n        }\n      });\n\n      canvas.addEventListener('mouseup', function() {\n        isDrawing = false;\n      });\n\n      canvas.addEventListener('mouseleave', function() {\n        isDrawing = false;\n      });\n\n      // G\u00e9rer le bouton Effacer\n      document.getElementById('clear_button').addEventListener('click', function() {\n        ctx.clearRect(0, 0, canvas.width, canvas.height);\n        document.getElementById('result').innerHTML = '';\n      });\n\n      // G\u00e9rer le bouton Pr\u00e9dire\n      document.getElementById('predict_button').addEventListener('click', function() {\n        var imageData = canvas.toDataURL('image/png');\n        document.getElementById('result').innerHTML = 'Analyse en cours...';\n        google.colab.kernel.invokeFunction('notebook.predict', [imageData], {});\n      });\n    &lt;/script&gt;\n    \"\"\"\n    return canvas_html\n\n# Fonction pour pr\u00e9traiter l'image dessin\u00e9e\ndef preprocess_image(image_data):\n    # Extraire les donn\u00e9es d'image du format base64\n    image_data = image_data.split(',')[1]\n    image = Image.open(io.BytesIO(base64.b64decode(image_data)))\n\n    # Redimensionner et convertir en niveaux de gris\n    image = image.resize((28, 28)).convert('L')\n\n    # Convertir en tableau numpy et normaliser\n    image_array = np.array(image)\n    image_array = 255 - image_array  # Inverser les couleurs (chiffre blanc sur fond noir comme MNIST)\n    image_array = image_array / 255.0\n\n    return image_array\n\n# Fonction pour afficher la pr\u00e9diction\ndef predict_digit(image_data):\n    # Pr\u00e9traiter l'image\n    image_array = preprocess_image(image_data)\n\n    # Pr\u00e9parer pour la pr\u00e9diction\n    image_array = image_array.reshape(1, 28, 28, 1)\n\n    # Pr\u00e9dire\n    prediction = model.predict(image_array)[0]\n    digit = np.argmax(prediction)\n    confidence = prediction[digit] * 100\n\n    # Afficher l'image pr\u00e9trait\u00e9e et la pr\u00e9diction\n    plt.figure(figsize=(6, 3))\n\n    plt.subplot(1, 2, 1)\n    plt.imshow(image_array.reshape(28, 28), cmap='gray')\n    plt.title(\"Image pr\u00e9trait\u00e9e\")\n    plt.axis('off')\n\n    plt.subplot(1, 2, 2)\n    plt.bar(range(10), prediction)\n    plt.title(f\"Pr\u00e9diction: {digit}\")\n    plt.xlabel(\"Chiffre\")\n    plt.ylabel(\"Confiance\")\n    plt.xticks(range(10))\n    plt.show()\n\n    # Mettre \u00e0 jour le r\u00e9sultat sur le canvas\n    output.eval_js(f\"\"\"\n    document.getElementById('result').innerHTML = 'Pr\u00e9diction: {digit} (Confiance: {confidence:.2f}%)';\n    \"\"\")\n\n# Enregistrer la fonction pour l'appel JavaScript\noutput.register_callback('notebook.predict', predict_digit)\n\n# Afficher le canvas\ndisplay(output.HTML(create_canvas()))\nprint(\"Dessinez un chiffre dans le canvas ci-dessus et cliquez sur 'Pr\u00e9dire'\")\n</code></pre>"},{"location":"seance1/partie1-mise-en-situation/premier_contact_reseau_neurones/#cellule-9-experimentation-markdown","title":"Cellule 9 (Exp\u00e9rimentation - Markdown)","text":"<pre><code>## \ud83e\uddea Exp\u00e9rimentations\n\nVoici quelques modifications que vous pouvez essayer pour am\u00e9liorer ou observer les effets sur le mod\u00e8le :\n\n1. **Modifier l'architecture du r\u00e9seau :**\n   - Augmenter/diminuer le nombre de filtres dans les couches Conv2D\n   - Ajouter/retirer des couches convolutives ou denses\n   - Ajouter une couche Dropout pour r\u00e9duire le surapprentissage\n\n2. **Changer les hyperparam\u00e8tres d'entra\u00eenement :**\n   - Augmenter le nombre d'\u00e9poques\n   - Modifier la taille du batch\n   - Essayer diff\u00e9rents optimiseurs (SGD, RMSprop, etc.)\n\n3. **Augmenter les donn\u00e9es :**\n   - Appliquer des rotations ou d\u00e9calages aux images d'entra\u00eenement\n\nPour chaque modification, observez l'impact sur :\n- La pr\u00e9cision finale\n- La vitesse d'entra\u00eenement\n- Les courbes d'apprentissage\n- Le comportement face \u00e0 vos propres dessins\n\nN'h\u00e9sitez pas \u00e0 documenter vos observations dans la fiche fournie.\n</code></pre>"},{"location":"seance1/partie1-mise-en-situation/presentation-slides/","title":"Deep Learning en action","text":""},{"location":"seance1/partie1-mise-en-situation/presentation-slides/#applications-concretes-et-demonstrations","title":"Applications concr\u00e8tes et d\u00e9monstrations","text":""},{"location":"seance1/partie1-mise-en-situation/presentation-slides/#quest-ce-que-le-deep-learning","title":"Qu'est-ce que le Deep Learning ?","text":"<ul> <li>Sous-domaine du Machine Learning</li> <li>Utilise des r\u00e9seaux de neurones \u00e0 plusieurs couches</li> <li>Apprend automatiquement les caract\u00e9ristiques importantes des donn\u00e9es</li> <li>Particuli\u00e8rement performant sur les donn\u00e9es complexes (images, texte, son)</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/presentation-slides/#pourquoi-le-deep-learning-change-la-donne","title":"Pourquoi le Deep Learning change la donne","text":"<ul> <li>Capacit\u00e9 \u00e0 traiter des donn\u00e9es non structur\u00e9es (texte, image, son)</li> <li>Performances sup\u00e9rieures sur des t\u00e2ches complexes</li> <li>Extraction automatique des caract\u00e9ristiques pertinentes</li> <li>Apprentissage de bout en bout (end-to-end learning)</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/presentation-slides/#applications-que-nous-allons-explorer-aujourdhui","title":"Applications que nous allons explorer aujourd'hui","text":"<ol> <li>GitHub Copilot : Assistant de programmation IA</li> <li>Reconnaissance d'objets : D\u00e9tection et classification d'objets dans des images</li> <li>G\u00e9n\u00e9ration de texte : Cr\u00e9ation automatique de contenu textuel coh\u00e9rent</li> </ol> <p>![Applications du Deep Learning](../../images/deep-learning-action.svg</p>"},{"location":"seance1/partie1-mise-en-situation/presentation-slides/#mais-comment-ca-marche-vraiment","title":"Mais comment \u00e7a marche vraiment ?","text":"<ul> <li>Le Deep Learning n'est pas \"magique\"</li> <li>Repose sur des principes math\u00e9matiques solides</li> <li>Apprend par optimisation statistique</li> <li>Ne \"comprend\" pas le monde comme les humains</li> </ul>"},{"location":"seance1/partie1-mise-en-situation/presentation-slides/#a-votre-tour","title":"\u00c0 votre tour !","text":"<p>Passons maintenant \u00e0 une exp\u00e9rience pratique :</p> <ul> <li>Construire vous-m\u00eame un r\u00e9seau de neurones simple</li> <li>L'entra\u00eener sur un jeu de donn\u00e9es de chiffres manuscrits (MNIST)</li> <li>Tester ses performances et l'optimiser</li> </ul> <p></p>"},{"location":"seance1/partie1-mise-en-situation/presentation-slides/#objectifs-de-lexercice-pratique","title":"Objectifs de l'exercice pratique","text":"<ol> <li>Se familiariser avec les outils (Google Colab, TensorFlow/Keras)</li> <li>Comprendre les \u00e9tapes de cr\u00e9ation et d'entra\u00eenement d'un mod\u00e8le</li> <li>Observer l'impact des param\u00e8tres sur les performances</li> <li>Visualiser le processus d'apprentissage en action</li> </ol>"},{"location":"seance1/partie1-mise-en-situation/presentation-slides/#commencer-lexercice-pratique","title":"Commencer l'exercice pratique \u2192","text":"<p>Mise en situation du Deep Learning</p> <p>Bon apprentissage !</p>"},{"location":"seance1/partie2-decouverte-concepts/anatomie-reseau/","title":"Anatomie reseau","text":"In\u00a0[\u00a0]: Copied! <pre># Anatomie d'un r\u00e9seau de neurones\n# Exploration interactive du fonctionnement interne d'un r\u00e9seau de neurones\n\n# Partie 1: Configuration initiale\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom google.colab import output\noutput.enable_custom_widget_manager()\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output\nfrom matplotlib.colors import LinearSegmentedColormap\n\nprint(\"Configuration termin\u00e9e!\")\n\n# Partie 2: Exploration d'un neurone unique\nprint(\"\\n--- Exploration d'un neurone unique ---\")\nprint(\"Dans cette partie, nous allons observer le fonctionnement d'un neurone artificiel.\")\n\n# Fonction pour calculer la sortie d'un neurone\ndef neuron_output(x1, x2, w1, w2, b, activation=\"relu\"):\n    # Calcul de la somme pond\u00e9r\u00e9e\n    z = x1 * w1 + x2 * w2 + b\n    \n    # Application de la fonction d'activation\n    if activation == \"relu\":\n        a = max(0, z)\n    elif activation == \"sigmoid\":\n        a = 1 / (1 + np.exp(-z))\n    elif activation == \"tanh\":\n        a = np.tanh(z)\n    else:\n        a = z  # Lin\u00e9aire\n    \n    return z, a\n\n# Fonction pour visualiser un neurone\ndef visualize_neuron(x1, x2, w1, w2, b, activation=\"relu\"):\n    # Calculer la sortie\n    z, a = neuron_output(x1, x2, w1, w2, b, activation)\n    \n    # Cr\u00e9er la figure\n    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n    \n    # 1. Repr\u00e9sentation du neurone\n    ax = axes[0]\n    ax.set_xlim(-0.5, 2.5)\n    ax.set_ylim(-0.5, 2.5)\n    \n    # Dessiner le neurone\n    circle = plt.Circle((1, 1), 0.4, fill=True, color='lightblue', alpha=0.7)\n    ax.add_artist(circle)\n    \n    # Dessiner les entr\u00e9es\n    ax.plot(0, 0.7, 'ro', markersize=10)\n    ax.plot(0, 1.3, 'ro', markersize=10)\n    \n    # Dessiner la sortie\n    ax.plot(2, 1, 'go', markersize=10)\n    \n    # Ajouter les connexions\n    ax.arrow(0, 0.7, 0.6, 0.1, head_width=0.1, head_length=0.1, fc='black', ec='black', linewidth=2)\n    ax.arrow(0, 1.3, 0.6, -0.1, head_width=0.1, head_length=0.1, fc='black', ec='black', linewidth=2)\n    ax.arrow(1.4, 1, 0.6, 0, head_width=0.1, head_length=0.1, fc='black', ec='black', linewidth=2)\n    \n    # Ajouter les textes\n    ax.text(-0.1, 0.7, f\"x\u2081 = {x1:.2f}\", fontsize=12, ha='right')\n    ax.text(-0.1, 1.3, f\"x\u2082 = {x2:.2f}\", fontsize=12, ha='right')\n    ax.text(1, 1, f\"z = {z:.2f}\\na = {a:.2f}\", fontsize=12, ha='center')\n    ax.text(0.5, 0.95, f\"w\u2081 = {w1:.2f}\", fontsize=10, rotation=15)\n    ax.text(0.5, 1.15, f\"w\u2082 = {w2:.2f}\", fontsize=10, rotation=-15)\n    ax.text(2.1, 1, f\"Sortie = {a:.2f}\", fontsize=12, ha='left')\n    ax.text(1, 0.5, f\"Biais = {b:.2f}\", fontsize=10)\n    \n    ax.set_title(\"Neurone artificiel\", fontsize=14)\n    ax.set_axis_off()\n    \n    # 2. Repr\u00e9sentation de la fonction d'activation\n    ax = axes[1]\n    x = np.linspace(-5, 5, 100)\n    \n    if activation == \"relu\":\n        y = np.maximum(0, x)\n        title = \"Fonction d'activation: ReLU\"\n    elif activation == \"sigmoid\":\n        y = 1 / (1 + np.exp(-x))\n        title = \"Fonction d'activation: Sigmoid\"\n    elif activation == \"tanh\":\n        y = np.tanh(x)\n        title = \"Fonction d'activation: Tanh\"\n    else:\n        y = x\n        title = \"Fonction d'activation: Lin\u00e9aire\"\n    \n    ax.plot(x, y, 'b-', linewidth=2)\n    ax.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n    ax.axvline(x=0, color='k', linestyle='-', alpha=0.3)\n    \n    # Marquer le point correspondant \u00e0 z\n    ax.plot(z, a, 'ro', markersize=8)\n    ax.plot([z, z], [0, a], 'r--', alpha=0.5)\n    ax.plot([0, z], [a, a], 'r--', alpha=0.5)\n    \n    ax.set_xlim(-5, 5)\n    ax.set_ylim(-1.5, 1.5)\n    ax.set_xlabel(\"z (somme pond\u00e9r\u00e9e)\")\n    ax.set_ylabel(\"a (activation)\")\n    ax.set_title(title, fontsize=14)\n    ax.grid(True, alpha=0.3)\n    \n    # 3. Visualisation de la fronti\u00e8re de d\u00e9cision\n    ax = axes[2]\n    \n    # Cr\u00e9er des points pour former une grille\n    grid_size = 20\n    x1_values = np.linspace(0, 1, grid_size)\n    x2_values = np.linspace(0, 1, grid_size)\n    x1_grid, x2_grid = np.meshgrid(x1_values, x2_values)\n    \n    # Calculer la sortie pour chaque point de la grille\n    z_grid = x1_grid * w1 + x2_grid * w2 + b\n    \n    if activation == \"relu\":\n        a_grid = np.maximum(0, z_grid)\n    elif activation == \"sigmoid\":\n        a_grid = 1 / (1 + np.exp(-z_grid))\n    elif activation == \"tanh\":\n        a_grid = np.tanh(z_grid)\n    else:\n        a_grid = z_grid\n    \n    # Cr\u00e9er une carte de couleur\n    cmap = plt.get_cmap('coolwarm')\n    \n    # Tracer la heatmap\n    im = ax.imshow(a_grid, origin='lower', extent=[0, 1, 0, 1], \n                   cmap=cmap, vmin=0, vmax=1)\n    plt.colorbar(im, ax=ax, label=\"Activation\")\n    \n    # Ajouter le point actuel\n    ax.plot(x1, x2, 'ko', markersize=8)\n    \n    # Tracer la fronti\u00e8re de d\u00e9cision (a = 0.5)\n    if activation in [\"sigmoid\", \"tanh\"]:\n        threshold = 0.5\n        CS = ax.contour(x1_grid, x2_grid, a_grid, levels=[threshold], \n                         colors='k', linestyles='--')\n        ax.clabel(CS, inline=True, fontsize=10, fmt={threshold: \"a = 0.5\"})\n    \n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_xlabel(\"x\u2081\")\n    ax.set_ylabel(\"x\u2082\")\n    ax.set_title(\"Carte d'activation\", fontsize=14)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return a\n\n# Cr\u00e9er des widgets interactifs pour le neurone\nw1_slider = widgets.FloatSlider(value=1.0, min=-3.0, max=3.0, step=0.1, description='Poids w\u2081:')\nw2_slider = widgets.FloatSlider(value=1.0, min=-3.0, max=3.0, step=0.1, description='Poids w\u2082:')\nb_slider = widgets.FloatSlider(value=0.0, min=-3.0, max=3.0, step=0.1, description='Biais:')\nx1_slider = widgets.FloatSlider(value=0.5, min=0.0, max=1.0, step=0.05, description='Entr\u00e9e x\u2081:')\nx2_slider = widgets.FloatSlider(value=0.5, min=0.0, max=1.0, step=0.05, description='Entr\u00e9e x\u2082:')\nactivation_dropdown = widgets.Dropdown(\n    options=['relu', 'sigmoid', 'tanh', 'linear'],\n    value='relu',\n    description='Activation:'\n)\n\n# Fonction pour mettre \u00e0 jour la visualisation\ndef update_neuron_visualization(w1, w2, b, x1, x2, activation):\n    clear_output(wait=True)\n    output = visualize_neuron(x1, x2, w1, w2, b, activation)\n    print(f\"Sortie du neurone: {output:.4f}\")\n    \n    # Expliquer le calcul\n    z = x1 * w1 + x2 * w2 + b\n    print(f\"\\nCalcul d\u00e9taill\u00e9:\")\n    print(f\"z = (x\u2081 \u00d7 w\u2081) + (x\u2082 \u00d7 w\u2082) + b\")\n    print(f\"z = ({x1:.2f} \u00d7 {w1:.2f}) + ({x2:.2f} \u00d7 {w2:.2f}) + {b:.2f}\")\n    print(f\"z = {x1*w1:.2f} + {x2*w2:.2f} + {b:.2f}\")\n    print(f\"z = {z:.2f}\")\n    \n    if activation == \"relu\":\n        print(f\"a = ReLU(z) = max(0, z) = max(0, {z:.2f}) = {max(0, z):.2f}\")\n    elif activation == \"sigmoid\":\n        sig_z = 1 / (1 + np.exp(-z))\n        print(f\"a = Sigmoid(z) = 1 / (1 + e^(-z)) = 1 / (1 + e^(-{z:.2f})) = {sig_z:.2f}\")\n    elif activation == \"tanh\":\n        tanh_z = np.tanh(z)\n        print(f\"a = tanh(z) = tanh({z:.2f}) = {tanh_z:.2f}\")\n    else:\n        print(f\"a = z = {z:.2f}\")  # Lin\u00e9aire\n\n# Interface interactive pour le neurone\nneuron_output = widgets.interactive_output(\n    update_neuron_visualization,\n    {'w1': w1_slider, 'w2': w2_slider, 'b': b_slider, \n     'x1': x1_slider, 'x2': x2_slider, 'activation': activation_dropdown}\n)\n\n# Afficher les widgets\nprint(\"Utilisez les contr\u00f4les ci-dessous pour modifier les propri\u00e9t\u00e9s du neurone:\")\ndisplay(widgets.VBox([\n    widgets.HBox([x1_slider, x2_slider]),\n    widgets.HBox([w1_slider, w2_slider]),\n    widgets.HBox([b_slider, activation_dropdown])\n]))\ndisplay(neuron_output)\n\n# Partie 3: Exploration d'un r\u00e9seau simple\nprint(\"\\n--- De l'unique au r\u00e9seau ---\")\nprint(\"Dans cette partie, nous allons explorer un petit r\u00e9seau de neurones.\")\n\n# Fonction pour cr\u00e9er et visualiser un r\u00e9seau simple\ndef create_simple_network(hidden_units=3, activation='relu'):\n    # Cr\u00e9er un mod\u00e8le s\u00e9quentiel\n    model = Sequential([\n        Dense(hidden_units, activation=activation, input_shape=(2,)),\n        Dense(1, activation='sigmoid')\n    ])\n    \n    # Compiler le mod\u00e8le (bien que nous ne l'entra\u00eenerons pas)\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return model\n\n# Fonction pour visualiser un r\u00e9seau simple\ndef visualize_network(inputs, weights1=None, biases1=None, weights2=None, biases2=None, hidden_units=3, activation='relu'):\n    # Cr\u00e9er le mod\u00e8le si non fourni\n    model = create_simple_network(hidden_units, activation)\n    \n    # Si des poids sont fournis, les appliquer\n    if weights1 is not None and biases1 is not None and weights2 is not None and biases2 is not None:\n        model.layers[0].set_weights([weights1, biases1])\n        model.layers[1].set_weights([weights2, biases2])\n    \n    # Convertir les entr\u00e9es pour pr\u00e9diction\n    x = np.array([inputs])\n    \n    # Obtenir les activations interm\u00e9diaires\n    intermediate_layer_model = tf.keras.Model(inputs=model.input,\n                                             outputs=model.layers[0].output)\n    intermediate_activations = intermediate_layer_model.predict(x)[0]\n    \n    # Obtenir les activations de sortie\n    output_activation = model.predict(x)[0][0]\n    \n    # Extraire les poids et biais\n    weights1, biases1 = model.layers[0].get_weights()\n    weights2, biases2 = model.layers[1].get_weights()\n    \n    # Cr\u00e9er la figure pour visualiser le r\u00e9seau\n    plt.figure(figsize=(12, 8))\n    \n    # D\u00e9finir les positions des neurones\n    input_layer_y = np.array([0.2, 0.8])\n    hidden_layer_y = np.linspace(0.1, 0.9, hidden_units)\n    output_layer_y = np.array([0.5])\n    \n    input_layer_x = 0.1\n    hidden_layer_x = 0.5\n    output_layer_x = 0.9\n    \n    # Dessiner les neurones d'entr\u00e9e\n    for i, y in enumerate(input_layer_y):\n        plt.scatter(input_layer_x, y, s=200, c='blue', alpha=0.7)\n        plt.text(input_layer_x, y, f\"x{i+1}={inputs[i]:.2f}\", fontsize=12, ha='center', va='center', color='white')\n    \n    # Dessiner les neurones cach\u00e9s\n    for i, y in enumerate(hidden_layer_y):\n        # Calculer la somme pond\u00e9r\u00e9e\n        z = np.dot(inputs, weights1[:, i]) + biases1[i]\n        \n        # Appliquer l'activation\n        if activation == 'relu':\n            a = max(0, z)\n        elif activation == 'sigmoid':\n            a = 1 / (1 + np.exp(-z))\n        elif activation == 'tanh':\n            a = np.tanh(z)\n        else:\n            a = z\n        \n        # Couleur bas\u00e9e sur l'activation\n        color = plt.cm.viridis(a)\n        \n        plt.scatter(hidden_layer_x, y, s=200, c=[color], alpha=0.7)\n        plt.text(hidden_layer_x, y, f\"{a:.2f}\", fontsize=12, ha='center', va='center', color='white')\n    \n    # Dessiner le neurone de sortie\n    plt.scatter(output_layer_x, output_layer_y, s=200, c='red', alpha=0.7)\n    plt.text(output_layer_x, output_layer_y, f\"{output_activation:.2f}\", fontsize=12, ha='center', va='center', color='white')\n    \n    # Dessiner les connexions entre couches d'entr\u00e9e et cach\u00e9e\n    for i, y_in in enumerate(input_layer_y):\n        for j, y_hid in enumerate(hidden_layer_y):\n            # Couleur et \u00e9paisseur bas\u00e9es sur le poids\n            weight = weights1[i, j]\n            width = abs(weight) * 3\n            color = 'red' if weight &lt; 0 else 'green'\n            alpha = min(abs(weight), 1.0)\n            \n            plt.plot([input_layer_x, hidden_layer_x], [y_in, y_hid], \n                    c=color, linewidth=width, alpha=alpha)\n    \n    # Dessiner les connexions entre couche cach\u00e9e et sortie\n    for i, y_hid in enumerate(hidden_layer_y):\n        # Couleur et \u00e9paisseur bas\u00e9es sur le poids\n        weight = weights2[i, 0]\n        width = abs(weight) * 3\n        color = 'red' if weight &lt; 0 else 'green'\n        alpha = min(abs(weight), 1.0)\n        \n        plt.plot([hidden_layer_x, output_layer_x], [y_hid, output_layer_y], \n                c=color, linewidth=width, alpha=alpha)\n    \n    # \u00c9tiquettes\n    plt.text(input_layer_x, 0.03, \"Couche d'entr\u00e9e\", fontsize=14, ha='center')\n    plt.text(hidden_layer_x, 0.03, \"Couche cach\u00e9e\", fontsize=14, ha='center')\n    plt.text(output_layer_x, 0.03, \"Couche de sortie\", fontsize=14, ha='center')\n    \n    # Enlever les axes\n    plt.axis('off')\n    plt.title(f\"R\u00e9seau de neurones - Activation cach\u00e9e: {activation}\", fontsize=16)\n    plt.tight_layout()\n    plt.show()\n    \n    # Afficher les calculs d\u00e9taill\u00e9s\n    print(\"\\nCalculs d\u00e9taill\u00e9s pour chaque neurone de la couche cach\u00e9e:\")\n    for i in range(hidden_units):\n        z = np.dot(inputs, weights1[:, i]) + biases1[i]\n        print(f\"\\nNeurone cach\u00e9 {i+1}:\")\n        print(f\"z = (x\u2081 \u00d7 w\u2081,{i+1}) + (x\u2082 \u00d7 w\u2082,{i+1}) + b{i+1}\")\n        print(f\"z = ({inputs[0]:.2f} \u00d7 {weights1[0, i]:.2f}) + ({inputs[1]:.2f} \u00d7 {weights1[1, i]:.2f}) + {biases1[i]:.2f}\")\n        print(f\"z = {inputs[0] * weights1[0, i]:.2f} + {inputs[1] * weights1[1, i]:.2f} + {biases1[i]:.2f} = {z:.2f}\")\n        \n        if activation == 'relu':\n            a = max(0, z)\n            print(f\"a = ReLU(z) = max(0, {z:.2f}) = {a:.2f}\")\n        elif activation == 'sigmoid':\n            a = 1 / (1 + np.exp(-z))\n            print(f\"a = Sigmoid(z) = 1 / (1 + e^(-{z:.2f})) = {a:.2f}\")\n        elif activation == 'tanh':\n            a = np.tanh(z)\n            print(f\"a = tanh(z) = tanh({z:.2f}) = {a:.2f}\")\n        else:\n            a = z\n            print(f\"a = z = {z:.2f}\")\n    \n    print(\"\\nCalcul pour le neurone de sortie:\")\n    z_out = np.dot(intermediate_activations, weights2[:, 0]) + biases2[0]\n    print(f\"z = \u03a3(a_cach\u00e9 \u00d7 w_sortie) + b_sortie = {z_out:.2f}\")\n    print(f\"sortie = Sigmoid(z) = 1 / (1 + e^(-{z_out:.2f})) = {output_activation:.2f}\")\n    \n    return model, weights1, biases1, weights2, biases2\n\n# Fonction pour g\u00e9n\u00e9rer des poids al\u00e9atoires\ndef generate_random_weights(hidden_units=3):\n    # G\u00e9n\u00e9rer des poids al\u00e9atoires pour la premi\u00e8re couche\n    weights1 = np.random.normal(0, 1, (2, hidden_units))\n    biases1 = np.random.normal(0, 1, hidden_units)\n    \n    # G\u00e9n\u00e9rer des poids al\u00e9atoires pour la couche de sortie\n    weights2 = np.random.normal(0, 1, (hidden_units, 1))\n    biases2 = np.random.normal(0, 1, 1)\n    \n    return weights1, biases1, weights2, biases2\n\n# Cr\u00e9er des widgets interactifs pour le r\u00e9seau\nx1_net_slider = widgets.FloatSlider(value=0.5, min=0.0, max=1.0, step=0.05, description='Entr\u00e9e x\u2081:')\nx2_net_slider = widgets.FloatSlider(value=0.5, min=0.0, max=1.0, step=0.05, description='Entr\u00e9e x\u2082:')\nhidden_units_slider = widgets.IntSlider(value=3, min=1, max=5, description='Neurones cach\u00e9s:')\nactivation_net_dropdown = widgets.Dropdown(\n    options=['relu', 'sigmoid', 'tanh', 'linear'],\n    value='relu',\n    description='Activation:'\n)\nrandom_button = widgets.Button(description=\"Poids al\u00e9atoires\")\n\n# Variables pour stocker les poids courants\ncurrent_weights1, current_biases1, current_weights2, current_biases2 = generate_random_weights()\n\n# Fonction pour visualiser le r\u00e9seau\ndef update_network_visualization(x1, x2, hidden_units, activation):\n    global current_weights1, current_biases1, current_weights2, current_biases2\n    \n    # Ajuster les dimensions des poids si n\u00e9cessaire\n    if current_weights1.shape[1] != hidden_units:\n        current_weights1, current_biases1, current_weights2, current_biases2 = generate_random_weights(hidden_units)\n    \n    # Visualiser le r\u00e9seau\n    inputs = np.array([x1, x2])\n    _, w1, b1, w2, b2 = visualize_network(\n        inputs, current_weights1, current_biases1, current_weights2, current_biases2, \n        hidden_units, activation\n    )\n    \n    # Mettre \u00e0 jour les poids courants\n    current_weights1, current_biases1 = w1, b1\n    current_weights2, current_biases2 = w2, b2\n\n# Fonction pour g\u00e9n\u00e9rer de nouveaux poids al\u00e9atoires\ndef regenerate_weights(b):\n    global current_weights1, current_biases1, current_weights2, current_biases2\n    current_weights1, current_biases1, current_weights2, current_biases2 = generate_random_weights(\n        hidden_units_slider.value\n    )\n    # Mettre \u00e0 jour la visualisation\n    update_network_visualization(\n        x1_net_slider.value, x2_net_slider.value,\n        hidden_units_slider.value, activation_net_dropdown.value\n    )\n\n# Associer la fonction au bouton\nrandom_button.on_click(regenerate_weights)\n\n# Interface interactive pour le r\u00e9seau\nnetwork_output = widgets.interactive_output(\n    update_network_visualization,\n    {'x1': x1_net_slider, 'x2': x2_net_slider, \n     'hidden_units': hidden_units_slider, 'activation': activation_net_dropdown}\n)\n\n# Afficher les widgets pour le r\u00e9seau\nprint(\"\\nExplorez le comportement d'un r\u00e9seau simple:\")\ndisplay(widgets.VBox([\n    widgets.HBox([x1_net_slider, x2_net_slider]),\n    widgets.HBox([hidden_units_slider, activation_net_dropdown]),\n    random_button\n]))\ndisplay(network_output)\n\n# Partie 4: Visualisation de l'entra\u00eenement\nprint(\"\\n--- Visualisation de l'entra\u00eenement ---\")\nprint(\"Dans cette partie, nous allons observer l'\u00e9volution des poids pendant l'entra\u00eenement.\")\n\n# G\u00e9n\u00e9rer des donn\u00e9es XOR\ndef generate_xor_data(n_samples=100):\n    X = np.random.rand(n_samples, 2)\n    y = np.logical_xor(X[:, 0] &gt; 0.5, X[:, 1] &gt; 0.5).astype(np.float32)\n    return X, y\n\n# Fonction pour visualiser l'\u00e9volution de l'apprentissage\ndef visualize_training_animation(learning_rate=0.1, epochs=50, hidden_units=4):\n    # G\u00e9n\u00e9rer des donn\u00e9es\n    X_train, y_train = generate_xor_data(200)\n    \n    # Cr\u00e9er un mod\u00e8le\n    model = Sequential([\n        Dense(hidden_units, activation='relu', input_shape=(2,)),\n        Dense(1, activation='sigmoid')\n    ])\n    \n    # Compiler avec un optimiseur personnalis\u00e9 pour suivre l'\u00e9volution des poids\n    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n    \n    # Extraire les poids initiaux\n    weights_history = [model.get_weights()]\n    \n    # Fonction pour collecter les poids apr\u00e8s chaque \u00e9poque\n    class WeightHistory(tf.keras.callbacks.Callback):\n        def on_epoch_end(self, epoch, logs=None):\n            weights_history.append(self.model.get_weights())\n    \n    # Entra\u00eener le mod\u00e8le\n    history = model.fit(\n        X_train, y_train,\n</pre> # Anatomie d'un r\u00e9seau de neurones # Exploration interactive du fonctionnement interne d'un r\u00e9seau de neurones  # Partie 1: Configuration initiale import numpy as np import matplotlib.pyplot as plt import tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense from google.colab import output output.enable_custom_widget_manager() import ipywidgets as widgets from IPython.display import display, clear_output from matplotlib.colors import LinearSegmentedColormap  print(\"Configuration termin\u00e9e!\")  # Partie 2: Exploration d'un neurone unique print(\"\\n--- Exploration d'un neurone unique ---\") print(\"Dans cette partie, nous allons observer le fonctionnement d'un neurone artificiel.\")  # Fonction pour calculer la sortie d'un neurone def neuron_output(x1, x2, w1, w2, b, activation=\"relu\"):     # Calcul de la somme pond\u00e9r\u00e9e     z = x1 * w1 + x2 * w2 + b          # Application de la fonction d'activation     if activation == \"relu\":         a = max(0, z)     elif activation == \"sigmoid\":         a = 1 / (1 + np.exp(-z))     elif activation == \"tanh\":         a = np.tanh(z)     else:         a = z  # Lin\u00e9aire          return z, a  # Fonction pour visualiser un neurone def visualize_neuron(x1, x2, w1, w2, b, activation=\"relu\"):     # Calculer la sortie     z, a = neuron_output(x1, x2, w1, w2, b, activation)          # Cr\u00e9er la figure     fig, axes = plt.subplots(1, 3, figsize=(18, 5))          # 1. Repr\u00e9sentation du neurone     ax = axes[0]     ax.set_xlim(-0.5, 2.5)     ax.set_ylim(-0.5, 2.5)          # Dessiner le neurone     circle = plt.Circle((1, 1), 0.4, fill=True, color='lightblue', alpha=0.7)     ax.add_artist(circle)          # Dessiner les entr\u00e9es     ax.plot(0, 0.7, 'ro', markersize=10)     ax.plot(0, 1.3, 'ro', markersize=10)          # Dessiner la sortie     ax.plot(2, 1, 'go', markersize=10)          # Ajouter les connexions     ax.arrow(0, 0.7, 0.6, 0.1, head_width=0.1, head_length=0.1, fc='black', ec='black', linewidth=2)     ax.arrow(0, 1.3, 0.6, -0.1, head_width=0.1, head_length=0.1, fc='black', ec='black', linewidth=2)     ax.arrow(1.4, 1, 0.6, 0, head_width=0.1, head_length=0.1, fc='black', ec='black', linewidth=2)          # Ajouter les textes     ax.text(-0.1, 0.7, f\"x\u2081 = {x1:.2f}\", fontsize=12, ha='right')     ax.text(-0.1, 1.3, f\"x\u2082 = {x2:.2f}\", fontsize=12, ha='right')     ax.text(1, 1, f\"z = {z:.2f}\\na = {a:.2f}\", fontsize=12, ha='center')     ax.text(0.5, 0.95, f\"w\u2081 = {w1:.2f}\", fontsize=10, rotation=15)     ax.text(0.5, 1.15, f\"w\u2082 = {w2:.2f}\", fontsize=10, rotation=-15)     ax.text(2.1, 1, f\"Sortie = {a:.2f}\", fontsize=12, ha='left')     ax.text(1, 0.5, f\"Biais = {b:.2f}\", fontsize=10)          ax.set_title(\"Neurone artificiel\", fontsize=14)     ax.set_axis_off()          # 2. Repr\u00e9sentation de la fonction d'activation     ax = axes[1]     x = np.linspace(-5, 5, 100)          if activation == \"relu\":         y = np.maximum(0, x)         title = \"Fonction d'activation: ReLU\"     elif activation == \"sigmoid\":         y = 1 / (1 + np.exp(-x))         title = \"Fonction d'activation: Sigmoid\"     elif activation == \"tanh\":         y = np.tanh(x)         title = \"Fonction d'activation: Tanh\"     else:         y = x         title = \"Fonction d'activation: Lin\u00e9aire\"          ax.plot(x, y, 'b-', linewidth=2)     ax.axhline(y=0, color='k', linestyle='-', alpha=0.3)     ax.axvline(x=0, color='k', linestyle='-', alpha=0.3)          # Marquer le point correspondant \u00e0 z     ax.plot(z, a, 'ro', markersize=8)     ax.plot([z, z], [0, a], 'r--', alpha=0.5)     ax.plot([0, z], [a, a], 'r--', alpha=0.5)          ax.set_xlim(-5, 5)     ax.set_ylim(-1.5, 1.5)     ax.set_xlabel(\"z (somme pond\u00e9r\u00e9e)\")     ax.set_ylabel(\"a (activation)\")     ax.set_title(title, fontsize=14)     ax.grid(True, alpha=0.3)          # 3. Visualisation de la fronti\u00e8re de d\u00e9cision     ax = axes[2]          # Cr\u00e9er des points pour former une grille     grid_size = 20     x1_values = np.linspace(0, 1, grid_size)     x2_values = np.linspace(0, 1, grid_size)     x1_grid, x2_grid = np.meshgrid(x1_values, x2_values)          # Calculer la sortie pour chaque point de la grille     z_grid = x1_grid * w1 + x2_grid * w2 + b          if activation == \"relu\":         a_grid = np.maximum(0, z_grid)     elif activation == \"sigmoid\":         a_grid = 1 / (1 + np.exp(-z_grid))     elif activation == \"tanh\":         a_grid = np.tanh(z_grid)     else:         a_grid = z_grid          # Cr\u00e9er une carte de couleur     cmap = plt.get_cmap('coolwarm')          # Tracer la heatmap     im = ax.imshow(a_grid, origin='lower', extent=[0, 1, 0, 1],                     cmap=cmap, vmin=0, vmax=1)     plt.colorbar(im, ax=ax, label=\"Activation\")          # Ajouter le point actuel     ax.plot(x1, x2, 'ko', markersize=8)          # Tracer la fronti\u00e8re de d\u00e9cision (a = 0.5)     if activation in [\"sigmoid\", \"tanh\"]:         threshold = 0.5         CS = ax.contour(x1_grid, x2_grid, a_grid, levels=[threshold],                           colors='k', linestyles='--')         ax.clabel(CS, inline=True, fontsize=10, fmt={threshold: \"a = 0.5\"})          ax.set_xlim(0, 1)     ax.set_ylim(0, 1)     ax.set_xlabel(\"x\u2081\")     ax.set_ylabel(\"x\u2082\")     ax.set_title(\"Carte d'activation\", fontsize=14)          plt.tight_layout()     plt.show()          return a  # Cr\u00e9er des widgets interactifs pour le neurone w1_slider = widgets.FloatSlider(value=1.0, min=-3.0, max=3.0, step=0.1, description='Poids w\u2081:') w2_slider = widgets.FloatSlider(value=1.0, min=-3.0, max=3.0, step=0.1, description='Poids w\u2082:') b_slider = widgets.FloatSlider(value=0.0, min=-3.0, max=3.0, step=0.1, description='Biais:') x1_slider = widgets.FloatSlider(value=0.5, min=0.0, max=1.0, step=0.05, description='Entr\u00e9e x\u2081:') x2_slider = widgets.FloatSlider(value=0.5, min=0.0, max=1.0, step=0.05, description='Entr\u00e9e x\u2082:') activation_dropdown = widgets.Dropdown(     options=['relu', 'sigmoid', 'tanh', 'linear'],     value='relu',     description='Activation:' )  # Fonction pour mettre \u00e0 jour la visualisation def update_neuron_visualization(w1, w2, b, x1, x2, activation):     clear_output(wait=True)     output = visualize_neuron(x1, x2, w1, w2, b, activation)     print(f\"Sortie du neurone: {output:.4f}\")          # Expliquer le calcul     z = x1 * w1 + x2 * w2 + b     print(f\"\\nCalcul d\u00e9taill\u00e9:\")     print(f\"z = (x\u2081 \u00d7 w\u2081) + (x\u2082 \u00d7 w\u2082) + b\")     print(f\"z = ({x1:.2f} \u00d7 {w1:.2f}) + ({x2:.2f} \u00d7 {w2:.2f}) + {b:.2f}\")     print(f\"z = {x1*w1:.2f} + {x2*w2:.2f} + {b:.2f}\")     print(f\"z = {z:.2f}\")          if activation == \"relu\":         print(f\"a = ReLU(z) = max(0, z) = max(0, {z:.2f}) = {max(0, z):.2f}\")     elif activation == \"sigmoid\":         sig_z = 1 / (1 + np.exp(-z))         print(f\"a = Sigmoid(z) = 1 / (1 + e^(-z)) = 1 / (1 + e^(-{z:.2f})) = {sig_z:.2f}\")     elif activation == \"tanh\":         tanh_z = np.tanh(z)         print(f\"a = tanh(z) = tanh({z:.2f}) = {tanh_z:.2f}\")     else:         print(f\"a = z = {z:.2f}\")  # Lin\u00e9aire  # Interface interactive pour le neurone neuron_output = widgets.interactive_output(     update_neuron_visualization,     {'w1': w1_slider, 'w2': w2_slider, 'b': b_slider,       'x1': x1_slider, 'x2': x2_slider, 'activation': activation_dropdown} )  # Afficher les widgets print(\"Utilisez les contr\u00f4les ci-dessous pour modifier les propri\u00e9t\u00e9s du neurone:\") display(widgets.VBox([     widgets.HBox([x1_slider, x2_slider]),     widgets.HBox([w1_slider, w2_slider]),     widgets.HBox([b_slider, activation_dropdown]) ])) display(neuron_output)  # Partie 3: Exploration d'un r\u00e9seau simple print(\"\\n--- De l'unique au r\u00e9seau ---\") print(\"Dans cette partie, nous allons explorer un petit r\u00e9seau de neurones.\")  # Fonction pour cr\u00e9er et visualiser un r\u00e9seau simple def create_simple_network(hidden_units=3, activation='relu'):     # Cr\u00e9er un mod\u00e8le s\u00e9quentiel     model = Sequential([         Dense(hidden_units, activation=activation, input_shape=(2,)),         Dense(1, activation='sigmoid')     ])          # Compiler le mod\u00e8le (bien que nous ne l'entra\u00eenerons pas)     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])          return model  # Fonction pour visualiser un r\u00e9seau simple def visualize_network(inputs, weights1=None, biases1=None, weights2=None, biases2=None, hidden_units=3, activation='relu'):     # Cr\u00e9er le mod\u00e8le si non fourni     model = create_simple_network(hidden_units, activation)          # Si des poids sont fournis, les appliquer     if weights1 is not None and biases1 is not None and weights2 is not None and biases2 is not None:         model.layers[0].set_weights([weights1, biases1])         model.layers[1].set_weights([weights2, biases2])          # Convertir les entr\u00e9es pour pr\u00e9diction     x = np.array([inputs])          # Obtenir les activations interm\u00e9diaires     intermediate_layer_model = tf.keras.Model(inputs=model.input,                                              outputs=model.layers[0].output)     intermediate_activations = intermediate_layer_model.predict(x)[0]          # Obtenir les activations de sortie     output_activation = model.predict(x)[0][0]          # Extraire les poids et biais     weights1, biases1 = model.layers[0].get_weights()     weights2, biases2 = model.layers[1].get_weights()          # Cr\u00e9er la figure pour visualiser le r\u00e9seau     plt.figure(figsize=(12, 8))          # D\u00e9finir les positions des neurones     input_layer_y = np.array([0.2, 0.8])     hidden_layer_y = np.linspace(0.1, 0.9, hidden_units)     output_layer_y = np.array([0.5])          input_layer_x = 0.1     hidden_layer_x = 0.5     output_layer_x = 0.9          # Dessiner les neurones d'entr\u00e9e     for i, y in enumerate(input_layer_y):         plt.scatter(input_layer_x, y, s=200, c='blue', alpha=0.7)         plt.text(input_layer_x, y, f\"x{i+1}={inputs[i]:.2f}\", fontsize=12, ha='center', va='center', color='white')          # Dessiner les neurones cach\u00e9s     for i, y in enumerate(hidden_layer_y):         # Calculer la somme pond\u00e9r\u00e9e         z = np.dot(inputs, weights1[:, i]) + biases1[i]                  # Appliquer l'activation         if activation == 'relu':             a = max(0, z)         elif activation == 'sigmoid':             a = 1 / (1 + np.exp(-z))         elif activation == 'tanh':             a = np.tanh(z)         else:             a = z                  # Couleur bas\u00e9e sur l'activation         color = plt.cm.viridis(a)                  plt.scatter(hidden_layer_x, y, s=200, c=[color], alpha=0.7)         plt.text(hidden_layer_x, y, f\"{a:.2f}\", fontsize=12, ha='center', va='center', color='white')          # Dessiner le neurone de sortie     plt.scatter(output_layer_x, output_layer_y, s=200, c='red', alpha=0.7)     plt.text(output_layer_x, output_layer_y, f\"{output_activation:.2f}\", fontsize=12, ha='center', va='center', color='white')          # Dessiner les connexions entre couches d'entr\u00e9e et cach\u00e9e     for i, y_in in enumerate(input_layer_y):         for j, y_hid in enumerate(hidden_layer_y):             # Couleur et \u00e9paisseur bas\u00e9es sur le poids             weight = weights1[i, j]             width = abs(weight) * 3             color = 'red' if weight &lt; 0 else 'green'             alpha = min(abs(weight), 1.0)                          plt.plot([input_layer_x, hidden_layer_x], [y_in, y_hid],                      c=color, linewidth=width, alpha=alpha)          # Dessiner les connexions entre couche cach\u00e9e et sortie     for i, y_hid in enumerate(hidden_layer_y):         # Couleur et \u00e9paisseur bas\u00e9es sur le poids         weight = weights2[i, 0]         width = abs(weight) * 3         color = 'red' if weight &lt; 0 else 'green'         alpha = min(abs(weight), 1.0)                  plt.plot([hidden_layer_x, output_layer_x], [y_hid, output_layer_y],                  c=color, linewidth=width, alpha=alpha)          # \u00c9tiquettes     plt.text(input_layer_x, 0.03, \"Couche d'entr\u00e9e\", fontsize=14, ha='center')     plt.text(hidden_layer_x, 0.03, \"Couche cach\u00e9e\", fontsize=14, ha='center')     plt.text(output_layer_x, 0.03, \"Couche de sortie\", fontsize=14, ha='center')          # Enlever les axes     plt.axis('off')     plt.title(f\"R\u00e9seau de neurones - Activation cach\u00e9e: {activation}\", fontsize=16)     plt.tight_layout()     plt.show()          # Afficher les calculs d\u00e9taill\u00e9s     print(\"\\nCalculs d\u00e9taill\u00e9s pour chaque neurone de la couche cach\u00e9e:\")     for i in range(hidden_units):         z = np.dot(inputs, weights1[:, i]) + biases1[i]         print(f\"\\nNeurone cach\u00e9 {i+1}:\")         print(f\"z = (x\u2081 \u00d7 w\u2081,{i+1}) + (x\u2082 \u00d7 w\u2082,{i+1}) + b{i+1}\")         print(f\"z = ({inputs[0]:.2f} \u00d7 {weights1[0, i]:.2f}) + ({inputs[1]:.2f} \u00d7 {weights1[1, i]:.2f}) + {biases1[i]:.2f}\")         print(f\"z = {inputs[0] * weights1[0, i]:.2f} + {inputs[1] * weights1[1, i]:.2f} + {biases1[i]:.2f} = {z:.2f}\")                  if activation == 'relu':             a = max(0, z)             print(f\"a = ReLU(z) = max(0, {z:.2f}) = {a:.2f}\")         elif activation == 'sigmoid':             a = 1 / (1 + np.exp(-z))             print(f\"a = Sigmoid(z) = 1 / (1 + e^(-{z:.2f})) = {a:.2f}\")         elif activation == 'tanh':             a = np.tanh(z)             print(f\"a = tanh(z) = tanh({z:.2f}) = {a:.2f}\")         else:             a = z             print(f\"a = z = {z:.2f}\")          print(\"\\nCalcul pour le neurone de sortie:\")     z_out = np.dot(intermediate_activations, weights2[:, 0]) + biases2[0]     print(f\"z = \u03a3(a_cach\u00e9 \u00d7 w_sortie) + b_sortie = {z_out:.2f}\")     print(f\"sortie = Sigmoid(z) = 1 / (1 + e^(-{z_out:.2f})) = {output_activation:.2f}\")          return model, weights1, biases1, weights2, biases2  # Fonction pour g\u00e9n\u00e9rer des poids al\u00e9atoires def generate_random_weights(hidden_units=3):     # G\u00e9n\u00e9rer des poids al\u00e9atoires pour la premi\u00e8re couche     weights1 = np.random.normal(0, 1, (2, hidden_units))     biases1 = np.random.normal(0, 1, hidden_units)          # G\u00e9n\u00e9rer des poids al\u00e9atoires pour la couche de sortie     weights2 = np.random.normal(0, 1, (hidden_units, 1))     biases2 = np.random.normal(0, 1, 1)          return weights1, biases1, weights2, biases2  # Cr\u00e9er des widgets interactifs pour le r\u00e9seau x1_net_slider = widgets.FloatSlider(value=0.5, min=0.0, max=1.0, step=0.05, description='Entr\u00e9e x\u2081:') x2_net_slider = widgets.FloatSlider(value=0.5, min=0.0, max=1.0, step=0.05, description='Entr\u00e9e x\u2082:') hidden_units_slider = widgets.IntSlider(value=3, min=1, max=5, description='Neurones cach\u00e9s:') activation_net_dropdown = widgets.Dropdown(     options=['relu', 'sigmoid', 'tanh', 'linear'],     value='relu',     description='Activation:' ) random_button = widgets.Button(description=\"Poids al\u00e9atoires\")  # Variables pour stocker les poids courants current_weights1, current_biases1, current_weights2, current_biases2 = generate_random_weights()  # Fonction pour visualiser le r\u00e9seau def update_network_visualization(x1, x2, hidden_units, activation):     global current_weights1, current_biases1, current_weights2, current_biases2          # Ajuster les dimensions des poids si n\u00e9cessaire     if current_weights1.shape[1] != hidden_units:         current_weights1, current_biases1, current_weights2, current_biases2 = generate_random_weights(hidden_units)          # Visualiser le r\u00e9seau     inputs = np.array([x1, x2])     _, w1, b1, w2, b2 = visualize_network(         inputs, current_weights1, current_biases1, current_weights2, current_biases2,          hidden_units, activation     )          # Mettre \u00e0 jour les poids courants     current_weights1, current_biases1 = w1, b1     current_weights2, current_biases2 = w2, b2  # Fonction pour g\u00e9n\u00e9rer de nouveaux poids al\u00e9atoires def regenerate_weights(b):     global current_weights1, current_biases1, current_weights2, current_biases2     current_weights1, current_biases1, current_weights2, current_biases2 = generate_random_weights(         hidden_units_slider.value     )     # Mettre \u00e0 jour la visualisation     update_network_visualization(         x1_net_slider.value, x2_net_slider.value,         hidden_units_slider.value, activation_net_dropdown.value     )  # Associer la fonction au bouton random_button.on_click(regenerate_weights)  # Interface interactive pour le r\u00e9seau network_output = widgets.interactive_output(     update_network_visualization,     {'x1': x1_net_slider, 'x2': x2_net_slider,       'hidden_units': hidden_units_slider, 'activation': activation_net_dropdown} )  # Afficher les widgets pour le r\u00e9seau print(\"\\nExplorez le comportement d'un r\u00e9seau simple:\") display(widgets.VBox([     widgets.HBox([x1_net_slider, x2_net_slider]),     widgets.HBox([hidden_units_slider, activation_net_dropdown]),     random_button ])) display(network_output)  # Partie 4: Visualisation de l'entra\u00eenement print(\"\\n--- Visualisation de l'entra\u00eenement ---\") print(\"Dans cette partie, nous allons observer l'\u00e9volution des poids pendant l'entra\u00eenement.\")  # G\u00e9n\u00e9rer des donn\u00e9es XOR def generate_xor_data(n_samples=100):     X = np.random.rand(n_samples, 2)     y = np.logical_xor(X[:, 0] &gt; 0.5, X[:, 1] &gt; 0.5).astype(np.float32)     return X, y  # Fonction pour visualiser l'\u00e9volution de l'apprentissage def visualize_training_animation(learning_rate=0.1, epochs=50, hidden_units=4):     # G\u00e9n\u00e9rer des donn\u00e9es     X_train, y_train = generate_xor_data(200)          # Cr\u00e9er un mod\u00e8le     model = Sequential([         Dense(hidden_units, activation='relu', input_shape=(2,)),         Dense(1, activation='sigmoid')     ])          # Compiler avec un optimiseur personnalis\u00e9 pour suivre l'\u00e9volution des poids     optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)     model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])          # Extraire les poids initiaux     weights_history = [model.get_weights()]          # Fonction pour collecter les poids apr\u00e8s chaque \u00e9poque     class WeightHistory(tf.keras.callbacks.Callback):         def on_epoch_end(self, epoch, logs=None):             weights_history.append(self.model.get_weights())          # Entra\u00eener le mod\u00e8le     history = model.fit(         X_train, y_train,"},{"location":"seance1/partie2-decouverte-concepts/deep-learning/","title":"Deep learning","text":"In\u00a0[\u00a0]: Copied! <pre># Notebook B: Classification avec Deep Learning\n# Classification des chiffres manuscrits avec un r\u00e9seau de neurones\n\n# Partie 1: Importation des biblioth\u00e8ques\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport time\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nimport seaborn as sns\nfrom google.colab import output\noutput.enable_custom_widget_manager()\nimport ipywidgets as widgets\n\n# V\u00e9rifier la version de TensorFlow\nprint(f\"TensorFlow version: {tf.__version__}\")\n\n# Partie 2: Chargement et exploration des donn\u00e9es\nprint(\"Chargement du jeu de donn\u00e9es MNIST...\")\n# Utilisation du jeu de donn\u00e9es MNIST int\u00e9gr\u00e9 \u00e0 TensorFlow\n(X_train_full, y_train_full), (X_test_full, y_test_full) = tf.keras.datasets.mnist.load_data()\n\n# Normalisation des valeurs de pixels entre 0 et 1\nX_train_full = X_train_full / 255.0\nX_test_full = X_test_full / 255.0\n\n# Exploration des donn\u00e9es\nprint(f\"Dimensions des donn\u00e9es d'entra\u00eenement: {X_train_full.shape}\")\nprint(f\"Dimensions des donn\u00e9es de test: {X_test_full.shape}\")\nprint(f\"Nombre de classes: {len(np.unique(y_train_full))}\")\n\n# Affichage de quelques exemples\nplt.figure(figsize=(10, 5))\nfor i in range(10):\n    plt.subplot(2, 5, i + 1)\n    plt.imshow(X_train_full[i], cmap='gray')\n    plt.title(f\"Label: {y_train_full[i]}\")\n    plt.axis('off')\nplt.tight_layout()\nplt.suptitle(\"Exemples de chiffres manuscrits\", y=1.05)\nplt.show()\n\n# Partie 3: Pr\u00e9paration des donn\u00e9es pour Deep Learning\n\nprint(\"\\n--- Pr\u00e9paration des donn\u00e9es pour le r\u00e9seau de neurones ---\")\nprint(\"Pour le Deep Learning, nous n'avons pas besoin d'extraire manuellement des caract\u00e9ristiques.\")\n\n# Utiliser un sous-ensemble des donn\u00e9es pour acc\u00e9l\u00e9rer la d\u00e9monstration (m\u00eame taille que le Random Forest)\nn_samples = 10000\nX_train = X_train_full[:n_samples]\ny_train = y_train_full[:n_samples]\nX_test = X_test_full[:2000]\ny_test = y_test_full[:2000]\n\n# Pour le Deep Learning, il nous faut juste redimensionner les images\nprint(\"Redimensionnement des images...\")\nprint(f\"Forme originale: {X_train.shape}\")\n\n# Aplatir les images 28x28 en vecteurs de 784 pixels\nX_train_flat = X_train.reshape(X_train.shape[0], 28*28)\nX_test_flat = X_test.reshape(X_test.shape[0], 28*28)\n\nprint(f\"Forme apr\u00e8s redimensionnement: {X_train_flat.shape}\")\n\n# One-hot encoding des labels\ny_train_cat = to_categorical(y_train, 10)\ny_test_cat = to_categorical(y_test, 10)\n\nprint(\"Encodage one-hot des labels\")\nprint(f\"Forme originale des labels: {y_train.shape}\")\nprint(f\"Forme apr\u00e8s encodage one-hot: {y_train_cat.shape}\")\n\n# Partie 4: Cr\u00e9ation du mod\u00e8le de Deep Learning\n\nprint(\"\\n--- Cr\u00e9ation du mod\u00e8le de r\u00e9seau de neurones ---\")\n\n# Param\u00e8tres du mod\u00e8le - vous pouvez les modifier\nn_hidden1 = 128  # Nombre de neurones dans la premi\u00e8re couche cach\u00e9e\nn_hidden2 = 64   # Nombre de neurones dans la seconde couche cach\u00e9e\nlearning_rate = 0.001  # Taux d'apprentissage\ndropout_rate = 0.2  # Taux de dropout pour la r\u00e9gularisation\nn_epochs = 10  # Nombre d'\u00e9poques d'entra\u00eenement\nbatch_size = 32  # Taille du batch\n\n# Cr\u00e9ation du mod\u00e8le\nmodel = Sequential([\n    # Couche d'entr\u00e9e: 784 neurones (un par pixel)\n    # Premi\u00e8re couche cach\u00e9e\n    Dense(n_hidden1, activation='relu', input_shape=(784,)),\n    Dropout(dropout_rate),\n    # Deuxi\u00e8me couche cach\u00e9e\n    Dense(n_hidden2, activation='relu'),\n    Dropout(dropout_rate),\n    # Couche de sortie: 10 neurones (un par classe)\n    Dense(10, activation='softmax')\n])\n\n# Compilation du mod\u00e8le\noptimizer = Adam(learning_rate=learning_rate)\nmodel.compile(\n    optimizer=optimizer,\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# Affichage du r\u00e9sum\u00e9 du mod\u00e8le\nmodel.summary()\n\n# Partie 5: Entra\u00eenement du mod\u00e8le\n\nprint(\"\\n--- Entra\u00eenement du mod\u00e8le de Deep Learning ---\")\n\n# Mesure du temps d'entra\u00eenement\nstart_time = time.time()\nprint(\"Entra\u00eenement du mod\u00e8le en cours...\")\n\n# Entra\u00eenement du mod\u00e8le\nhistory = model.fit(\n    X_train_flat, y_train_cat,\n    epochs=n_epochs,\n    batch_size=batch_size,\n    validation_split=0.2,\n    verbose=1\n)\n\nend_time = time.time()\ntraining_time = end_time - start_time\nprint(f\"Temps d'entra\u00eenement: {training_time:.2f} secondes\")\n\n# Partie 6: Visualisation de l'apprentissage\n\nprint(\"\\n--- Visualisation de l'apprentissage ---\")\n\n# Tracer l'\u00e9volution de la pr\u00e9cision et de la perte\nplt.figure(figsize=(12, 4))\n\n# \u00c9volution de la pr\u00e9cision\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Entra\u00eenement')\nplt.plot(history.history['val_accuracy'], label='Validation')\nplt.title('\u00c9volution de la pr\u00e9cision')\nplt.xlabel('\u00c9poque')\nplt.ylabel('Pr\u00e9cision')\nplt.legend()\n\n# \u00c9volution de la perte\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Entra\u00eenement')\nplt.plot(history.history['val_loss'], label='Validation')\nplt.title('\u00c9volution de la perte')\nplt.xlabel('\u00c9poque')\nplt.ylabel('Perte')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n# Partie 7: \u00c9valuation du mod\u00e8le\n\nprint(\"\\n--- \u00c9valuation du mod\u00e8le de Deep Learning ---\")\n\n# \u00c9valuation sur l'ensemble de test\ntest_loss, test_accuracy = model.evaluate(X_test_flat, y_test_cat, verbose=0)\nprint(f\"Pr\u00e9cision sur l'ensemble de test: {test_accuracy*100:.2f}%\")\n\n# Pr\u00e9dictions sur l'ensemble de test\ny_pred_prob = model.predict(X_test_flat)\ny_pred = np.argmax(y_pred_prob, axis=1)\n\n# Calcul des m\u00e9triques\nconf_matrix = confusion_matrix(y_test, y_pred)\nclass_report = classification_report(y_test, y_pred)\n\nprint(\"\\nMatrice de confusion:\")\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Pr\u00e9dictions')\nplt.ylabel('Valeurs r\u00e9elles')\nplt.title('Matrice de confusion')\nplt.show()\n\nprint(\"\\nRapport de classification:\")\nprint(class_report)\n\n# Partie 8: Visualisation des erreurs\n\nprint(\"\\n--- Analyse des erreurs ---\")\n\n# Identifier les erreurs\nerror_indices = np.where(y_pred != y_test)[0]\nn_errors = min(10, len(error_indices))  # Afficher max 10 erreurs\n\nif n_errors &gt; 0:\n    plt.figure(figsize=(12, 4))\n    for i, idx in enumerate(error_indices[:n_errors]):\n        plt.subplot(2, 5, i + 1)\n        plt.imshow(X_test[idx], cmap='gray')\n        plt.title(f\"R\u00e9el: {y_test[idx]}\\nPr\u00e9dit: {y_pred[idx]}\")\n        plt.axis('off')\n    plt.tight_layout()\n    plt.suptitle(\"Exemples d'erreurs de classification\", y=1.05)\n    plt.show()\nelse:\n    print(\"Aucune erreur trouv\u00e9e dans l'\u00e9chantillon de test!\")\n\n# Partie 9: Visualisation des poids\n\nprint(\"\\n--- Visualisation des poids appris ---\")\n\n# R\u00e9cup\u00e9rer les poids de la premi\u00e8re couche\nweights = model.layers[0].get_weights()[0]  # [784, n_hidden1]\n\n# Visualiser quelques filtres (neurones de la premi\u00e8re couche)\nplt.figure(figsize=(12, 6))\nfor i in range(10):\n    plt.subplot(2, 5, i + 1)\n    # Redimensionner les poids du neurone en 28x28\n    neuron_weights = weights[:, i].reshape(28, 28)\n    plt.imshow(neuron_weights, cmap='coolwarm')\n    plt.title(f\"Neurone {i+1}\")\n    plt.axis('off')\nplt.tight_layout()\nplt.suptitle(\"Poids appris par les neurones de la premi\u00e8re couche\", y=1.05)\nplt.show()\n\nprint(\"Ces visualisations montrent ce que 'recherchent' les neurones de la premi\u00e8re couche dans les images.\")\n\n# Partie 10: D\u00e9fi de g\u00e9n\u00e9ralisation\n\nprint(\"\\n--- D\u00e9fi de g\u00e9n\u00e9ralisation ---\")\nprint(\"Nous allons maintenant tester le mod\u00e8le sur des chiffres l\u00e9g\u00e8rement modifi\u00e9s pour \u00e9valuer sa capacit\u00e9 de g\u00e9n\u00e9ralisation.\")\n\n# Fonction pour ajouter du bruit aux images\ndef add_noise(images, noise_level=0.2):\n    noisy_images = images.copy()\n    noise = np.random.normal(0, noise_level, images.shape)\n    noisy_images = noisy_images + noise\n    # Assurer que les valeurs restent entre 0 et 1\n    noisy_images = np.clip(noisy_images, 0, 1)\n    return noisy_images\n\n# Fonction pour appliquer une rotation aux images\ndef rotate_images(images, max_angle=15):\n    from scipy.ndimage import rotate\n    rotated_images = np.zeros_like(images)\n    for i, img in enumerate(images):\n        angle = np.random.uniform(-max_angle, max_angle)\n        rotated = rotate(img, angle, reshape=False)\n        rotated_images[i] = rotated\n    return rotated_images\n\n# Cr\u00e9er un jeu de donn\u00e9es modifi\u00e9\nprint(\"Cr\u00e9ation d'un jeu de donn\u00e9es avec des chiffres modifi\u00e9s...\")\n\n# Utiliser un nouvel ensemble de donn\u00e9es pour ce test\nX_new = X_test_full[2000:4000]\ny_new = y_test_full[2000:4000]\n\n# Appliquer des transformations\nX_new_noisy = add_noise(X_new, noise_level=0.2)\nX_new_rotated = rotate_images(X_new, max_angle=15)\n\n# Visualiser quelques exemples\nplt.figure(figsize=(12, 8))\nfor i in range(5):\n    # Original\n    plt.subplot(3, 5, i + 1)\n    plt.imshow(X_new[i], cmap='gray')\n    plt.title(f\"Original: {y_new[i]}\")\n    plt.axis('off')\n    \n    # Avec bruit\n    plt.subplot(3, 5, i + 6)\n    plt.imshow(X_new_noisy[i], cmap='gray')\n    plt.title(\"Avec bruit\")\n    plt.axis('off')\n    \n    # Avec rotation\n    plt.subplot(3, 5, i + 11)\n    plt.imshow(X_new_rotated[i], cmap='gray')\n    plt.title(\"Avec rotation\")\n    plt.axis('off')\n\nplt.tight_layout()\nplt.suptitle(\"Exemples de chiffres modifi\u00e9s\", y=1.02)\nplt.show()\n\n# Pr\u00e9paration des donn\u00e9es modifi\u00e9es\nX_new_flat = X_new.reshape(X_new.shape[0], 28*28)\nX_new_noisy_flat = X_new_noisy.reshape(X_new_noisy.shape[0], 28*28)\nX_new_rotated_flat = X_new_rotated.reshape(X_new_rotated.shape[0], 28*28)\n\n# \u00c9valuer le mod\u00e8le sur les donn\u00e9es modifi\u00e9es\nprint(\"\\n\u00c9valuation sur les donn\u00e9es originales:\")\ny_new_pred = np.argmax(model.predict(X_new_flat), axis=1)\naccuracy_original = accuracy_score(y_new, y_new_pred)\nprint(f\"Pr\u00e9cision sur donn\u00e9es originales: {accuracy_original*100:.2f}%\")\n\nprint(\"\\n\u00c9valuation sur les donn\u00e9es avec bruit:\")\ny_new_noisy_pred = np.argmax(model.predict(X_new_noisy_flat), axis=1)\naccuracy_noisy = accuracy_score(y_new, y_new_noisy_pred)\nprint(f\"Pr\u00e9cision sur donn\u00e9es bruit\u00e9es: {accuracy_noisy*100:.2f}%\")\n\nprint(\"\\n\u00c9valuation sur les donn\u00e9es avec rotation:\")\ny_new_rotated_pred = np.argmax(model.predict(X_new_rotated_flat), axis=1)\naccuracy_rotated = accuracy_score(y_new, y_new_rotated_pred)\nprint(f\"Pr\u00e9cision sur donn\u00e9es pivot\u00e9es: {accuracy_rotated*100:.2f}%\")\n\nprint(\"\\nComparaison des pr\u00e9cisions:\")\nprint(f\"Pr\u00e9cision sur donn\u00e9es originales: {accuracy_original*100:.2f}%\")\nprint(f\"Pr\u00e9cision sur donn\u00e9es bruit\u00e9es: {accuracy_noisy*100:.2f}%\")\nprint(f\"Pr\u00e9cision sur donn\u00e9es pivot\u00e9es: {accuracy_rotated*100:.2f}%\")\n\n# Partie 11: Conclusions et r\u00e9flexion\n\nprint(\"\\n--- Conclusions sur le Deep Learning ---\")\nprint(\"\"\"\nPoints forts du r\u00e9seau de neurones:\n- Apprentissage automatique des caract\u00e9ristiques (pas de feature engineering manuel)\n- Bonnes performances sur les donn\u00e9es originales et transform\u00e9es\n- Capacit\u00e9 \u00e0 capturer des motifs complexes\n\nLimites:\n- Temps d'entra\u00eenement g\u00e9n\u00e9ralement plus long que les m\u00e9thodes classiques\n- Plus de param\u00e8tres \u00e0 r\u00e9gler\n- Risque de surapprentissage sur petits ensembles de donn\u00e9es\n- Interpr\u00e9tabilit\u00e9 plus difficile\n\nQuestions pour la r\u00e9flexion:\n1. Pourquoi le Deep Learning g\u00e8re-t-il mieux les transformations des donn\u00e9es?\n2. Comment pourrions-nous am\u00e9liorer encore les performances du mod\u00e8le?\n3. Quels types de probl\u00e8mes sont particuli\u00e8rement adapt\u00e9s au Deep Learning?\n\"\"\")\n\n# Partie 12: Widget interactif pour tester le mod\u00e8le\n\nprint(\"\\n--- Testez le mod\u00e8le vous-m\u00eame ---\")\n\ndef test_dl_model(digit_idx):\n    if digit_idx &lt; len(X_test):\n        # Afficher l'image\n        img = X_test[digit_idx]\n        plt.figure(figsize=(6, 6))\n        plt.imshow(img, cmap='gray')\n        plt.title(f\"Chiffre \u00e0 classifier\")\n        plt.axis('off')\n        plt.show()\n        \n        # Faire la pr\u00e9diction\n        img_flat = img.reshape(1, 784)\n        prediction_prob = model.predict(img_flat)[0]\n        prediction = np.argmax(prediction_prob)\n        real_label = y_test[digit_idx]\n        \n        # Afficher les probabilit\u00e9s\n        plt.figure(figsize=(10, 4))\n        plt.bar(range(10), prediction_prob)\n        plt.xticks(range(10))\n        plt.xlabel('Chiffre')\n        plt.ylabel('Probabilit\u00e9')\n        plt.title('Probabilit\u00e9s pr\u00e9dites pour chaque chiffre')\n        plt.show()\n        \n        print(f\"Pr\u00e9diction du mod\u00e8le Deep Learning: {prediction}\")\n        print(f\"\u00c9tiquette r\u00e9elle: {real_label}\")\n        print(f\"Pr\u00e9diction {'correcte' if prediction == real_label else 'incorrecte'}\")\n        \n        # Afficher les 3 pr\u00e9dictions les plus probables\n        top3_idx = np.argsort(prediction_prob)[-3:][::-1]\n        print(\"\\nTop 3 des pr\u00e9dictions:\")\n        for i, idx in enumerate(top3_idx):\n            print(f\"{i+1}. Chiffre {idx}: {prediction_prob[idx]*100:.2f}%\")\n    else:\n        print(\"Index hors limites!\")\n\n# Cr\u00e9er un slider pour s\u00e9lectionner un chiffre \u00e0 tester\ndigit_selector = widgets.IntSlider(\n    value=0,\n    min=0,\n    max=len(X_test)-1,\n    step=1,\n    description='Index:',\n    continuous_update=False\n)\n\n# Bouton pour ex\u00e9cuter le test\ntest_button = widgets.Button(description=\"Tester\")\noutput = widgets.Output()\n\ndef on_button_clicked(b):\n    with output:\n        output.clear_output()\n        test_dl_model(digit_selector.value)\n\ntest_button.on_click(on_button_clicked)\n\n# Afficher les widgets\ndisplay(widgets.HBox([digit_selector, test_button]))\ndisplay(output)\n\nprint(\"Utilisez le slider pour s\u00e9lectionner un index et cliquez sur 'Tester' pour classifier le chiffre correspondant.\")\n\n# Partie 13: Comparaison avec le mod\u00e8le Random Forest\n\nprint(\"\\n--- Comment comparer avec le mod\u00e8le de Machine Learning classique? ---\")\nprint(\"\"\"\nApr\u00e8s avoir explor\u00e9 ce mod\u00e8le de Deep Learning, comparez-le avec le mod\u00e8le Random Forest (Notebook A) sur les aspects suivants:\n\n1. Pr\u00e9paration des donn\u00e9es:\n   - Random Forest: n\u00e9cessite une r\u00e9duction de dimension (PCA)\n   - Deep Learning: travaille directement avec les pixels bruts\n\n2. Architecture et hyperparam\u00e8tres:\n   - Random Forest: nombre d'arbres, profondeur, crit\u00e8res de division\n   - Deep Learning: nombre de couches, neurones, fonctions d'activation, dropout\n\n3. Temps d'entra\u00eenement:\n   - Lequel est plus rapide sur ce jeu de donn\u00e9es?\n   - Comment cela \u00e9voluerait-il avec plus de donn\u00e9es?\n\n4. Performance:\n   - Sur les donn\u00e9es originales\n   - Sur les donn\u00e9es modifi\u00e9es (bruit, rotation)\n\n5. Interpr\u00e9tabilit\u00e9:\n   - Facilit\u00e9 \u00e0 comprendre ce que le mod\u00e8le a appris\n   - Visualisation des caract\u00e9ristiques importantes\n\nRemplissez le tableau comparatif fourni pour structurer votre analyse.\n\"\"\")\n</pre> # Notebook B: Classification avec Deep Learning # Classification des chiffres manuscrits avec un r\u00e9seau de neurones  # Partie 1: Importation des biblioth\u00e8ques import numpy as np import pandas as pd import matplotlib.pyplot as plt import time import tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense, Flatten, Dropout from tensorflow.keras.optimizers import Adam from tensorflow.keras.utils import to_categorical from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score, confusion_matrix, classification_report import seaborn as sns from google.colab import output output.enable_custom_widget_manager() import ipywidgets as widgets  # V\u00e9rifier la version de TensorFlow print(f\"TensorFlow version: {tf.__version__}\")  # Partie 2: Chargement et exploration des donn\u00e9es print(\"Chargement du jeu de donn\u00e9es MNIST...\") # Utilisation du jeu de donn\u00e9es MNIST int\u00e9gr\u00e9 \u00e0 TensorFlow (X_train_full, y_train_full), (X_test_full, y_test_full) = tf.keras.datasets.mnist.load_data()  # Normalisation des valeurs de pixels entre 0 et 1 X_train_full = X_train_full / 255.0 X_test_full = X_test_full / 255.0  # Exploration des donn\u00e9es print(f\"Dimensions des donn\u00e9es d'entra\u00eenement: {X_train_full.shape}\") print(f\"Dimensions des donn\u00e9es de test: {X_test_full.shape}\") print(f\"Nombre de classes: {len(np.unique(y_train_full))}\")  # Affichage de quelques exemples plt.figure(figsize=(10, 5)) for i in range(10):     plt.subplot(2, 5, i + 1)     plt.imshow(X_train_full[i], cmap='gray')     plt.title(f\"Label: {y_train_full[i]}\")     plt.axis('off') plt.tight_layout() plt.suptitle(\"Exemples de chiffres manuscrits\", y=1.05) plt.show()  # Partie 3: Pr\u00e9paration des donn\u00e9es pour Deep Learning  print(\"\\n--- Pr\u00e9paration des donn\u00e9es pour le r\u00e9seau de neurones ---\") print(\"Pour le Deep Learning, nous n'avons pas besoin d'extraire manuellement des caract\u00e9ristiques.\")  # Utiliser un sous-ensemble des donn\u00e9es pour acc\u00e9l\u00e9rer la d\u00e9monstration (m\u00eame taille que le Random Forest) n_samples = 10000 X_train = X_train_full[:n_samples] y_train = y_train_full[:n_samples] X_test = X_test_full[:2000] y_test = y_test_full[:2000]  # Pour le Deep Learning, il nous faut juste redimensionner les images print(\"Redimensionnement des images...\") print(f\"Forme originale: {X_train.shape}\")  # Aplatir les images 28x28 en vecteurs de 784 pixels X_train_flat = X_train.reshape(X_train.shape[0], 28*28) X_test_flat = X_test.reshape(X_test.shape[0], 28*28)  print(f\"Forme apr\u00e8s redimensionnement: {X_train_flat.shape}\")  # One-hot encoding des labels y_train_cat = to_categorical(y_train, 10) y_test_cat = to_categorical(y_test, 10)  print(\"Encodage one-hot des labels\") print(f\"Forme originale des labels: {y_train.shape}\") print(f\"Forme apr\u00e8s encodage one-hot: {y_train_cat.shape}\")  # Partie 4: Cr\u00e9ation du mod\u00e8le de Deep Learning  print(\"\\n--- Cr\u00e9ation du mod\u00e8le de r\u00e9seau de neurones ---\")  # Param\u00e8tres du mod\u00e8le - vous pouvez les modifier n_hidden1 = 128  # Nombre de neurones dans la premi\u00e8re couche cach\u00e9e n_hidden2 = 64   # Nombre de neurones dans la seconde couche cach\u00e9e learning_rate = 0.001  # Taux d'apprentissage dropout_rate = 0.2  # Taux de dropout pour la r\u00e9gularisation n_epochs = 10  # Nombre d'\u00e9poques d'entra\u00eenement batch_size = 32  # Taille du batch  # Cr\u00e9ation du mod\u00e8le model = Sequential([     # Couche d'entr\u00e9e: 784 neurones (un par pixel)     # Premi\u00e8re couche cach\u00e9e     Dense(n_hidden1, activation='relu', input_shape=(784,)),     Dropout(dropout_rate),     # Deuxi\u00e8me couche cach\u00e9e     Dense(n_hidden2, activation='relu'),     Dropout(dropout_rate),     # Couche de sortie: 10 neurones (un par classe)     Dense(10, activation='softmax') ])  # Compilation du mod\u00e8le optimizer = Adam(learning_rate=learning_rate) model.compile(     optimizer=optimizer,     loss='categorical_crossentropy',     metrics=['accuracy'] )  # Affichage du r\u00e9sum\u00e9 du mod\u00e8le model.summary()  # Partie 5: Entra\u00eenement du mod\u00e8le  print(\"\\n--- Entra\u00eenement du mod\u00e8le de Deep Learning ---\")  # Mesure du temps d'entra\u00eenement start_time = time.time() print(\"Entra\u00eenement du mod\u00e8le en cours...\")  # Entra\u00eenement du mod\u00e8le history = model.fit(     X_train_flat, y_train_cat,     epochs=n_epochs,     batch_size=batch_size,     validation_split=0.2,     verbose=1 )  end_time = time.time() training_time = end_time - start_time print(f\"Temps d'entra\u00eenement: {training_time:.2f} secondes\")  # Partie 6: Visualisation de l'apprentissage  print(\"\\n--- Visualisation de l'apprentissage ---\")  # Tracer l'\u00e9volution de la pr\u00e9cision et de la perte plt.figure(figsize=(12, 4))  # \u00c9volution de la pr\u00e9cision plt.subplot(1, 2, 1) plt.plot(history.history['accuracy'], label='Entra\u00eenement') plt.plot(history.history['val_accuracy'], label='Validation') plt.title('\u00c9volution de la pr\u00e9cision') plt.xlabel('\u00c9poque') plt.ylabel('Pr\u00e9cision') plt.legend()  # \u00c9volution de la perte plt.subplot(1, 2, 2) plt.plot(history.history['loss'], label='Entra\u00eenement') plt.plot(history.history['val_loss'], label='Validation') plt.title('\u00c9volution de la perte') plt.xlabel('\u00c9poque') plt.ylabel('Perte') plt.legend()  plt.tight_layout() plt.show()  # Partie 7: \u00c9valuation du mod\u00e8le  print(\"\\n--- \u00c9valuation du mod\u00e8le de Deep Learning ---\")  # \u00c9valuation sur l'ensemble de test test_loss, test_accuracy = model.evaluate(X_test_flat, y_test_cat, verbose=0) print(f\"Pr\u00e9cision sur l'ensemble de test: {test_accuracy*100:.2f}%\")  # Pr\u00e9dictions sur l'ensemble de test y_pred_prob = model.predict(X_test_flat) y_pred = np.argmax(y_pred_prob, axis=1)  # Calcul des m\u00e9triques conf_matrix = confusion_matrix(y_test, y_pred) class_report = classification_report(y_test, y_pred)  print(\"\\nMatrice de confusion:\") plt.figure(figsize=(8, 6)) sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues') plt.xlabel('Pr\u00e9dictions') plt.ylabel('Valeurs r\u00e9elles') plt.title('Matrice de confusion') plt.show()  print(\"\\nRapport de classification:\") print(class_report)  # Partie 8: Visualisation des erreurs  print(\"\\n--- Analyse des erreurs ---\")  # Identifier les erreurs error_indices = np.where(y_pred != y_test)[0] n_errors = min(10, len(error_indices))  # Afficher max 10 erreurs  if n_errors &gt; 0:     plt.figure(figsize=(12, 4))     for i, idx in enumerate(error_indices[:n_errors]):         plt.subplot(2, 5, i + 1)         plt.imshow(X_test[idx], cmap='gray')         plt.title(f\"R\u00e9el: {y_test[idx]}\\nPr\u00e9dit: {y_pred[idx]}\")         plt.axis('off')     plt.tight_layout()     plt.suptitle(\"Exemples d'erreurs de classification\", y=1.05)     plt.show() else:     print(\"Aucune erreur trouv\u00e9e dans l'\u00e9chantillon de test!\")  # Partie 9: Visualisation des poids  print(\"\\n--- Visualisation des poids appris ---\")  # R\u00e9cup\u00e9rer les poids de la premi\u00e8re couche weights = model.layers[0].get_weights()[0]  # [784, n_hidden1]  # Visualiser quelques filtres (neurones de la premi\u00e8re couche) plt.figure(figsize=(12, 6)) for i in range(10):     plt.subplot(2, 5, i + 1)     # Redimensionner les poids du neurone en 28x28     neuron_weights = weights[:, i].reshape(28, 28)     plt.imshow(neuron_weights, cmap='coolwarm')     plt.title(f\"Neurone {i+1}\")     plt.axis('off') plt.tight_layout() plt.suptitle(\"Poids appris par les neurones de la premi\u00e8re couche\", y=1.05) plt.show()  print(\"Ces visualisations montrent ce que 'recherchent' les neurones de la premi\u00e8re couche dans les images.\")  # Partie 10: D\u00e9fi de g\u00e9n\u00e9ralisation  print(\"\\n--- D\u00e9fi de g\u00e9n\u00e9ralisation ---\") print(\"Nous allons maintenant tester le mod\u00e8le sur des chiffres l\u00e9g\u00e8rement modifi\u00e9s pour \u00e9valuer sa capacit\u00e9 de g\u00e9n\u00e9ralisation.\")  # Fonction pour ajouter du bruit aux images def add_noise(images, noise_level=0.2):     noisy_images = images.copy()     noise = np.random.normal(0, noise_level, images.shape)     noisy_images = noisy_images + noise     # Assurer que les valeurs restent entre 0 et 1     noisy_images = np.clip(noisy_images, 0, 1)     return noisy_images  # Fonction pour appliquer une rotation aux images def rotate_images(images, max_angle=15):     from scipy.ndimage import rotate     rotated_images = np.zeros_like(images)     for i, img in enumerate(images):         angle = np.random.uniform(-max_angle, max_angle)         rotated = rotate(img, angle, reshape=False)         rotated_images[i] = rotated     return rotated_images  # Cr\u00e9er un jeu de donn\u00e9es modifi\u00e9 print(\"Cr\u00e9ation d'un jeu de donn\u00e9es avec des chiffres modifi\u00e9s...\")  # Utiliser un nouvel ensemble de donn\u00e9es pour ce test X_new = X_test_full[2000:4000] y_new = y_test_full[2000:4000]  # Appliquer des transformations X_new_noisy = add_noise(X_new, noise_level=0.2) X_new_rotated = rotate_images(X_new, max_angle=15)  # Visualiser quelques exemples plt.figure(figsize=(12, 8)) for i in range(5):     # Original     plt.subplot(3, 5, i + 1)     plt.imshow(X_new[i], cmap='gray')     plt.title(f\"Original: {y_new[i]}\")     plt.axis('off')          # Avec bruit     plt.subplot(3, 5, i + 6)     plt.imshow(X_new_noisy[i], cmap='gray')     plt.title(\"Avec bruit\")     plt.axis('off')          # Avec rotation     plt.subplot(3, 5, i + 11)     plt.imshow(X_new_rotated[i], cmap='gray')     plt.title(\"Avec rotation\")     plt.axis('off')  plt.tight_layout() plt.suptitle(\"Exemples de chiffres modifi\u00e9s\", y=1.02) plt.show()  # Pr\u00e9paration des donn\u00e9es modifi\u00e9es X_new_flat = X_new.reshape(X_new.shape[0], 28*28) X_new_noisy_flat = X_new_noisy.reshape(X_new_noisy.shape[0], 28*28) X_new_rotated_flat = X_new_rotated.reshape(X_new_rotated.shape[0], 28*28)  # \u00c9valuer le mod\u00e8le sur les donn\u00e9es modifi\u00e9es print(\"\\n\u00c9valuation sur les donn\u00e9es originales:\") y_new_pred = np.argmax(model.predict(X_new_flat), axis=1) accuracy_original = accuracy_score(y_new, y_new_pred) print(f\"Pr\u00e9cision sur donn\u00e9es originales: {accuracy_original*100:.2f}%\")  print(\"\\n\u00c9valuation sur les donn\u00e9es avec bruit:\") y_new_noisy_pred = np.argmax(model.predict(X_new_noisy_flat), axis=1) accuracy_noisy = accuracy_score(y_new, y_new_noisy_pred) print(f\"Pr\u00e9cision sur donn\u00e9es bruit\u00e9es: {accuracy_noisy*100:.2f}%\")  print(\"\\n\u00c9valuation sur les donn\u00e9es avec rotation:\") y_new_rotated_pred = np.argmax(model.predict(X_new_rotated_flat), axis=1) accuracy_rotated = accuracy_score(y_new, y_new_rotated_pred) print(f\"Pr\u00e9cision sur donn\u00e9es pivot\u00e9es: {accuracy_rotated*100:.2f}%\")  print(\"\\nComparaison des pr\u00e9cisions:\") print(f\"Pr\u00e9cision sur donn\u00e9es originales: {accuracy_original*100:.2f}%\") print(f\"Pr\u00e9cision sur donn\u00e9es bruit\u00e9es: {accuracy_noisy*100:.2f}%\") print(f\"Pr\u00e9cision sur donn\u00e9es pivot\u00e9es: {accuracy_rotated*100:.2f}%\")  # Partie 11: Conclusions et r\u00e9flexion  print(\"\\n--- Conclusions sur le Deep Learning ---\") print(\"\"\" Points forts du r\u00e9seau de neurones: - Apprentissage automatique des caract\u00e9ristiques (pas de feature engineering manuel) - Bonnes performances sur les donn\u00e9es originales et transform\u00e9es - Capacit\u00e9 \u00e0 capturer des motifs complexes  Limites: - Temps d'entra\u00eenement g\u00e9n\u00e9ralement plus long que les m\u00e9thodes classiques - Plus de param\u00e8tres \u00e0 r\u00e9gler - Risque de surapprentissage sur petits ensembles de donn\u00e9es - Interpr\u00e9tabilit\u00e9 plus difficile  Questions pour la r\u00e9flexion: 1. Pourquoi le Deep Learning g\u00e8re-t-il mieux les transformations des donn\u00e9es? 2. Comment pourrions-nous am\u00e9liorer encore les performances du mod\u00e8le? 3. Quels types de probl\u00e8mes sont particuli\u00e8rement adapt\u00e9s au Deep Learning? \"\"\")  # Partie 12: Widget interactif pour tester le mod\u00e8le  print(\"\\n--- Testez le mod\u00e8le vous-m\u00eame ---\")  def test_dl_model(digit_idx):     if digit_idx &lt; len(X_test):         # Afficher l'image         img = X_test[digit_idx]         plt.figure(figsize=(6, 6))         plt.imshow(img, cmap='gray')         plt.title(f\"Chiffre \u00e0 classifier\")         plt.axis('off')         plt.show()                  # Faire la pr\u00e9diction         img_flat = img.reshape(1, 784)         prediction_prob = model.predict(img_flat)[0]         prediction = np.argmax(prediction_prob)         real_label = y_test[digit_idx]                  # Afficher les probabilit\u00e9s         plt.figure(figsize=(10, 4))         plt.bar(range(10), prediction_prob)         plt.xticks(range(10))         plt.xlabel('Chiffre')         plt.ylabel('Probabilit\u00e9')         plt.title('Probabilit\u00e9s pr\u00e9dites pour chaque chiffre')         plt.show()                  print(f\"Pr\u00e9diction du mod\u00e8le Deep Learning: {prediction}\")         print(f\"\u00c9tiquette r\u00e9elle: {real_label}\")         print(f\"Pr\u00e9diction {'correcte' if prediction == real_label else 'incorrecte'}\")                  # Afficher les 3 pr\u00e9dictions les plus probables         top3_idx = np.argsort(prediction_prob)[-3:][::-1]         print(\"\\nTop 3 des pr\u00e9dictions:\")         for i, idx in enumerate(top3_idx):             print(f\"{i+1}. Chiffre {idx}: {prediction_prob[idx]*100:.2f}%\")     else:         print(\"Index hors limites!\")  # Cr\u00e9er un slider pour s\u00e9lectionner un chiffre \u00e0 tester digit_selector = widgets.IntSlider(     value=0,     min=0,     max=len(X_test)-1,     step=1,     description='Index:',     continuous_update=False )  # Bouton pour ex\u00e9cuter le test test_button = widgets.Button(description=\"Tester\") output = widgets.Output()  def on_button_clicked(b):     with output:         output.clear_output()         test_dl_model(digit_selector.value)  test_button.on_click(on_button_clicked)  # Afficher les widgets display(widgets.HBox([digit_selector, test_button])) display(output)  print(\"Utilisez le slider pour s\u00e9lectionner un index et cliquez sur 'Tester' pour classifier le chiffre correspondant.\")  # Partie 13: Comparaison avec le mod\u00e8le Random Forest  print(\"\\n--- Comment comparer avec le mod\u00e8le de Machine Learning classique? ---\") print(\"\"\" Apr\u00e8s avoir explor\u00e9 ce mod\u00e8le de Deep Learning, comparez-le avec le mod\u00e8le Random Forest (Notebook A) sur les aspects suivants:  1. Pr\u00e9paration des donn\u00e9es:    - Random Forest: n\u00e9cessite une r\u00e9duction de dimension (PCA)    - Deep Learning: travaille directement avec les pixels bruts  2. Architecture et hyperparam\u00e8tres:    - Random Forest: nombre d'arbres, profondeur, crit\u00e8res de division    - Deep Learning: nombre de couches, neurones, fonctions d'activation, dropout  3. Temps d'entra\u00eenement:    - Lequel est plus rapide sur ce jeu de donn\u00e9es?    - Comment cela \u00e9voluerait-il avec plus de donn\u00e9es?  4. Performance:    - Sur les donn\u00e9es originales    - Sur les donn\u00e9es modifi\u00e9es (bruit, rotation)  5. Interpr\u00e9tabilit\u00e9:    - Facilit\u00e9 \u00e0 comprendre ce que le mod\u00e8le a appris    - Visualisation des caract\u00e9ristiques importantes  Remplissez le tableau comparatif fourni pour structurer votre analyse. \"\"\")"},{"location":"seance1/partie2-decouverte-concepts/machine-learning-classique/","title":"Machine learning classique","text":"In\u00a0[\u00a0]: Copied! <pre># Notebook A: Classification avec Machine Learning classique\n# Classification des chiffres manuscrits avec Random Forest\n\n# Partie 1: Importation des biblioth\u00e8ques\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nimport time\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport seaborn as sns\nfrom sklearn.pipeline import Pipeline\nfrom google.colab import output\noutput.enable_custom_widget_manager()\nimport ipywidgets as widgets\n\n# Partie 2: Chargement et exploration des donn\u00e9es\nprint(\"Chargement du jeu de donn\u00e9es MNIST...\")\n# Utilisation du jeu de donn\u00e9es MNIST int\u00e9gr\u00e9 \u00e0 sklearn\nfrom sklearn.datasets import fetch_openml\nmnist = fetch_openml('mnist_784', version=1, as_frame=False)\nX, y = mnist[\"data\"], mnist[\"target\"]\nX = X / 255.0  # Normalisation des valeurs de pixels entre 0 et 1\ny = y.astype(np.uint8)  # Conversion des labels en entiers\n\n# Exploration des donn\u00e9es\nprint(f\"Dimensions du jeu de donn\u00e9es: {X.shape}\")\nprint(f\"Nombre de classes: {len(np.unique(y))}\")\n\n# Affichage de quelques exemples\nplt.figure(figsize=(10, 5))\nfor i in range(10):\n    plt.subplot(2, 5, i + 1)\n    plt.imshow(X[i].reshape(28, 28), cmap='gray')\n    plt.title(f\"Label: {y[i]}\")\n    plt.axis('off')\nplt.tight_layout()\nplt.suptitle(\"Exemples de chiffres manuscrits\", y=1.05)\nplt.show()\n\n# Partie 3: Pr\u00e9paration des donn\u00e9es pour Machine Learning classique\n\nprint(\"\\n--- Pr\u00e9paration des donn\u00e9es pour Random Forest ---\")\nprint(\"Pour le Machine Learning classique, nous devons souvent extraire des caract\u00e9ristiques manuellement.\")\n\n# R\u00e9duction de dimension avec PCA pour acc\u00e9l\u00e9rer l'entra\u00eenement\nprint(\"Application d'une r\u00e9duction de dimension (PCA)...\")\nn_components = 50  # R\u00e9duire de 784 \u00e0 50 caract\u00e9ristiques\n\n# S\u00e9paration en ensembles d'entra\u00eenement et de test\n# Utilisation d'un \u00e9chantillon r\u00e9duit pour acc\u00e9l\u00e9rer la d\u00e9monstration\nX_sample = X[:10000]\ny_sample = y[:10000]\n\nX_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)\n\nprint(f\"Taille de l'ensemble d'entra\u00eenement: {X_train.shape}\")\nprint(f\"Taille de l'ensemble de test: {X_test.shape}\")\n\n# Cr\u00e9ation d'un pipeline d'extraction de caract\u00e9ristiques\nfeature_pipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('pca', PCA(n_components=n_components))\n])\n\n# Application aux donn\u00e9es\nprint(\"Extraction de caract\u00e9ristiques...\")\nX_train_features = feature_pipeline.fit_transform(X_train)\nX_test_features = feature_pipeline.transform(X_test)\n\nprint(f\"Dimensions apr\u00e8s extraction de caract\u00e9ristiques: {X_train_features.shape}\")\n\n# Partie 4: Entra\u00eenement du mod\u00e8le Random Forest\n\nprint(\"\\n--- Entra\u00eenement du mod\u00e8le Random Forest ---\")\n\n# Param\u00e8tres du mod\u00e8le - vous pouvez les modifier\nn_estimators = 100  # Nombre d'arbres\nmax_depth = 10      # Profondeur maximale des arbres\nmin_samples_split = 2  # Nombre minimum d'\u00e9chantillons requis pour diviser un n\u0153ud\n\n# Cr\u00e9ation du mod\u00e8le\nrf_model = RandomForestClassifier(\n    n_estimators=n_estimators,\n    max_depth=max_depth,\n    min_samples_split=min_samples_split,\n    random_state=42,\n    n_jobs=-1  # Utiliser tous les c\u0153urs disponibles\n)\n\n# Mesure du temps d'entra\u00eenement\nstart_time = time.time()\nprint(\"Entra\u00eenement du mod\u00e8le en cours...\")\nrf_model.fit(X_train_features, y_train)\nend_time = time.time()\ntraining_time = end_time - start_time\n\nprint(f\"Temps d'entra\u00eenement: {training_time:.2f} secondes\")\n\n# Partie 5: \u00c9valuation du mod\u00e8le\n\nprint(\"\\n--- \u00c9valuation du mod\u00e8le Random Forest ---\")\n\n# Pr\u00e9dictions sur l'ensemble de test\ny_pred = rf_model.predict(X_test_features)\n\n# Calcul des m\u00e9triques\naccuracy = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\nclass_report = classification_report(y_test, y_pred)\n\nprint(f\"Pr\u00e9cision globale: {accuracy*100:.2f}%\")\nprint(\"\\nMatrice de confusion:\")\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Pr\u00e9dictions')\nplt.ylabel('Valeurs r\u00e9elles')\nplt.title('Matrice de confusion')\nplt.show()\n\nprint(\"\\nRapport de classification:\")\nprint(class_report)\n\n# Partie 6: Visualisation des erreurs\n\nprint(\"\\n--- Analyse des erreurs ---\")\n\n# Identifier les erreurs\nerror_indices = np.where(y_pred != y_test)[0]\nn_errors = min(10, len(error_indices))  # Afficher max 10 erreurs\n\nif n_errors &gt; 0:\n    plt.figure(figsize=(12, 4))\n    for i, idx in enumerate(error_indices[:n_errors]):\n        plt.subplot(2, 5, i + 1)\n        # R\u00e9cup\u00e9rer l'image originale\n        img = X_test[idx].reshape(28, 28)\n        plt.imshow(img, cmap='gray')\n        plt.title(f\"R\u00e9el: {y_test[idx]}\\nPr\u00e9dit: {y_pred[idx]}\")\n        plt.axis('off')\n    plt.tight_layout()\n    plt.suptitle(\"Exemples d'erreurs de classification\", y=1.05)\n    plt.show()\nelse:\n    print(\"Aucune erreur trouv\u00e9e dans l'\u00e9chantillon de test!\")\n\n# Partie 7: Importance des caract\u00e9ristiques\n\nprint(\"\\n--- Importance des caract\u00e9ristiques ---\")\n# Visualiser l'importance des composantes principales\nfeature_importance = rf_model.feature_importances_\nsorted_idx = np.argsort(feature_importance)[::-1]\n\nplt.figure(figsize=(10, 5))\nplt.bar(range(20), feature_importance[sorted_idx[:20]])\nplt.xticks(range(20), [f\"Feat {i}\" for i in sorted_idx[:20]], rotation=90)\nplt.xlabel('Composantes principales')\nplt.ylabel('Importance')\nplt.title('Top 20 des composantes principales les plus importantes')\nplt.tight_layout()\nplt.show()\n\nprint(\"Les caract\u00e9ristiques les plus importantes sont les composantes principales qui capturent le plus de variance dans les donn\u00e9es.\")\n\n# Partie 8: D\u00e9fi de g\u00e9n\u00e9ralisation\n\nprint(\"\\n--- D\u00e9fi de g\u00e9n\u00e9ralisation ---\")\nprint(\"Nous allons maintenant tester le mod\u00e8le sur des chiffres l\u00e9g\u00e8rement modifi\u00e9s pour \u00e9valuer sa capacit\u00e9 de g\u00e9n\u00e9ralisation.\")\n\n# Fonction pour ajouter du bruit aux images\ndef add_noise(images, noise_level=0.2):\n    noisy_images = images.copy()\n    noise = np.random.normal(0, noise_level, images.shape)\n    noisy_images = noisy_images + noise\n    # Assurer que les valeurs restent entre 0 et 1\n    noisy_images = np.clip(noisy_images, 0, 1)\n    return noisy_images\n\n# Fonction pour appliquer une rotation aux images\ndef rotate_images(images, max_angle=15):\n    from scipy.ndimage import rotate\n    rotated_images = np.zeros_like(images)\n    for i, img in enumerate(images):\n        angle = np.random.uniform(-max_angle, max_angle)\n        img_2d = img.reshape(28, 28)\n        rotated = rotate(img_2d, angle, reshape=False)\n        rotated_images[i] = rotated.flatten()\n    return rotated_images\n\n# Cr\u00e9er un jeu de donn\u00e9es modifi\u00e9\nprint(\"Cr\u00e9ation d'un jeu de donn\u00e9es avec des chiffres modifi\u00e9s...\")\n\n# Utiliser la partie restante des donn\u00e9es pour ce test\nX_new = X[10000:12000]\ny_new = y[10000:12000]\n\n# Appliquer des transformations\nX_new_noisy = add_noise(X_new, noise_level=0.2)\nX_new_rotated = rotate_images(X_new, max_angle=15)\n\n# Visualiser quelques exemples\nplt.figure(figsize=(12, 8))\nfor i in range(5):\n    # Original\n    plt.subplot(3, 5, i + 1)\n    plt.imshow(X_new[i].reshape(28, 28), cmap='gray')\n    plt.title(f\"Original: {y_new[i]}\")\n    plt.axis('off')\n    \n    # Avec bruit\n    plt.subplot(3, 5, i + 6)\n    plt.imshow(X_new_noisy[i].reshape(28, 28), cmap='gray')\n    plt.title(\"Avec bruit\")\n    plt.axis('off')\n    \n    # Avec rotation\n    plt.subplot(3, 5, i + 11)\n    plt.imshow(X_new_rotated[i].reshape(28, 28), cmap='gray')\n    plt.title(\"Avec rotation\")\n    plt.axis('off')\n\nplt.tight_layout()\nplt.suptitle(\"Exemples de chiffres modifi\u00e9s\", y=1.02)\nplt.show()\n\n# \u00c9valuer le mod\u00e8le sur les donn\u00e9es modifi\u00e9es\nprint(\"\\n\u00c9valuation sur les donn\u00e9es avec bruit:\")\nX_new_noisy_features = feature_pipeline.transform(X_new_noisy)\ny_new_noisy_pred = rf_model.predict(X_new_noisy_features)\naccuracy_noisy = accuracy_score(y_new, y_new_noisy_pred)\nprint(f\"Pr\u00e9cision sur donn\u00e9es bruit\u00e9es: {accuracy_noisy*100:.2f}%\")\n\nprint(\"\\n\u00c9valuation sur les donn\u00e9es avec rotation:\")\nX_new_rotated_features = feature_pipeline.transform(X_new_rotated)\ny_new_rotated_pred = rf_model.predict(X_new_rotated_features)\naccuracy_rotated = accuracy_score(y_new, y_new_rotated_pred)\nprint(f\"Pr\u00e9cision sur donn\u00e9es pivot\u00e9es: {accuracy_rotated*100:.2f}%\")\n\nprint(\"\\nComparaison avec la pr\u00e9cision originale:\")\nprint(f\"Pr\u00e9cision sur donn\u00e9es originales: {accuracy*100:.2f}%\")\nprint(f\"Pr\u00e9cision sur donn\u00e9es bruit\u00e9es: {accuracy_noisy*100:.2f}%\")\nprint(f\"Pr\u00e9cision sur donn\u00e9es pivot\u00e9es: {accuracy_rotated*100:.2f}%\")\n\n# Partie 9: Conclusions et r\u00e9flexion\n\nprint(\"\\n--- Conclusions sur le Machine Learning classique ---\")\nprint(\"\"\"\nPoints forts du Random Forest:\n- Entra\u00eenement relativement rapide\n- Bonnes performances sur les donn\u00e9es originales\n- Interpr\u00e9tabilit\u00e9 (importance des caract\u00e9ristiques)\n\nLimites:\n- N\u00e9cessite une extraction manuelle de caract\u00e9ristiques (PCA dans notre cas)\n- Sensibilit\u00e9 aux transformations des donn\u00e9es (bruit, rotation)\n- Difficult\u00e9 \u00e0 capturer des motifs complexes sans feature engineering appropri\u00e9\n\nQuestions pour la r\u00e9flexion:\n1. Pourquoi avons-nous besoin de r\u00e9duire la dimensionnalit\u00e9 pour le Random Forest?\n2. Comment pourrait-on am\u00e9liorer la robustesse aux transformations?\n3. Quelles autres caract\u00e9ristiques pourraient \u00eatre extraites manuellement pour am\u00e9liorer les performances?\n\"\"\")\n\n# Partie 10: Widget interactif pour tester le mod\u00e8le\n\nprint(\"\\n--- Testez le mod\u00e8le vous-m\u00eame ---\")\n\ndef test_model(digit_idx):\n    if digit_idx &lt; len(X_test):\n        # Afficher l'image\n        img = X_test[digit_idx].reshape(28, 28)\n        plt.figure(figsize=(6, 6))\n        plt.imshow(img, cmap='gray')\n        plt.title(f\"Chiffre \u00e0 classifier\")\n        plt.axis('off')\n        plt.show()\n        \n        # Faire la pr\u00e9diction\n        features = feature_pipeline.transform([X_test[digit_idx]])\n        prediction = rf_model.predict(features)[0]\n        real_label = y_test[digit_idx]\n        \n        print(f\"Pr\u00e9diction du mod\u00e8le Random Forest: {prediction}\")\n        print(f\"\u00c9tiquette r\u00e9elle: {real_label}\")\n        print(f\"Pr\u00e9diction {'correcte' if prediction == real_label else 'incorrecte'}\")\n    else:\n        print(\"Index hors limites!\")\n\n# Cr\u00e9er un slider pour s\u00e9lectionner un chiffre \u00e0 tester\ndigit_selector = widgets.IntSlider(\n    value=0,\n    min=0,\n    max=len(X_test)-1,\n    step=1,\n    description='Index:',\n    continuous_update=False\n)\n\n# Bouton pour ex\u00e9cuter le test\ntest_button = widgets.Button(description=\"Tester\")\noutput = widgets.Output()\n\ndef on_button_clicked(b):\n    with output:\n        output.clear_output()\n        test_model(digit_selector.value)\n\ntest_button.on_click(on_button_clicked)\n\n# Afficher les widgets\ndisplay(widgets.HBox([digit_selector, test_button]))\ndisplay(output)\n\nprint(\"Utilisez le slider pour s\u00e9lectionner un index et cliquez sur 'Tester' pour classifier le chiffre correspondant.\")\n</pre> # Notebook A: Classification avec Machine Learning classique # Classification des chiffres manuscrits avec Random Forest  # Partie 1: Importation des biblioth\u00e8ques import numpy as np import pandas as pd import matplotlib.pyplot as plt from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score, confusion_matrix, classification_report import time from sklearn.preprocessing import StandardScaler from sklearn.decomposition import PCA import seaborn as sns from sklearn.pipeline import Pipeline from google.colab import output output.enable_custom_widget_manager() import ipywidgets as widgets  # Partie 2: Chargement et exploration des donn\u00e9es print(\"Chargement du jeu de donn\u00e9es MNIST...\") # Utilisation du jeu de donn\u00e9es MNIST int\u00e9gr\u00e9 \u00e0 sklearn from sklearn.datasets import fetch_openml mnist = fetch_openml('mnist_784', version=1, as_frame=False) X, y = mnist[\"data\"], mnist[\"target\"] X = X / 255.0  # Normalisation des valeurs de pixels entre 0 et 1 y = y.astype(np.uint8)  # Conversion des labels en entiers  # Exploration des donn\u00e9es print(f\"Dimensions du jeu de donn\u00e9es: {X.shape}\") print(f\"Nombre de classes: {len(np.unique(y))}\")  # Affichage de quelques exemples plt.figure(figsize=(10, 5)) for i in range(10):     plt.subplot(2, 5, i + 1)     plt.imshow(X[i].reshape(28, 28), cmap='gray')     plt.title(f\"Label: {y[i]}\")     plt.axis('off') plt.tight_layout() plt.suptitle(\"Exemples de chiffres manuscrits\", y=1.05) plt.show()  # Partie 3: Pr\u00e9paration des donn\u00e9es pour Machine Learning classique  print(\"\\n--- Pr\u00e9paration des donn\u00e9es pour Random Forest ---\") print(\"Pour le Machine Learning classique, nous devons souvent extraire des caract\u00e9ristiques manuellement.\")  # R\u00e9duction de dimension avec PCA pour acc\u00e9l\u00e9rer l'entra\u00eenement print(\"Application d'une r\u00e9duction de dimension (PCA)...\") n_components = 50  # R\u00e9duire de 784 \u00e0 50 caract\u00e9ristiques  # S\u00e9paration en ensembles d'entra\u00eenement et de test # Utilisation d'un \u00e9chantillon r\u00e9duit pour acc\u00e9l\u00e9rer la d\u00e9monstration X_sample = X[:10000] y_sample = y[:10000]  X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)  print(f\"Taille de l'ensemble d'entra\u00eenement: {X_train.shape}\") print(f\"Taille de l'ensemble de test: {X_test.shape}\")  # Cr\u00e9ation d'un pipeline d'extraction de caract\u00e9ristiques feature_pipeline = Pipeline([     ('scaler', StandardScaler()),     ('pca', PCA(n_components=n_components)) ])  # Application aux donn\u00e9es print(\"Extraction de caract\u00e9ristiques...\") X_train_features = feature_pipeline.fit_transform(X_train) X_test_features = feature_pipeline.transform(X_test)  print(f\"Dimensions apr\u00e8s extraction de caract\u00e9ristiques: {X_train_features.shape}\")  # Partie 4: Entra\u00eenement du mod\u00e8le Random Forest  print(\"\\n--- Entra\u00eenement du mod\u00e8le Random Forest ---\")  # Param\u00e8tres du mod\u00e8le - vous pouvez les modifier n_estimators = 100  # Nombre d'arbres max_depth = 10      # Profondeur maximale des arbres min_samples_split = 2  # Nombre minimum d'\u00e9chantillons requis pour diviser un n\u0153ud  # Cr\u00e9ation du mod\u00e8le rf_model = RandomForestClassifier(     n_estimators=n_estimators,     max_depth=max_depth,     min_samples_split=min_samples_split,     random_state=42,     n_jobs=-1  # Utiliser tous les c\u0153urs disponibles )  # Mesure du temps d'entra\u00eenement start_time = time.time() print(\"Entra\u00eenement du mod\u00e8le en cours...\") rf_model.fit(X_train_features, y_train) end_time = time.time() training_time = end_time - start_time  print(f\"Temps d'entra\u00eenement: {training_time:.2f} secondes\")  # Partie 5: \u00c9valuation du mod\u00e8le  print(\"\\n--- \u00c9valuation du mod\u00e8le Random Forest ---\")  # Pr\u00e9dictions sur l'ensemble de test y_pred = rf_model.predict(X_test_features)  # Calcul des m\u00e9triques accuracy = accuracy_score(y_test, y_pred) conf_matrix = confusion_matrix(y_test, y_pred) class_report = classification_report(y_test, y_pred)  print(f\"Pr\u00e9cision globale: {accuracy*100:.2f}%\") print(\"\\nMatrice de confusion:\") plt.figure(figsize=(8, 6)) sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues') plt.xlabel('Pr\u00e9dictions') plt.ylabel('Valeurs r\u00e9elles') plt.title('Matrice de confusion') plt.show()  print(\"\\nRapport de classification:\") print(class_report)  # Partie 6: Visualisation des erreurs  print(\"\\n--- Analyse des erreurs ---\")  # Identifier les erreurs error_indices = np.where(y_pred != y_test)[0] n_errors = min(10, len(error_indices))  # Afficher max 10 erreurs  if n_errors &gt; 0:     plt.figure(figsize=(12, 4))     for i, idx in enumerate(error_indices[:n_errors]):         plt.subplot(2, 5, i + 1)         # R\u00e9cup\u00e9rer l'image originale         img = X_test[idx].reshape(28, 28)         plt.imshow(img, cmap='gray')         plt.title(f\"R\u00e9el: {y_test[idx]}\\nPr\u00e9dit: {y_pred[idx]}\")         plt.axis('off')     plt.tight_layout()     plt.suptitle(\"Exemples d'erreurs de classification\", y=1.05)     plt.show() else:     print(\"Aucune erreur trouv\u00e9e dans l'\u00e9chantillon de test!\")  # Partie 7: Importance des caract\u00e9ristiques  print(\"\\n--- Importance des caract\u00e9ristiques ---\") # Visualiser l'importance des composantes principales feature_importance = rf_model.feature_importances_ sorted_idx = np.argsort(feature_importance)[::-1]  plt.figure(figsize=(10, 5)) plt.bar(range(20), feature_importance[sorted_idx[:20]]) plt.xticks(range(20), [f\"Feat {i}\" for i in sorted_idx[:20]], rotation=90) plt.xlabel('Composantes principales') plt.ylabel('Importance') plt.title('Top 20 des composantes principales les plus importantes') plt.tight_layout() plt.show()  print(\"Les caract\u00e9ristiques les plus importantes sont les composantes principales qui capturent le plus de variance dans les donn\u00e9es.\")  # Partie 8: D\u00e9fi de g\u00e9n\u00e9ralisation  print(\"\\n--- D\u00e9fi de g\u00e9n\u00e9ralisation ---\") print(\"Nous allons maintenant tester le mod\u00e8le sur des chiffres l\u00e9g\u00e8rement modifi\u00e9s pour \u00e9valuer sa capacit\u00e9 de g\u00e9n\u00e9ralisation.\")  # Fonction pour ajouter du bruit aux images def add_noise(images, noise_level=0.2):     noisy_images = images.copy()     noise = np.random.normal(0, noise_level, images.shape)     noisy_images = noisy_images + noise     # Assurer que les valeurs restent entre 0 et 1     noisy_images = np.clip(noisy_images, 0, 1)     return noisy_images  # Fonction pour appliquer une rotation aux images def rotate_images(images, max_angle=15):     from scipy.ndimage import rotate     rotated_images = np.zeros_like(images)     for i, img in enumerate(images):         angle = np.random.uniform(-max_angle, max_angle)         img_2d = img.reshape(28, 28)         rotated = rotate(img_2d, angle, reshape=False)         rotated_images[i] = rotated.flatten()     return rotated_images  # Cr\u00e9er un jeu de donn\u00e9es modifi\u00e9 print(\"Cr\u00e9ation d'un jeu de donn\u00e9es avec des chiffres modifi\u00e9s...\")  # Utiliser la partie restante des donn\u00e9es pour ce test X_new = X[10000:12000] y_new = y[10000:12000]  # Appliquer des transformations X_new_noisy = add_noise(X_new, noise_level=0.2) X_new_rotated = rotate_images(X_new, max_angle=15)  # Visualiser quelques exemples plt.figure(figsize=(12, 8)) for i in range(5):     # Original     plt.subplot(3, 5, i + 1)     plt.imshow(X_new[i].reshape(28, 28), cmap='gray')     plt.title(f\"Original: {y_new[i]}\")     plt.axis('off')          # Avec bruit     plt.subplot(3, 5, i + 6)     plt.imshow(X_new_noisy[i].reshape(28, 28), cmap='gray')     plt.title(\"Avec bruit\")     plt.axis('off')          # Avec rotation     plt.subplot(3, 5, i + 11)     plt.imshow(X_new_rotated[i].reshape(28, 28), cmap='gray')     plt.title(\"Avec rotation\")     plt.axis('off')  plt.tight_layout() plt.suptitle(\"Exemples de chiffres modifi\u00e9s\", y=1.02) plt.show()  # \u00c9valuer le mod\u00e8le sur les donn\u00e9es modifi\u00e9es print(\"\\n\u00c9valuation sur les donn\u00e9es avec bruit:\") X_new_noisy_features = feature_pipeline.transform(X_new_noisy) y_new_noisy_pred = rf_model.predict(X_new_noisy_features) accuracy_noisy = accuracy_score(y_new, y_new_noisy_pred) print(f\"Pr\u00e9cision sur donn\u00e9es bruit\u00e9es: {accuracy_noisy*100:.2f}%\")  print(\"\\n\u00c9valuation sur les donn\u00e9es avec rotation:\") X_new_rotated_features = feature_pipeline.transform(X_new_rotated) y_new_rotated_pred = rf_model.predict(X_new_rotated_features) accuracy_rotated = accuracy_score(y_new, y_new_rotated_pred) print(f\"Pr\u00e9cision sur donn\u00e9es pivot\u00e9es: {accuracy_rotated*100:.2f}%\")  print(\"\\nComparaison avec la pr\u00e9cision originale:\") print(f\"Pr\u00e9cision sur donn\u00e9es originales: {accuracy*100:.2f}%\") print(f\"Pr\u00e9cision sur donn\u00e9es bruit\u00e9es: {accuracy_noisy*100:.2f}%\") print(f\"Pr\u00e9cision sur donn\u00e9es pivot\u00e9es: {accuracy_rotated*100:.2f}%\")  # Partie 9: Conclusions et r\u00e9flexion  print(\"\\n--- Conclusions sur le Machine Learning classique ---\") print(\"\"\" Points forts du Random Forest: - Entra\u00eenement relativement rapide - Bonnes performances sur les donn\u00e9es originales - Interpr\u00e9tabilit\u00e9 (importance des caract\u00e9ristiques)  Limites: - N\u00e9cessite une extraction manuelle de caract\u00e9ristiques (PCA dans notre cas) - Sensibilit\u00e9 aux transformations des donn\u00e9es (bruit, rotation) - Difficult\u00e9 \u00e0 capturer des motifs complexes sans feature engineering appropri\u00e9  Questions pour la r\u00e9flexion: 1. Pourquoi avons-nous besoin de r\u00e9duire la dimensionnalit\u00e9 pour le Random Forest? 2. Comment pourrait-on am\u00e9liorer la robustesse aux transformations? 3. Quelles autres caract\u00e9ristiques pourraient \u00eatre extraites manuellement pour am\u00e9liorer les performances? \"\"\")  # Partie 10: Widget interactif pour tester le mod\u00e8le  print(\"\\n--- Testez le mod\u00e8le vous-m\u00eame ---\")  def test_model(digit_idx):     if digit_idx &lt; len(X_test):         # Afficher l'image         img = X_test[digit_idx].reshape(28, 28)         plt.figure(figsize=(6, 6))         plt.imshow(img, cmap='gray')         plt.title(f\"Chiffre \u00e0 classifier\")         plt.axis('off')         plt.show()                  # Faire la pr\u00e9diction         features = feature_pipeline.transform([X_test[digit_idx]])         prediction = rf_model.predict(features)[0]         real_label = y_test[digit_idx]                  print(f\"Pr\u00e9diction du mod\u00e8le Random Forest: {prediction}\")         print(f\"\u00c9tiquette r\u00e9elle: {real_label}\")         print(f\"Pr\u00e9diction {'correcte' if prediction == real_label else 'incorrecte'}\")     else:         print(\"Index hors limites!\")  # Cr\u00e9er un slider pour s\u00e9lectionner un chiffre \u00e0 tester digit_selector = widgets.IntSlider(     value=0,     min=0,     max=len(X_test)-1,     step=1,     description='Index:',     continuous_update=False )  # Bouton pour ex\u00e9cuter le test test_button = widgets.Button(description=\"Tester\") output = widgets.Output()  def on_button_clicked(b):     with output:         output.clear_output()         test_model(digit_selector.value)  test_button.on_click(on_button_clicked)  # Afficher les widgets display(widgets.HBox([digit_selector, test_button])) display(output)  print(\"Utilisez le slider pour s\u00e9lectionner un index et cliquez sur 'Tester' pour classifier le chiffre correspondant.\")"},{"location":"seance1/partie2-decouverte-concepts/math-simplified-nn/","title":"Les bases du Deep Learning : une approche simplifi\u00e9e","text":""},{"location":"seance1/partie2-decouverte-concepts/math-simplified-nn/#introduction","title":"Introduction","text":"<p>Ce document pr\u00e9sente les concepts fondamentaux du Deep Learning de mani\u00e8re accessible, sans les math\u00e9matiques complexes. Notre objectif est de vous donner une compr\u00e9hension intuitive du fonctionnement des r\u00e9seaux de neurones.</p>"},{"location":"seance1/partie2-decouverte-concepts/math-simplified-nn/#1-le-neurone-artificiel-comprendre-la-brique-de-base","title":"1. Le neurone artificiel : comprendre la brique de base","text":""},{"location":"seance1/partie2-decouverte-concepts/math-simplified-nn/#comment-fonctionne-un-neurone-artificiel","title":"Comment fonctionne un neurone artificiel ?","text":"<p>Un neurone artificiel s'inspire du fonctionnement des neurones biologiques. Il combine plusieurs informations d'entr\u00e9e pour produire une d\u00e9cision.</p> <p></p> <p>Fonctionnement en 5 \u00e9tapes :</p> <ol> <li>Recevoir des entr\u00e9es : Le neurone re\u00e7oit plusieurs valeurs (comme la taille et le poids d'un fruit)</li> <li>Pond\u00e9rer ces entr\u00e9es : Certaines entr\u00e9es sont plus importantes que d'autres (le poids peut \u00eatre plus d\u00e9terminant que la taille)</li> <li>Faire la somme : Additionner toutes ces valeurs pond\u00e9r\u00e9es</li> <li>Ajouter un d\u00e9calage (biais) : Ajuster le seuil de d\u00e9cision</li> <li>Appliquer une fonction d'activation : Transformer cette somme en une sortie utile</li> </ol> <p>Analogie : Si vous d\u00e9cidez d'acheter un t\u00e9l\u00e9phone, vous consid\u00e9rez plusieurs facteurs (prix, performances, appareil photo) avec diff\u00e9rentes importances. Vous additionnez mentalement ces consid\u00e9rations, puis prenez une d\u00e9cision (acheter ou non).</p>"},{"location":"seance1/partie2-decouverte-concepts/math-simplified-nn/#la-fonction-dactivation-le-pouvoir-de-decision","title":"La fonction d'activation : le pouvoir de d\u00e9cision","text":"<p>La fonction d'activation est comme un interrupteur qui d\u00e9termine si le neurone \"s'active\" ou non.</p> <p>Types principaux :</p> <ol> <li>ReLU (Rectified Linear Unit) : </li> <li>Simple : si le nombre est n\u00e9gatif, il devient 0; sinon, il reste inchang\u00e9</li> <li> <p>Comme un interrupteur qui ne laisse passer que les valeurs positives</p> </li> <li> <p>Sigmoid : </p> </li> <li>Transforme n'importe quel nombre en une valeur entre 0 et 1</li> <li>Pratique pour exprimer des probabilit\u00e9s (ex: probabilit\u00e9 que l'image contienne un chat)</li> </ol> <p>Visualisation :</p> <p></p>"},{"location":"seance1/partie2-decouverte-concepts/math-simplified-nn/#2-le-reseau-de-neurones-une-equipe-organisee","title":"2. Le r\u00e9seau de neurones : une \u00e9quipe organis\u00e9e","text":"<p>Un r\u00e9seau de neurones est simplement une organisation de neurones en couches qui travaillent ensemble.</p>"},{"location":"seance1/partie2-decouverte-concepts/math-simplified-nn/#organisation-en-couches","title":"Organisation en couches","text":"<ul> <li>Couche d'entr\u00e9e : Re\u00e7oit les donn\u00e9es brutes (pixels d'une image, mots d'un texte...)</li> <li>Couches cach\u00e9es : Traitent l'information de fa\u00e7on de plus en plus abstraite</li> <li>Couche de sortie : Donne le r\u00e9sultat final (classification, pr\u00e9diction...)</li> </ul> <p>Analogie : Dans une entreprise, les informations passent par plusieurs services avant d'aboutir \u00e0 une d\u00e9cision finale. Chaque service (couche) traite l'information \u00e0 son niveau.</p>"},{"location":"seance1/partie2-decouverte-concepts/math-simplified-nn/#comment-linformation-circule","title":"Comment l'information circule","text":"<ol> <li>Les donn\u00e9es entrent par la premi\u00e8re couche</li> <li>Chaque neurone calcule sa sortie et la transmet aux neurones de la couche suivante</li> <li>L'information se propage ainsi jusqu'\u00e0 la couche de sortie</li> </ol> <p>C'est ce qu'on appelle la propagation avant ou \"forward propagation\".</p>"},{"location":"seance1/partie2-decouverte-concepts/math-simplified-nn/#3-lapprentissage-comment-le-reseau-devient-intelligent","title":"3. L'apprentissage : comment le r\u00e9seau devient intelligent","text":""},{"location":"seance1/partie2-decouverte-concepts/math-simplified-nn/#le-principe-de-base","title":"Le principe de base","text":"<p>L'apprentissage d'un r\u00e9seau de neurones se r\u00e9sume \u00e0 : 1. Faire des pr\u00e9dictions 2. Mesurer les erreurs 3. Ajuster les poids pour r\u00e9duire ces erreurs 4. Recommencer</p> <p></p>"},{"location":"seance1/partie2-decouverte-concepts/math-simplified-nn/#mesurer-lerreur","title":"Mesurer l'erreur","text":"<p>Pour savoir si le r\u00e9seau fait bien son travail, on calcule la diff\u00e9rence entre : - Ce que le r\u00e9seau pr\u00e9dit - Ce qu'il aurait d\u00fb pr\u00e9dire (la v\u00e9rit\u00e9)</p> <p>Plus cette diff\u00e9rence est petite, meilleur est le r\u00e9seau.</p> <p>Exemple : Si le r\u00e9seau pr\u00e9dit qu'une image a 80% de chances de contenir un chat alors qu'il y a effectivement un chat, l'erreur est de 20%.</p>"},{"location":"seance1/partie2-decouverte-concepts/math-simplified-nn/#lajustement-des-poids-la-descente-de-gradient","title":"L'ajustement des poids : la descente de gradient","text":"<p>Pour am\u00e9liorer le r\u00e9seau, on ajuste les poids dans la bonne direction :</p> <ol> <li>On d\u00e9termine si chaque poids doit \u00eatre augment\u00e9 ou diminu\u00e9</li> <li>On modifie chaque poids d'un petit pas dans la bonne direction</li> <li>On v\u00e9rifie si la pr\u00e9diction s'am\u00e9liore</li> </ol> <p>Analogie : Imaginez que vous \u00eates dans le brouillard en montagne et que vous voulez descendre. Vous t\u00e2tez le terrain autour de vous pour sentir o\u00f9 \u00e7a descend, puis vous faites un pas dans cette direction. Vous r\u00e9p\u00e9tez jusqu'\u00e0 atteindre le fond de la vall\u00e9e.</p> <p></p>"},{"location":"seance1/partie2-decouverte-concepts/math-simplified-nn/#retropropagation-distribuer-la-responsabilite","title":"R\u00e9tropropagation : distribuer la responsabilit\u00e9","text":"<p>Quand le r\u00e9seau fait une erreur, comment savoir quels poids ajuster ? La r\u00e9tropropagation consiste \u00e0 :</p> <ol> <li>Calculer l'erreur \u00e0 la sortie</li> <li>\"Remonter\" cette erreur dans le r\u00e9seau</li> <li>D\u00e9terminer la contribution de chaque connexion \u00e0 l'erreur totale</li> <li>Ajuster chaque poids en cons\u00e9quence</li> </ol> <p>Analogie : Dans une \u00e9quipe qui a commis une erreur, on analyse la responsabilit\u00e9 de chaque membre pour savoir qui doit ajuster son comportement et comment.</p>"},{"location":"seance1/partie2-decouverte-concepts/math-simplified-nn/#4-les-architectures-populaires-simplifiees","title":"4. Les architectures populaires simplifi\u00e9es","text":""},{"location":"seance1/partie2-decouverte-concepts/math-simplified-nn/#les-reseaux-convolutifs-cnn-pour-les-images","title":"Les r\u00e9seaux convolutifs (CNN) pour les images","text":"<p>Les CNN sont sp\u00e9cialement con\u00e7us pour traiter des images :</p> <p></p> <ul> <li>Ils utilisent des \"filtres\" qui balayent l'image pour d\u00e9tecter des motifs</li> <li>Les premi\u00e8res couches d\u00e9tectent des \u00e9l\u00e9ments simples (lignes, coins)</li> <li>Les couches suivantes combinent ces \u00e9l\u00e9ments pour reconna\u00eetre des formes plus complexes (yeux, visages, objets)</li> </ul> <p>Analogie : C'est comme si vous regardiez une image avec diff\u00e9rentes loupes, chacune sp\u00e9cialis\u00e9e pour rep\u00e9rer un certain type de d\u00e9tail.</p>"},{"location":"seance1/partie2-decouverte-concepts/math-simplified-nn/#les-reseaux-recurrents-rnn-pour-les-sequences","title":"Les r\u00e9seaux r\u00e9currents (RNN) pour les s\u00e9quences","text":"<p>Les RNN sont adapt\u00e9s aux donn\u00e9es s\u00e9quentielles (texte, parole, vid\u00e9o) :</p> <p></p> <ul> <li>Ils ont une \"m\u00e9moire\" qui conserve les informations importantes des \u00e9tapes pr\u00e9c\u00e9dentes</li> <li>Cette m\u00e9moire permet de comprendre le contexte (comme le sens d'un mot en fonction des mots pr\u00e9c\u00e9dents)</li> </ul> <p>Analogie : C'est comme lire un livre en se souvenant des chapitres pr\u00e9c\u00e9dents pour comprendre le chapitre actuel.</p>"},{"location":"seance1/partie2-decouverte-concepts/math-simplified-nn/#5-astuces-pour-ameliorer-les-reseaux","title":"5. Astuces pour am\u00e9liorer les r\u00e9seaux","text":""},{"location":"seance1/partie2-decouverte-concepts/math-simplified-nn/#la-regularisation-eviter-le-par-cur","title":"La r\u00e9gularisation : \u00e9viter le \"par c\u0153ur\"","text":"<p>Parfois, un r\u00e9seau apprend trop bien les exemples d'entra\u00eenement mais ne g\u00e9n\u00e9ralise pas aux nouveaux cas. C'est le surapprentissage.</p> <p>La r\u00e9gularisation est comme imposer des contraintes au r\u00e9seau pour l'emp\u00eacher de trop se sp\u00e9cialiser :</p> <ul> <li>Dropout : D\u00e9sactiver al\u00e9atoirement certains neurones pendant l'entra\u00eenement</li> <li>L1/L2 : P\u00e9naliser les poids trop grands</li> </ul> <p>Analogie : C'est comme \u00e9tudier pour un examen en variant les conditions d'\u00e9tude pour s'assurer de comprendre le concept et pas juste m\u00e9moriser.</p>"},{"location":"seance1/partie2-decouverte-concepts/math-simplified-nn/#le-taux-dapprentissage-la-taille-des-pas","title":"Le taux d'apprentissage : la taille des pas","text":"<p>Le taux d'apprentissage d\u00e9termine l'ampleur des ajustements \u00e0 chaque \u00e9tape : - Trop grand : on risque de \"sauter\" par-dessus la solution - Trop petit : l'apprentissage est tr\u00e8s lent</p> <p></p> <p>Analogie : C'est comme r\u00e9gler la sensibilit\u00e9 du volant d'une voiture - trop sensible et vous zigzaguez, pas assez et vous tournez trop lentement.</p>"},{"location":"seance1/partie2-decouverte-concepts/math-simplified-nn/#conclusion","title":"Conclusion","text":"<p>Vous avez maintenant une compr\u00e9hension intuitive des concepts fondamentaux du Deep Learning :</p> <ol> <li>Les neurones artificiels combinent et transforment les informations</li> <li>Les r\u00e9seaux organisent ces neurones en couches pour traiter l'information progressivement</li> <li>L'apprentissage consiste \u00e0 ajuster les poids pour minimiser les erreurs</li> <li>Diff\u00e9rentes architectures sont sp\u00e9cialis\u00e9es pour diff\u00e9rents types de donn\u00e9es</li> <li>Des techniques sp\u00e9cifiques permettent d'am\u00e9liorer les performances</li> </ol> <p>Cette approche simplifi\u00e9e vous donne les bases n\u00e9cessaires pour comprendre les discussions sur le Deep Learning et pour explorer plus en profondeur si vous le souhaitez.</p>"},{"location":"seance1/partie2-decouverte-concepts/math-simplified-nn/#pour-aller-plus-loin","title":"Pour aller plus loin","text":"<p>Si ces concepts vous int\u00e9ressent, vous pouvez explorer : - TensorFlow Playground - Visualiser et exp\u00e9rimenter avec des r\u00e9seaux de neurones simples - 3Blue1Brown - Neural Networks - S\u00e9rie de vid\u00e9os avec d'excellentes visualisations - Machine Learning for Beginners - Cours de Microsoft avec approche pratique</p> <p>Retour aux ressources</p>"},{"location":"seance1/partie2-decouverte-concepts/partie2-decouverte-concepts/","title":"Phase 2 : D\u00e9couverte des concepts par l'exp\u00e9rimentation (1h30)","text":""},{"location":"seance1/partie2-decouverte-concepts/partie2-decouverte-concepts/#objectifs-de-la-phase","title":"Objectifs de la phase","text":"<p>Dans cette phase, vous allez : - Comparer exp\u00e9rimentalement le Machine Learning classique et le Deep Learning - Observer les diff\u00e9rences fondamentales en termes de pr\u00e9paration des donn\u00e9es et de performances - D\u00e9couvrir l'anatomie d'un r\u00e9seau de neurones en manipulant directement ses composants - Comprendre par la pratique comment l'information circule dans un r\u00e9seau de neurones</p>"},{"location":"seance1/partie2-decouverte-concepts/partie2-decouverte-concepts/#atelier-pratique-boite-noire-machine-learning-vs-deep-learning-45-min","title":"Atelier pratique \"Bo\u00eete noire\" : Machine Learning vs Deep Learning (45 min)","text":""},{"location":"seance1/partie2-decouverte-concepts/partie2-decouverte-concepts/#contexte-et-preparation-5-min","title":"Contexte et pr\u00e9paration (5 min)","text":"<p>Nous allons explorer les diff\u00e9rences fondamentales entre le Machine Learning classique et le Deep Learning non pas par la th\u00e9orie, mais en observant leurs comportements sur un m\u00eame jeu de donn\u00e9es.</p> <p>Organisation : - Travaillez en bin\u00f4me - Chaque bin\u00f4me doit explorer en parall\u00e8le les deux notebooks fournis</p> <p>Mat\u00e9riel n\u00e9cessaire : - Compte Google (pour acc\u00e9der \u00e0 Google Colab) - Liens vers deux notebooks compl\u00e9mentaires :   - Notebook A : Classification avec un algorithme classique (Random Forest)   - Notebook B : Classification avec un r\u00e9seau de neurones simple</p> <p>Jeu de donn\u00e9es : MNIST (chiffres manuscrits)</p>"},{"location":"seance1/partie2-decouverte-concepts/partie2-decouverte-concepts/#instructions","title":"Instructions","text":""},{"location":"seance1/partie2-decouverte-concepts/partie2-decouverte-concepts/#etape-1-exploration-parallele-25-min","title":"\u00c9tape 1 : Exploration parall\u00e8le (25 min)","text":"<ol> <li>Ouvrez les deux notebooks (A et B) dans deux onglets s\u00e9par\u00e9s.</li> <li>Ex\u00e9cutez les cellules dans l'ordre indiqu\u00e9 (Ctrl+Enter ou bouton \u25b6\ufe0f).</li> <li>Pour chaque notebook, observez et notez :</li> <li>Comment les donn\u00e9es sont pr\u00e9par\u00e9es</li> <li>Quels param\u00e8tres peuvent \u00eatre ajust\u00e9s</li> <li>Le temps n\u00e9cessaire \u00e0 l'entra\u00eenement</li> <li>Les performances obtenues (pr\u00e9cision, rappel, F1-score)</li> <li>Les types d'erreurs commises par chaque mod\u00e8le</li> <li>Utilisez ce tableau comparatif pour vos notes :</li> </ol> Aspect observ\u00e9 Machine Learning (Random Forest) Deep Learning (R\u00e9seau de neurones) Pr\u00e9paration des donn\u00e9es Param\u00e8tres principaux Temps d'entra\u00eenement Pr\u00e9cision globale Types d'erreurs fr\u00e9quentes"},{"location":"seance1/partie2-decouverte-concepts/partie2-decouverte-concepts/#etape-2-defi-de-generalisation-10-min","title":"\u00c9tape 2 : D\u00e9fi de g\u00e9n\u00e9ralisation (10 min)","text":"<ol> <li>Dans chaque notebook, localisez la section \"D\u00e9fi de g\u00e9n\u00e9ralisation\".</li> <li>Ex\u00e9cutez les cellules qui chargent le nouveau jeu de test.</li> <li>Observez comment chaque mod\u00e8le performe sur ces nouvelles donn\u00e9es.</li> <li>Notez les diff\u00e9rences de performance entre les deux approches.</li> </ol> <p>Questions \u00e0 discuter : * Lequel des mod\u00e8les g\u00e9n\u00e9ralise le mieux aux nouvelles donn\u00e9es ? * Pourquoi pensez-vous qu'il y a cette diff\u00e9rence ? * Quels avantages et inconv\u00e9nients voyez-vous pour chaque approche ?</p>"},{"location":"seance1/partie2-decouverte-concepts/partie2-decouverte-concepts/#etape-3-mise-en-commun-5-min","title":"\u00c9tape 3 : Mise en commun (5 min)","text":"<p>Pr\u00e9parez-vous \u00e0 partager vos observations avec le reste de la classe : * Principales diff\u00e9rences constat\u00e9es * Surprises ou d\u00e9couvertes int\u00e9ressantes * Questions que cette exp\u00e9rimentation a soulev\u00e9es</p> <p>Concepts cl\u00e9s \u00e0 identifier</p> <p>\u00c0 travers cette exp\u00e9rimentation, essayez d'identifier par vous-m\u00eames ces concepts fondamentaux : * Comment les caract\u00e9ristiques (features) sont trait\u00e9es dans chaque approche * Le r\u00f4le de la repr\u00e9sentation des donn\u00e9es * La capacit\u00e9 d'abstraction des diff\u00e9rents mod\u00e8les * Les compromis entre temps d'entra\u00eenement et performance</p> <p>Ressources suppl\u00e9mentaires * Documentation scikit-learn (Random Forest) * Documentation TensorFlow/Keras * Visualisations interactives TensorFlow Playground</p>"},{"location":"seance1/partie2-decouverte-concepts/partie2-decouverte-concepts/#tp-guide-anatomie-dun-reseau-de-neurones-45-min","title":"TP guid\u00e9 : Anatomie d'un r\u00e9seau de neurones (45 min)","text":"<p>Dans cette seconde partie, vous allez plonger au c\u0153ur des r\u00e9seaux de neurones pour comprendre leur fonctionnement interne.</p>"},{"location":"seance1/partie2-decouverte-concepts/partie2-decouverte-concepts/#materiel-et-ressources","title":"Mat\u00e9riel et ressources","text":"<ul> <li>Notebook interactif \"Anatomie d'un r\u00e9seau de neurones\"</li> <li>Sch\u00e9ma \u00e0 compl\u00e9ter pour la synth\u00e8se</li> <li>Fiche r\u00e9capitulative des termes techniques</li> </ul>"},{"location":"seance1/partie2-decouverte-concepts/partie2-decouverte-concepts/#instructions_1","title":"Instructions","text":""},{"location":"seance1/partie2-decouverte-concepts/partie2-decouverte-concepts/#partie-1-exploration-dun-neurone-unique-15-min","title":"Partie 1 : Exploration d'un neurone unique (15 min)","text":"<p>Dans cette partie, vous allez manipuler un neurone artificiel unique pour comprendre son fonctionnement de base.</p> <ol> <li>Ex\u00e9cutez les cellules d'importation des biblioth\u00e8ques et de configuration.</li> <li>Localisez la section \"Neurone unique\" et ex\u00e9cutez la cellule d'initialisation.</li> <li>Exp\u00e9rimentez avec les contr\u00f4les interactifs pour :</li> <li>Modifier les valeurs d'entr\u00e9e (x\u2081, x\u2082)</li> <li>Ajuster les poids (w\u2081, w\u2082)</li> <li>Changer la valeur du biais (b)</li> <li>Observer l'effet sur la sortie du neurone</li> </ol> <p>Questions \u00e0 explorer : * Que se passe-t-il si tous les poids sont \u00e0 z\u00e9ro ? * Comment pouvez-vous configurer le neurone pour qu'il s'active uniquement si les deux entr\u00e9es sont \u00e9lev\u00e9es ? * Quel est l'effet du biais sur le \"seuil\" d'activation ? * Comment la fonction d'activation ReLU transforme-t-elle la sortie ?</p>"},{"location":"seance1/partie2-decouverte-concepts/partie2-decouverte-concepts/#partie-2-de-lunique-au-reseau-15-min","title":"Partie 2 : De l'unique au r\u00e9seau (15 min)","text":"<p>Nous allons maintenant passer \u00e0 un petit r\u00e9seau de neurones pour comprendre comment l'information circule \u00e0 travers les couches.</p> <ol> <li>Localisez la section \"R\u00e9seau simple\" et ex\u00e9cutez les cellules d'initialisation.</li> <li>Explorez le r\u00e9seau compos\u00e9 de :</li> <li>Une couche d'entr\u00e9e (2 neurones)</li> <li>Une couche cach\u00e9e (3 neurones)</li> <li>Une couche de sortie (1 neurone)</li> <li>R\u00e9alisez les exp\u00e9riences suivantes :</li> <li>Observez comment le signal se propage \u00e0 travers les couches</li> <li>Suivez le parcours d'une information sp\u00e9cifique (valeur d'entr\u00e9e)</li> <li>Identifiez les \"motifs d'activation\" qui se forment pour diff\u00e9rentes entr\u00e9es</li> <li>Testez diff\u00e9rentes fonctions d'activation (ReLU, Sigmoid, Tanh)</li> </ol> <p>Exercice pratique : Essayez de configurer manuellement les poids pour que le r\u00e9seau r\u00e9alise la fonction logique XOR (entr\u00e9es : [0,0]\u21920, [0,1]\u21921, [1,0]\u21921, [1,1]\u21920).</p>"},{"location":"seance1/partie2-decouverte-concepts/partie2-decouverte-concepts/#partie-3-visualisation-de-lentrainement-10-min","title":"Partie 3 : Visualisation de l'entra\u00eenement (10 min)","text":"<p>Dans cette partie, vous allez observer comment un r\u00e9seau apprend au fil du temps.</p> <ol> <li>Localisez la section \"Entra\u00eenement\" et ex\u00e9cutez la cellule d'initialisation.</li> <li>Lancez la visualisation de l'entra\u00eenement en temps r\u00e9el.</li> <li>Observez :</li> <li>L'\u00e9volution des poids \u00e0 chaque it\u00e9ration</li> <li>Comment la \"fronti\u00e8re de d\u00e9cision\" se modifie</li> <li>La diminution de l'erreur au fil des \u00e9poques</li> <li>Essayez de modifier :</li> <li>Le taux d'apprentissage (learning rate)</li> <li>La complexit\u00e9 du probl\u00e8me (type de donn\u00e9es)</li> <li>L'architecture du r\u00e9seau (nombre de neurones)</li> </ol>"},{"location":"seance1/partie2-decouverte-concepts/partie2-decouverte-concepts/#partie-4-synthese-et-verbalisation-5-min","title":"Partie 4 : Synth\u00e8se et verbalisation (5 min)","text":"<ol> <li>Compl\u00e9tez le sch\u00e9ma du r\u00e9seau de neurones fourni en fin de notebook.</li> <li>Identifiez et nommez correctement :</li> <li>Les entr\u00e9es et sorties</li> <li>Les poids et biais</li> <li>Les fonctions d'activation</li> <li>Les couches cach\u00e9es</li> <li>R\u00e9digez un court paragraphe (5-7 lignes) expliquant avec vos propres mots :</li> <li>Comment un r\u00e9seau de neurones traite l'information</li> <li>Comment il peut apprendre \u00e0 partir d'exemples</li> </ol>"},{"location":"seance1/partie2-decouverte-concepts/partie2-decouverte-concepts/#points-cles-a-retenir","title":"Points cl\u00e9s \u00e0 retenir","text":"<p>\u00c0 travers cette exploration, vous devriez avoir d\u00e9couvert :</p> <ul> <li>Le r\u00f4le fondamental des poids et biais</li> <li>L'importance des fonctions d'activation pour introduire la non-lin\u00e9arit\u00e9</li> <li>Comment l'information se propage \u00e0 travers un r\u00e9seau (forward propagation)</li> <li>Les bases du processus d'apprentissage (ajustement des poids)</li> </ul>"},{"location":"seance1/partie2-decouverte-concepts/partie2-decouverte-concepts/#ressources-supplementaires","title":"Ressources suppl\u00e9mentaires","text":"<ul> <li>Visualisations interactives : Playground TensorFlow</li> <li>Tutoriel : Comprendre les r\u00e9seaux de neurones</li> <li>Document : Math\u00e9matiques des r\u00e9seaux de neurones simplifi\u00e9es</li> </ul>"},{"location":"seance1/partie2-decouverte-concepts/partie2-decouverte-concepts/#conclusion","title":"Conclusion","text":"<p>Cette phase vous a permis de passer de l'observation pure \u00e0 une compr\u00e9hension plus approfondie des m\u00e9canismes internes du Deep Learning, tout en conservant une approche tr\u00e8s pratique et exp\u00e9rimentale. Les concepts d\u00e9couverts serviront de fondation pour la suite du parcours.</p> <p>Retour \u00e0 la S\u00e9ance 1 Continuer vers la Phase 3</p>"},{"location":"seance1/partie3-mini-projet/partie3-mini-projet/","title":"Phase 3 : Mini-projet collaboratif (1h)","text":""},{"location":"seance1/partie3-mini-projet/partie3-mini-projet/#objectif","title":"Objectif","text":"<p>Mettre en pratique vos connaissances en am\u00e9liorant un mod\u00e8le de Deep Learning existant, tout en d\u00e9veloppant vos comp\u00e9tences en r\u00e9solution de probl\u00e8mes et en travail d'\u00e9quipe.</p>"},{"location":"seance1/partie3-mini-projet/partie3-mini-projet/#challenge-damelioration-dun-modele-1h","title":"Challenge d'am\u00e9lioration d'un mod\u00e8le (1h)","text":""},{"location":"seance1/partie3-mini-projet/partie3-mini-projet/#formation-des-equipes-5-min","title":"Formation des \u00e9quipes (5 min)","text":"<p>Formez des groupes de 1-2 \u00e9tudiants. Chaque groupe recevra un lien vers un notebook contenant un mod\u00e8le de base fonctionnel, mais avec des performances m\u00e9diocres.</p>"},{"location":"seance1/partie3-mini-projet/partie3-mini-projet/#presentation-du-challenge-10-min","title":"Pr\u00e9sentation du challenge (10 min)","text":"<p>Votre mission : am\u00e9liorer la performance du mod\u00e8le de base qui atteint seulement 85% de pr\u00e9cision sur le dataset MNIST.</p>"},{"location":"seance1/partie3-mini-projet/partie3-mini-projet/#regles-du-challenge","title":"R\u00e8gles du challenge","text":"<ul> <li>Vous avez 40 minutes pour am\u00e9liorer le mod\u00e8le</li> <li>Vous pouvez modifier l'architecture, les hyperparam\u00e8tres, la pr\u00e9paration des donn\u00e9es</li> <li>Chaque groupe doit documenter ses modifications et justifier ses choix</li> <li>Le tableau de scores en temps r\u00e9el affichera la pr\u00e9cision de chaque mod\u00e8le</li> </ul>"},{"location":"seance1/partie3-mini-projet/partie3-mini-projet/#modele-de-base","title":"Mod\u00e8le de base","text":"<p>Le notebook contient un mod\u00e8le CNN simple avec : - Une couche de convolution (16 filtres, taille 3x3) - Une couche de max pooling (2x2) - Une couche fully connected (128 neurones) - Une couche de sortie (10 classes)</p>"},{"location":"seance1/partie3-mini-projet/partie3-mini-projet/#travail-en-groupe-35-min","title":"Travail en groupe (35 min)","text":"<ol> <li>Analyse du mod\u00e8le de base</li> <li>Identifiez les points faibles potentiels</li> <li> <p>Faites un plan d'am\u00e9lioration</p> </li> <li> <p>Exp\u00e9rimentation</p> </li> <li>Testez diff\u00e9rentes modifications :<ul> <li>Nombre de couches de convolution</li> <li>Nombre de filtres</li> <li>Taille des filtres</li> <li>Ajout de dropout</li> <li>Modification du learning rate</li> </ul> </li> <li> <p>Documentez chaque essai dans le tableau fourni</p> </li> <li> <p>Optimisation finale</p> </li> <li>S\u00e9lectionnez vos meilleures modifications</li> <li>Combinez-les pour obtenir le meilleur mod\u00e8le possible</li> <li>Assurez-vous de pouvoir expliquer votre approche</li> </ol>"},{"location":"seance1/partie3-mini-projet/partie3-mini-projet/#partage-des-resultats-10-min","title":"Partage des r\u00e9sultats (10 min)","text":"<p>Chaque groupe pr\u00e9sente bri\u00e8vement : - Les modifications apport\u00e9es au mod\u00e8le - L'am\u00e9lioration obtenue - Les difficult\u00e9s rencontr\u00e9es et les solutions trouv\u00e9es</p>"},{"location":"seance1/partie3-mini-projet/partie3-mini-projet/#tableau-de-suivi-des-modifications","title":"Tableau de suivi des modifications","text":"<p>Pour chaque modification test\u00e9e, renseignez les informations suivantes :</p> Modification Description Pr\u00e9cision avant Pr\u00e9cision apr\u00e8s Observations"},{"location":"seance1/partie3-mini-projet/partie3-mini-projet/#ressources-disponibles","title":"Ressources disponibles","text":"<ul> <li>Fiche r\u00e9capitulative des architectures CNN</li> <li>Guide des bonnes pratiques pour l'am\u00e9lioration des mod\u00e8les</li> <li>Documentation TensorFlow/Keras</li> </ul>"},{"location":"seance1/partie3-mini-projet/partie3-mini-projet/#conseils-pour-reussir","title":"Conseils pour r\u00e9ussir","text":"<ul> <li>Commencez par des modifications simples pour \u00e9tablir une base de comparaison</li> <li>N'h\u00e9sitez pas \u00e0 vous inspirer des architectures connues (LeNet, AlexNet, etc.)</li> <li>Faites attention \u00e0 l'overfitting - testez toujours sur l'ensemble de validation</li> <li>Collaborez efficacement en r\u00e9partissant les t\u00e2ches</li> </ul> <p>Continuer vers le d\u00e9brief</p>"},{"location":"seance1/partie4-debrief/partie4-debrief/","title":"Phase 4 : D\u00e9brief et conceptualisation (30 min)","text":""},{"location":"seance1/partie4-debrief/partie4-debrief/#objectif","title":"Objectif","text":"<p>Formaliser les connaissances acquises pendant la session pratique et \u00e9tablir le vocabulaire technique du Deep Learning \u00e0 partir de vos exp\u00e9riences v\u00e9cues.</p>"},{"location":"seance1/partie4-debrief/partie4-debrief/#mise-en-commun-des-decouvertes-20-min","title":"Mise en commun des d\u00e9couvertes (20 min)","text":""},{"location":"seance1/partie4-debrief/partie4-debrief/#presentation-des-resultats-du-mini-projet-10-min","title":"Pr\u00e9sentation des r\u00e9sultats du mini-projet (10 min)","text":"<p>Chaque groupe pr\u00e9sente bri\u00e8vement (2-3 minutes) : - Sa meilleure solution - Les modifications qui ont eu le plus d'impact - Les apprentissages cl\u00e9s tir\u00e9s de leurs exp\u00e9rimentations</p>"},{"location":"seance1/partie4-debrief/partie4-debrief/#construction-collaborative-dune-carte-mentale-10-min","title":"Construction collaborative d'une carte mentale (10 min)","text":"<p>Ensemble, nous allons construire une carte des concepts cl\u00e9s du Deep Learning :</p> <ol> <li>\u00c9l\u00e9ments fondamentaux</li> <li>Neurone artificiel</li> <li>Poids et biais</li> <li>Fonction d'activation</li> <li> <p>Couches de neurones</p> </li> <li> <p>Architecture des r\u00e9seaux</p> </li> <li>R\u00e9seau dense (fully connected)</li> <li>R\u00e9seau convolutif (CNN)</li> <li> <p>R\u00e9seau r\u00e9current (RNN)</p> </li> <li> <p>Processus d'apprentissage</p> </li> <li>Forward propagation</li> <li>Backpropagation</li> <li>Descente de gradient</li> <li> <p>Fonction de perte (loss)</p> </li> <li> <p>Hyperparam\u00e8tres importants</p> </li> <li>Learning rate</li> <li>Nombre d'\u00e9poques</li> <li>Taille des batchs</li> <li>Architecture du r\u00e9seau</li> </ol>"},{"location":"seance1/partie4-debrief/partie4-debrief/#synthese-et-introduction-de-la-terminologie-10-min","title":"Synth\u00e8se et introduction de la terminologie (10 min)","text":""},{"location":"seance1/partie4-debrief/partie4-debrief/#formalisation-des-concepts","title":"Formalisation des concepts","text":"<p>\u00c0 partir des observations empiriques, nous allons formaliser les concepts cl\u00e9s :</p> <ul> <li> <p>D\u00e9finition du Deep Learning : Sous-domaine du Machine Learning utilisant des r\u00e9seaux de neurones \u00e0 plusieurs couches pour apprendre des repr\u00e9sentations hi\u00e9rarchiques des donn\u00e9es.</p> </li> <li> <p>Avantages par rapport au ML classique :</p> </li> <li>Extraction automatique de caract\u00e9ristiques</li> <li>Capacit\u00e9 \u00e0 mod\u00e9liser des relations complexes</li> <li> <p>Adaptabilit\u00e9 \u00e0 divers types de donn\u00e9es (images, texte, son...)</p> </li> <li> <p>Limitations observ\u00e9es :</p> </li> <li>Besoin de grandes quantit\u00e9s de donn\u00e9es</li> <li>Co\u00fbt computationnel \u00e9lev\u00e9</li> <li>\"Bo\u00eete noire\" difficile \u00e0 interpr\u00e9ter</li> </ul>"},{"location":"seance1/partie4-debrief/partie4-debrief/#glossaire-collaboratif","title":"Glossaire collaboratif","text":"<p>Compl\u00e9tez ensemble le glossaire interactif du Deep Learning avec vos propres mots, bas\u00e9s sur votre exp\u00e9rience de la journ\u00e9e.</p>"},{"location":"seance1/partie4-debrief/partie4-debrief/#mise-en-perspective","title":"Mise en perspective","text":""},{"location":"seance1/partie4-debrief/partie4-debrief/#applications-reelles-du-deep-learning","title":"Applications r\u00e9elles du Deep Learning","text":"<ul> <li>Vision par ordinateur : reconnaissance d'objets, d\u00e9tection de visages, conduite autonome</li> <li>Traitement du langage naturel : traduction, r\u00e9sum\u00e9, g\u00e9n\u00e9ration de texte</li> <li>Audio : reconnaissance vocale, g\u00e9n\u00e9ration de musique</li> <li>Sant\u00e9 : diagnostic m\u00e9dical, d\u00e9couverte de m\u00e9dicaments</li> <li>Jeux : AlphaGo, agents RL pour les jeux vid\u00e9o</li> </ul>"},{"location":"seance1/partie4-debrief/partie4-debrief/#preparation-pour-la-prochaine-seance","title":"Pr\u00e9paration pour la prochaine s\u00e9ance","text":"<p>La prochaine fois, nous explorerons plus en d\u00e9tail : - Les diff\u00e9rents types de r\u00e9seaux neuronaux et leurs applications sp\u00e9cifiques - Les techniques d'optimisation pour am\u00e9liorer les performances - L'int\u00e9gration du Deep Learning dans des applications r\u00e9elles</p>"},{"location":"seance1/partie4-debrief/partie4-debrief/#ressources-pour-approfondir","title":"Ressources pour approfondir","text":"<ul> <li>Cours \"Neural Networks and Deep Learning\" sur Coursera</li> <li>TensorFlow Playground</li> <li>Livre \"Deep Learning with Python\" par Fran\u00e7ois Chollet</li> <li>Tutoriels TensorFlow</li> </ul>"},{"location":"seance1/partie4-debrief/partie4-debrief/#conclusion","title":"Conclusion","text":"<p>Aujourd'hui, vous avez : - D\u00e9couvert le Deep Learning par la pratique - Compar\u00e9 le ML classique et le Deep Learning - Explor\u00e9 le fonctionnement interne des r\u00e9seaux de neurones - Am\u00e9lior\u00e9 un mod\u00e8le r\u00e9el en \u00e9quipe</p> <p>Ces bases vous permettront d'aborder la prochaine s\u00e9ance avec une compr\u00e9hension solide des concepts fondamentaux.</p> <p>Retour \u00e0 l'accueil</p>"},{"location":"seance1/ressources/comparaison-ml-dl/","title":"Comparaison Machine Learning vs Deep Learning","text":""},{"location":"seance1/ressources/comparaison-ml-dl/#tableau-comparatif-detaille","title":"Tableau Comparatif D\u00e9taill\u00e9","text":"Crit\u00e8re Machine Learning Classique Deep Learning D\u00e9finition Algorithmes qui apprennent \u00e0 partir de donn\u00e9es en identifiant des patterns pr\u00e9d\u00e9finis Sous-ensemble du Machine Learning bas\u00e9 sur des r\u00e9seaux de neurones artificiels multicouches Extraction des caract\u00e9ristiques N\u00e9cessite un travail manuel d'ing\u00e9nierie des caract\u00e9ristiques (feature engineering) Capacit\u00e9 \u00e0 extraire automatiquement les caract\u00e9ristiques pertinentes Volume de donn\u00e9es requis Fonctionne bien avec des petits \u00e0 moyens ensembles de donn\u00e9es Performant avec de tr\u00e8s grands volumes de donn\u00e9es Puissance de calcul Peut fonctionner sur des ordinateurs standard N\u00e9cessite g\u00e9n\u00e9ralement des GPU ou des ressources de calcul puissantes Types de probl\u00e8mes Classification, r\u00e9gression, clustering simples Probl\u00e8mes complexes : reconnaissance d'image, traitement du langage naturel, g\u00e9n\u00e9ration de contenu Interpr\u00e9tabilit\u00e9 Souvent plus facile \u00e0 interpr\u00e9ter Plus difficile \u00e0 comprendre (bo\u00eete noire) Complexit\u00e9 d'impl\u00e9mentation Plus simple \u00e0 mettre en place Plus complexe, n\u00e9cessite une expertise plus pointe"},{"location":"seance1/ressources/comparaison-ml-dl/#exemple-pratique-de-difference","title":"Exemple Pratique de Diff\u00e9rence","text":""},{"location":"seance1/ressources/comparaison-ml-dl/#machine-learning-classique-random-forest","title":"Machine Learning Classique (Random Forest)","text":"<ul> <li>Processus :</li> <li>Extraction manuelle des caract\u00e9ristiques</li> <li>S\u00e9lection des attributs pertinents</li> <li>Entra\u00eenement sur des donn\u00e9es pr\u00e9par\u00e9es</li> <li>Forces :</li> <li>Interpr\u00e9tabilit\u00e9</li> <li>Efficacit\u00e9 sur des donn\u00e9es structur\u00e9es</li> <li>Limites :</li> <li>Performance limit\u00e9e sur des donn\u00e9es complexes</li> <li>N\u00e9cessite une expertise en feature engineering</li> </ul>"},{"location":"seance1/ressources/comparaison-ml-dl/#deep-learning-reseau-de-neurones","title":"Deep Learning (R\u00e9seau de Neurones)","text":"<ul> <li>Processus :</li> <li>Alimentation directe des donn\u00e9es brutes</li> <li>Extraction automatique des caract\u00e9ristiques</li> <li>Apprentissage multicouche</li> <li>Forces :</li> <li>Apprentissage automatique des caract\u00e9ristiques</li> <li>Haute performance sur des donn\u00e9es non structur\u00e9es</li> <li>Capacit\u00e9 \u00e0 g\u00e9rer des probl\u00e8mes complexes</li> <li>Limites :</li> <li>Besoin de grandes quantit\u00e9s de donn\u00e9es</li> <li>Ressources de calcul importantes</li> <li>Moins interpr\u00e9table</li> </ul>"},{"location":"seance1/ressources/comparaison-ml-dl/#analogie-explicative","title":"Analogie Explicative","text":"<p>\ud83e\udde9 Machine Learning Classique : Comme un puzzle o\u00f9 vous devez trier et placer manuellement chaque pi\u00e8ce.</p> <p>\ud83e\udde0 Deep Learning : Comme un cerveau qui apprend \u00e0 reconna\u00eetre le puzzle automatiquement, en comprenant les relations entre les pi\u00e8ces.</p>"},{"location":"seance1/ressources/comparaison-ml-dl/#quand-utiliser-quoi","title":"Quand Utiliser Quoi ?","text":""},{"location":"seance1/ressources/comparaison-ml-dl/#machine-learning-classique","title":"Machine Learning Classique","text":"<ul> <li>Donn\u00e9es structur\u00e9es limit\u00e9es</li> <li>Probl\u00e8mes simples de pr\u00e9diction</li> <li>Besoin d'interpr\u00e9tabilit\u00e9</li> <li>Ressources de calcul limit\u00e9es</li> </ul>"},{"location":"seance1/ressources/comparaison-ml-dl/#deep-learning","title":"Deep Learning","text":"<ul> <li>Grandes quantit\u00e9s de donn\u00e9es</li> <li>Probl\u00e8mes complexes (image, son, texte)</li> <li>N\u00e9cessit\u00e9 de features avanc\u00e9es</li> <li>Ressources de calcul disponibles</li> </ul>"},{"location":"seance1/ressources/comparaison-ml-dl/#exercice-pratique","title":"Exercice Pratique","text":"<p>Durant la s\u00e9ance, vous allez : 1. Impl\u00e9menter un mod\u00e8le de Machine Learning classique 2. Cr\u00e9er un r\u00e9seau de neurones simple 3. Comparer leurs performances 4. Comprendre les diff\u00e9rences concr\u00e8tes</p>"},{"location":"seance1/ressources/comparaison-ml-dl/#ressources-complementaires","title":"Ressources Compl\u00e9mentaires","text":"<ul> <li>\ud83d\udcd8 Livres recommand\u00e9s</li> <li>\ud83c\udf10 Liens vers des tutoriels</li> <li>\ud83d\udcf9 Vid\u00e9os explicatives</li> </ul>"},{"location":"seance1/ressources/comparaison-ml-dl/#reflexion-personnelle","title":"R\u00e9flexion Personnelle","text":"<p>Prenez des notes sur : - Les diff\u00e9rences que vous observez - Les surprises lors de votre exp\u00e9rimentation - Les questions qui \u00e9mergent</p> <p>Objectif : D\u00e9velopper une compr\u00e9hension intuitive, pas seulement technique !</p>"},{"location":"seance1/ressources/fiche-observations/","title":"Fiche d'Observations : Hello World du Deep Learning","text":""},{"location":"seance1/ressources/fiche-observations/#informations-personnelles","title":"Informations Personnelles","text":"<ul> <li>Nom : ________</li> <li>Pr\u00e9nom : ________</li> <li>Groupe : ________</li> <li>Date : ________</li> </ul>"},{"location":"seance1/ressources/fiche-observations/#partie-1-exploration-du-modele","title":"Partie 1 : Exploration du Mod\u00e8le","text":""},{"location":"seance1/ressources/fiche-observations/#configuration-initiale","title":"Configuration Initiale","text":"<ul> <li>Biblioth\u00e8ques utilis\u00e9es :   \u25a1 NumPy   \u25a1 Matplotlib   \u25a1 TensorFlow   \u25a1 Keras</li> </ul>"},{"location":"seance1/ressources/fiche-observations/#jeu-de-donnees-mnist","title":"Jeu de Donn\u00e9es MNIST","text":"<ul> <li>Nombre total d'images d'entra\u00eenement : ______</li> <li>Nombre total d'images de test : ______</li> <li>Taille des images : __ x ____</li> </ul>"},{"location":"seance1/ressources/fiche-observations/#partie-2-architecture-du-reseau-de-neurones","title":"Partie 2 : Architecture du R\u00e9seau de Neurones","text":""},{"location":"seance1/ressources/fiche-observations/#structure-du-modele","title":"Structure du Mod\u00e8le","text":"<p>Notez les couches et leurs caract\u00e9ristiques :</p> <ol> <li>Couche 1 (Convolution) :</li> <li>Nombre de filtres : _</li> <li>Taille des filtres : _ </li> <li> <p>Fonction d'activation : _</p> </li> <li> <p>Couche de Pooling :</p> </li> <li>Type : _</li> <li> <p>Taille : _</p> </li> <li> <p>Couches Denses :</p> </li> <li>Nombre de neurones (1\u00e8re couche dense) : _</li> <li>Fonction d'activation (1\u00e8re couche dense) : _</li> <li>Nombre de neurones (couche de sortie) : _</li> <li>Fonction d'activation (couche de sortie) : _</li> </ol>"},{"location":"seance1/ressources/fiche-observations/#partie-3-entrainement-du-modele","title":"Partie 3 : Entra\u00eenement du Mod\u00e8le","text":""},{"location":"seance1/ressources/fiche-observations/#parametres-dentrainement","title":"Param\u00e8tres d'Entra\u00eenement","text":"<ul> <li>Nombre d'\u00e9poques : _</li> <li>Taille du batch : _</li> <li>Optimiseur : _</li> <li>Fonction de perte : _</li> </ul>"},{"location":"seance1/ressources/fiche-observations/#metriques-de-performance","title":"M\u00e9triques de Performance","text":"M\u00e9trique Entra\u00eenement Validation Pr\u00e9cision ______ ______ Perte ______ ______"},{"location":"seance1/ressources/fiche-observations/#partie-4-observations-et-reflexions","title":"Partie 4 : Observations et R\u00e9flexions","text":""},{"location":"seance1/ressources/fiche-observations/#evolution-de-lapprentissage","title":"\u00c9volution de l'Apprentissage","text":"<p>D\u00e9crivez ce que vous observez dans les graphiques de pr\u00e9cision et de perte :</p>"},{"location":"seance1/ressources/fiche-observations/#predictions","title":"Pr\u00e9dictions","text":"<p>Notez quelques exemples de pr\u00e9dictions correctes et incorrectes :</p> <p>Pr\u00e9dictions correctes : 1. ____ 2. ______</p> <p>Pr\u00e9dictions incorrectes : 1. ____ 2. ______</p>"},{"location":"seance1/ressources/fiche-observations/#partie-5-experimentation-personnelle","title":"Partie 5 : Exp\u00e9rimentation Personnelle","text":""},{"location":"seance1/ressources/fiche-observations/#modifications-testees","title":"Modifications Test\u00e9es","text":"<p>Indiquez les modifications que vous avez apport\u00e9es et leurs effets :</p> <ol> <li> <p>Modification : ____    Effet observ\u00e9 : ______</p> </li> <li> <p>Modification : ____    Effet observ\u00e9 : ______</p> </li> </ol>"},{"location":"seance1/ressources/fiche-observations/#reflexion-finale","title":"R\u00e9flexion Finale","text":"<p>Quels sont les trois concepts cl\u00e9s que vous avez appris aujourd'hui ? 1. ____ 2. ___ 3. _____</p>"},{"location":"seance1/ressources/fiche-observations/#questions-ouvertes","title":"Questions Ouvertes","text":"<p>Quelles questions restent sans r\u00e9ponse pour vous apr\u00e8s cette s\u00e9ance ?</p>"},{"location":"seance1/ressources/fiche-observations/#evaluation-personnelle","title":"\u00c9valuation Personnelle","text":"<p>Sur une \u00e9chelle de 1 \u00e0 5, \u00e9valuez votre compr\u00e9hension : - Fonctionnement de base d'un r\u00e9seau de neurones : [  ] - Impact des param\u00e8tres sur l'apprentissage : [  ] - Processus de reconnaissance d'images : [  ]</p> <p>1 = Tr\u00e8s faible, 5 = Excellent</p>"},{"location":"seance1/ressources/fiche-observations/#commentaires-supplementaires","title":"Commentaires Suppl\u00e9mentaires","text":"<p>Merci d'avoir particip\u00e9 \u00e0 cette premi\u00e8re exploration du Deep Learning !</p>"},{"location":"seance1/ressources/glossaire-dl/","title":"Glossaire du Deep Learning","text":""},{"location":"seance1/ressources/glossaire-dl/#termes-fondamentaux","title":"Termes fondamentaux","text":"Terme D\u00e9finition Exemple concret Deep Learning Sous-domaine du Machine Learning utilisant des r\u00e9seaux de neurones \u00e0 plusieurs couches Reconnaissance d'objets dans des photos R\u00e9seau de neurones Syst\u00e8me inspir\u00e9 du cerveau humain compos\u00e9 de n\u0153uds (neurones) interconnect\u00e9s R\u00e9seau capable de reconna\u00eetre des chiffres manuscrits Neurone artificiel Unit\u00e9 de calcul de base qui re\u00e7oit des entr\u00e9es, applique une transformation et produit une sortie Un neurone qui s'active quand il d\u00e9tecte un contour vertical Couche Ensemble de neurones situ\u00e9s au m\u00eame niveau dans le r\u00e9seau Couche d'entr\u00e9e, couche cach\u00e9e, couche de sortie Poids Valeurs num\u00e9riques qui d\u00e9finissent l'importance relative de chaque connexion Un poids \u00e9lev\u00e9 (ex: 0.8) indique une forte influence Biais Valeur ajout\u00e9e \u00e0 la somme pond\u00e9r\u00e9e pour ajuster le seuil d'activation Permet \u00e0 un neurone de s'activer m\u00eame si toutes les entr\u00e9es sont nulles Fonction d'activation Fonction math\u00e9matique qui d\u00e9termine la sortie d'un neurone ReLU, Sigmoid, Tanh"},{"location":"seance1/ressources/glossaire-dl/#architectures-de-reseaux","title":"Architectures de r\u00e9seaux","text":"Terme D\u00e9finition Cas d'utilisation R\u00e9seau dense R\u00e9seau o\u00f9 chaque neurone est connect\u00e9 \u00e0 tous les neurones de la couche pr\u00e9c\u00e9dente Classification d'images simples, pr\u00e9diction de valeurs R\u00e9seau convolutif (CNN) R\u00e9seau sp\u00e9cialis\u00e9 dans le traitement des donn\u00e9es en grille comme les images Reconnaissance d'objets, classification d'images R\u00e9seau r\u00e9current (RNN) R\u00e9seau avec des connexions formant des cycles, adapt\u00e9 aux donn\u00e9es s\u00e9quentielles Traduction automatique, g\u00e9n\u00e9ration de texte LSTM/GRU Types de RNN capables de m\u00e9moriser l'information sur de longues s\u00e9quences Analyse de texte long, pr\u00e9diction de s\u00e9ries temporelles"},{"location":"seance1/ressources/glossaire-dl/#apprentissage","title":"Apprentissage","text":"Terme D\u00e9finition Exemple Forward propagation Passage des donn\u00e9es d'entr\u00e9e \u00e0 travers le r\u00e9seau pour produire une pr\u00e9diction Calcul de la sortie d'un mod\u00e8le pour une image d'entr\u00e9e Loss (perte) Mesure de l'\u00e9cart entre les pr\u00e9dictions et les valeurs r\u00e9elles Erreur quadratique moyenne, entropie crois\u00e9e Backpropagation Algorithme qui calcule le gradient de l'erreur par rapport aux poids Calcul de la contribution de chaque poids \u00e0 l'erreur totale Descente de gradient Algorithme d'optimisation qui ajuste les poids pour minimiser l'erreur Modification it\u00e9rative des poids dans la direction du gradient n\u00e9gatif \u00c9poque Un passage complet \u00e0 travers l'ensemble des donn\u00e9es d'entra\u00eenement Entra\u00eener un mod\u00e8le pendant 10 \u00e9poques Batch Sous-ensemble des donn\u00e9es trait\u00e9 avant une mise \u00e0 jour des poids Traiter les donn\u00e9es par lots de 32 exemples"},{"location":"seance1/ressources/glossaire-dl/#hyperparametres-et-optimisation","title":"Hyperparam\u00e8tres et optimisation","text":"Terme D\u00e9finition Impact Learning rate Taux qui contr\u00f4le l'ampleur des ajustements des poids Trop \u00e9lev\u00e9: divergence, trop faible: apprentissage lent Dropout Technique o\u00f9 des neurones sont al\u00e9atoirement d\u00e9sactiv\u00e9s pendant l'entra\u00eenement R\u00e9duit l'overfitting en for\u00e7ant le r\u00e9seau \u00e0 \u00eatre redondant Batch normalization Normalisation des activations d'une couche pour stabiliser l'apprentissage Acc\u00e9l\u00e8re l'entra\u00eenement et am\u00e9liore la convergence Early stopping Arr\u00eat de l'entra\u00eenement quand les performances sur la validation cessent de s'am\u00e9liorer \u00c9vite l'overfitting en emp\u00eachant le surajustement aux donn\u00e9es d'entra\u00eenement"},{"location":"seance1/ressources/glossaire-dl/#problemes-courants","title":"Probl\u00e8mes courants","text":"Terme D\u00e9finition Solution possible Overfitting Le mod\u00e8le apprend trop bien les donn\u00e9es d'entra\u00eenement au d\u00e9triment de la g\u00e9n\u00e9ralisation R\u00e9gularisation, dropout, plus de donn\u00e9es Underfitting Le mod\u00e8le est trop simple pour capturer la complexit\u00e9 des donn\u00e9es Augmenter la complexit\u00e9 du mod\u00e8le, entra\u00eener plus longtemps Vanishing gradient Probl\u00e8me o\u00f9 le gradient devient tr\u00e8s petit, ralentissant l'apprentissage Utiliser ReLU, LSTM, initialisation des poids adapt\u00e9e Exploding gradient Probl\u00e8me o\u00f9 le gradient devient tr\u00e8s grand, d\u00e9stabilisant l'apprentissage Gradient clipping, normalisation des poids"},{"location":"seance1/ressources/qcm-evaluation/","title":"QCM d'\u00e9valuation - Introduction au Deep Learning","text":"<p>Ce QCM vous permettra d'\u00e9valuer votre compr\u00e9hension des concepts fondamentaux du Deep Learning vus durant cette premi\u00e8re s\u00e9ance.</p>"},{"location":"seance1/ressources/qcm-evaluation/#instructions","title":"Instructions","text":"<ul> <li>Cochez la ou les r\u00e9ponses correctes pour chaque question</li> <li>Certaines questions peuvent avoir plusieurs r\u00e9ponses correctes</li> <li>Dur\u00e9e recommand\u00e9e : 10 minutes</li> </ul>"},{"location":"seance1/ressources/qcm-evaluation/#questions","title":"Questions","text":""},{"location":"seance1/ressources/qcm-evaluation/#1-quest-ce-qui-differencie-principalement-le-deep-learning-du-machine-learning-classique","title":"1. Qu'est-ce qui diff\u00e9rencie principalement le Deep Learning du Machine Learning classique ?","text":"<ul> <li> Le Deep Learning est plus rapide \u00e0 entra\u00eener</li> <li> Le Deep Learning utilise toujours du mat\u00e9riel sp\u00e9cialis\u00e9 (GPU)</li> <li> Le Deep Learning extrait automatiquement les caract\u00e9ristiques pertinentes des donn\u00e9es</li> <li> Le Deep Learning fonctionne uniquement sur des images</li> </ul>"},{"location":"seance1/ressources/qcm-evaluation/#2-quels-sont-les-composants-fondamentaux-dun-reseau-de-neurones-plusieurs-reponses-possibles","title":"2. Quels sont les composants fondamentaux d'un r\u00e9seau de neurones ? (plusieurs r\u00e9ponses possibles)","text":"<ul> <li> Neurones</li> <li> Poids</li> <li> Biais</li> <li> Algorithmes de tri</li> <li> Fonctions d'activation</li> </ul>"},{"location":"seance1/ressources/qcm-evaluation/#3-quelle-est-la-principale-fonction-du-processus-de-forward-propagation","title":"3. Quelle est la principale fonction du processus de \"forward propagation\" ?","text":"<ul> <li> Ajuster les poids du r\u00e9seau</li> <li> Calculer l'erreur entre les pr\u00e9dictions et les valeurs r\u00e9elles</li> <li> Propager les entr\u00e9es \u00e0 travers le r\u00e9seau pour produire une sortie</li> <li> R\u00e9duire la taille du r\u00e9seau</li> </ul>"},{"location":"seance1/ressources/qcm-evaluation/#4-quest-ce-quune-epoque-dentrainement","title":"4. Qu'est-ce qu'une \u00e9poque d'entra\u00eenement ?","text":"<ul> <li> Une m\u00e9thode d'initialisation des poids</li> <li> Un passage complet \u00e0 travers l'ensemble des donn\u00e9es d'entra\u00eenement</li> <li> Une fonction d'activation sp\u00e9cifique</li> <li> Le temps n\u00e9cessaire pour entra\u00eener un mod\u00e8le</li> </ul>"},{"location":"seance1/ressources/qcm-evaluation/#5-parmi-ces-fonctions-dactivation-laquelle-nest-pas-couramment-utilisee-dans-les-reseaux-de-neurones","title":"5. Parmi ces fonctions d'activation, laquelle n'est pas couramment utilis\u00e9e dans les r\u00e9seaux de neurones ?","text":"<ul> <li> ReLU</li> <li> Sigmoid</li> <li> Tanh</li> <li> Logarithmic</li> <li> Softmax</li> </ul>"},{"location":"seance1/ressources/qcm-evaluation/#6-quel-probleme-les-reseaux-cnn-convolutional-neural-networks-sont-ils-specifiquement-concus-pour-resoudre","title":"6. Quel probl\u00e8me les r\u00e9seaux CNN (Convolutional Neural Networks) sont-ils sp\u00e9cifiquement con\u00e7us pour r\u00e9soudre ?","text":"<ul> <li> Traitement du langage naturel</li> <li> Analyse d'images</li> <li> Pr\u00e9diction de valeurs boursi\u00e8res</li> <li> G\u00e9n\u00e9ration de musique</li> </ul>"},{"location":"seance1/ressources/qcm-evaluation/#7-dans-le-contexte-du-deep-learning-que-signifie-le-terme-overfitting","title":"7. Dans le contexte du Deep Learning, que signifie le terme \"overfitting\" ?","text":"<ul> <li> Le mod\u00e8le est trop simple pour capturer les motifs dans les donn\u00e9es</li> <li> Le mod\u00e8le m\u00e9morise les donn\u00e9es d'entra\u00eenement au d\u00e9triment de la g\u00e9n\u00e9ralisation</li> <li> Le mod\u00e8le s'entra\u00eene trop rapidement</li> <li> Le mod\u00e8le utilise trop de ressources computationnelles</li> </ul>"},{"location":"seance1/ressources/qcm-evaluation/#8-quest-ce-que-le-learning-rate-dans-un-reseau-de-neurones","title":"8. Qu'est-ce que le \"learning rate\" dans un r\u00e9seau de neurones ?","text":"<ul> <li> Le taux de neurones activ\u00e9s dans le r\u00e9seau</li> <li> La vitesse \u00e0 laquelle le r\u00e9seau traite les donn\u00e9es</li> <li> Le param\u00e8tre qui contr\u00f4le l'ampleur des ajustements des poids pendant l'entra\u00eenement</li> <li> Le pourcentage de donn\u00e9es utilis\u00e9es pour l'entra\u00eenement</li> </ul>"},{"location":"seance1/ressources/qcm-evaluation/#9-quelles-sont-les-applications-pratiques-du-deep-learning-que-nous-avons-observees-plusieurs-reponses-possibles","title":"9. Quelles sont les applications pratiques du Deep Learning que nous avons observ\u00e9es ? (plusieurs r\u00e9ponses possibles)","text":"<ul> <li> Compl\u00e9tion de code (GitHub Copilot)</li> <li> Reconnaissance d'objets dans des images</li> <li> G\u00e9n\u00e9ration de texte</li> <li> Optimisation des performances mat\u00e9rielles</li> <li> Reconnaissance de chiffres manuscrits</li> </ul>"},{"location":"seance1/ressources/qcm-evaluation/#10-lorsque-nous-avons-modifie-larchitecture-du-reseau-dans-le-hello-world-du-deep-learning-quavons-nous-observe-plusieurs-reponses-possibles","title":"10. Lorsque nous avons modifi\u00e9 l'architecture du r\u00e9seau dans le \"Hello World du Deep Learning\", qu'avons-nous observ\u00e9 ? (plusieurs r\u00e9ponses possibles)","text":"<ul> <li> Ajouter plus de neurones am\u00e9liore toujours les performances</li> <li> Trop de neurones peut causer du surapprentissage</li> <li> Le choix de la fonction d'activation influence les performances</li> <li> Le temps d'entra\u00eenement est ind\u00e9pendant du nombre de neurones</li> </ul>"},{"location":"seance1/ressources/qcm-evaluation/#11-quelle-technique-avons-nous-utilisee-pour-comparer-la-generalisation-du-machine-learning-classique-et-du-deep-learning","title":"11. Quelle technique avons-nous utilis\u00e9e pour comparer la g\u00e9n\u00e9ralisation du Machine Learning classique et du Deep Learning ?","text":"<ul> <li> Mesure du temps d'inf\u00e9rence</li> <li> Test sur des donn\u00e9es intentionnellement bruit\u00e9es</li> <li> Visualisation des fronti\u00e8res de d\u00e9cision</li> <li> Comparaison des fonctions d'activation</li> </ul>"},{"location":"seance1/ressources/qcm-evaluation/#12-dans-un-neurone-artificiel-quel-est-le-role-du-biais-bias","title":"12. Dans un neurone artificiel, quel est le r\u00f4le du biais (bias) ?","text":"<ul> <li> Il permet d'acc\u00e9l\u00e9rer l'apprentissage</li> <li> Il ajuste le seuil d'activation du neurone</li> <li> Il limite la valeur maximale de sortie</li> <li> Il connecte les neurones entre eux</li> </ul>"},{"location":"seance1/ressources/qcm-evaluation/#13-lors-de-lamelioration-du-modele-cnn-dans-le-mini-projet-quelle-modification-a-generalement-eu-limpact-le-plus-positif","title":"13. Lors de l'am\u00e9lioration du mod\u00e8le CNN dans le mini-projet, quelle modification a g\u00e9n\u00e9ralement eu l'impact le plus positif ?","text":"<ul> <li> Augmentation du learning rate</li> <li> R\u00e9duction du nombre d'\u00e9poques</li> <li> Ajout de couches de convolution</li> <li> Suppression des couches de pooling</li> </ul>"},{"location":"seance1/ressources/qcm-evaluation/#14-quest-ce-qui-caracterise-un-reseau-de-neurones-profond","title":"14. Qu'est-ce qui caract\u00e9rise un r\u00e9seau de neurones \"profond\" ?","text":"<ul> <li> Il utilise uniquement des GPUs pour l'entra\u00eenement</li> <li> Il poss\u00e8de plusieurs couches cach\u00e9es</li> <li> Il traite uniquement des images haute r\u00e9solution</li> <li> Il est entra\u00een\u00e9 sur d'\u00e9normes quantit\u00e9s de donn\u00e9es</li> </ul>"},{"location":"seance1/ressources/qcm-evaluation/#15-quels-avantages-le-deep-learning-presente-t-il-par-rapport-au-machine-learning-classique-pour-la-reconnaissance-dimages-plusieurs-reponses-possibles","title":"15. Quels avantages le Deep Learning pr\u00e9sente-t-il par rapport au Machine Learning classique pour la reconnaissance d'images ? (plusieurs r\u00e9ponses possibles)","text":"<ul> <li> Il ne n\u00e9cessite pas d'extraction manuelle de caract\u00e9ristiques</li> <li> Il est toujours plus pr\u00e9cis quelles que soient les donn\u00e9es</li> <li> Il peut apprendre des repr\u00e9sentations hi\u00e9rarchiques des caract\u00e9ristiques</li> <li> Il n\u00e9cessite moins de donn\u00e9es d'entra\u00eenement</li> </ul>"},{"location":"seance1/ressources/qcm-evaluation/#soumission","title":"Soumission","text":"<p>Une fois le QCM compl\u00e9t\u00e9, soumettez vos r\u00e9ponses sur la plateforme du cours pour obtenir votre score et les explications des r\u00e9ponses correctes.</p>"},{"location":"seance1/ressources/schema-a-completer/","title":"Sch\u00e9ma conceptuel \u00e0 compl\u00e9ter","text":""},{"location":"seance1/ressources/schema-a-completer/#instructions","title":"Instructions","text":"<p>Le sch\u00e9ma ci-dessous repr\u00e9sente l'architecture et le fonctionnement d'un r\u00e9seau de neurones. Compl\u00e9tez-le en pla\u00e7ant les \u00e9tiquettes appropri\u00e9es aux emplacements num\u00e9rot\u00e9s.</p> <pre><code>                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502             \u2502\n                    \u2502      1      \u2502\n                    \u2502             \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n                          \u25bc\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502                           \u2502\n            \u2502             2             \u2502\n            \u2502                           \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n                          \u25bc\n      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n      \u2502                                   \u2502\n      \u2502               3                   \u2502\n      \u2502                                   \u2502\n      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n                          \u25bc\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502                           \u2502\n            \u2502             4             \u2502\n            \u2502                           \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n                          \u25bc\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502             \u2502\n                    \u2502      5      \u2502\n                    \u2502             \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n                          \u25bc\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502             \u2502\n                    \u2502      6      \u2502\n                    \u2502             \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u25b2\n                          \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502             \u2502\n                    \u2502      7      \u2502\n                    \u2502             \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"seance1/ressources/schema-a-completer/#elements-a-placer","title":"\u00c9l\u00e9ments \u00e0 placer","text":"<p>Choisissez dans la liste suivante les \u00e9l\u00e9ments \u00e0 placer aux emplacements num\u00e9rot\u00e9s :</p> <ol> <li>Couche d'entr\u00e9e (Input Layer)</li> <li>Premi\u00e8re couche cach\u00e9e (Hidden Layer 1)</li> <li>Deuxi\u00e8me couche cach\u00e9e (Hidden Layer 2)</li> <li>Couche de sortie (Output Layer)</li> <li>Pr\u00e9diction (Prediction)</li> <li>Calcul de l'erreur (Loss Calculation)</li> <li>Donn\u00e9es r\u00e9elles (Ground Truth)</li> <li>Forward Propagation</li> <li>Backward Propagation</li> <li>Fonction d'activation</li> <li>Ajustement des poids (Weight Update)</li> <li>Preprocessing des donn\u00e9es</li> </ol>"},{"location":"seance1/ressources/schema-a-completer/#structure-du-reseau","title":"Structure du r\u00e9seau","text":"<p>En plus de compl\u00e9ter le sch\u00e9ma, indiquez :</p> <ol> <li> <p>Quel type de r\u00e9seau de neurones est repr\u00e9sent\u00e9 ici ? _____</p> </li> <li> <p>Combien de neurones pourrait contenir chaque couche pour un probl\u00e8me de reconnaissance de chiffres manuscrits (MNIST) ?</p> </li> <li>Couche d'entr\u00e9e : _</li> <li>Premi\u00e8re couche cach\u00e9e : _</li> <li>Deuxi\u00e8me couche cach\u00e9e : _</li> <li> <p>Couche de sortie : _</p> </li> <li> <p>Quelle fonction d'activation serait appropri\u00e9e pour :</p> </li> <li>Les couches cach\u00e9es : _____</li> <li>La couche de sortie : _____</li> </ol>"},{"location":"seance1/ressources/schema-a-completer/#processus-dapprentissage","title":"Processus d'apprentissage","text":"<p>D\u00e9crivez bri\u00e8vement les \u00e9tapes du processus d'apprentissage en utilisant les termes appropri\u00e9s :</p>"},{"location":"seance1/ressources/schema-a-completer/#rendu","title":"Rendu","text":"<p>Une fois compl\u00e9t\u00e9, incluez ce sch\u00e9ma dans votre synth\u00e8se personnelle en expliquant comment ces diff\u00e9rentes composantes interagissent pour permettre l'apprentissage du r\u00e9seau.</p>"},{"location":"seance1%20bis/partie1-mise-en-situation/","title":"Partie1 mise en situation","text":""},{"location":"seance1%20bis/partie1-mise-en-situation/#phase-1-mise-en-situation-pratique-1h","title":"Phase 1 : Mise en situation pratique (1h)","text":""},{"location":"seance1%20bis/partie1-mise-en-situation/#introduction-par-lexemple-15-min","title":"Introduction par l'exemple (15 min)","text":"<p>Objectif : D\u00e9couvrez le Deep Learning par la pratique : une immersion imm\u00e9diate pour ma\u00eetriser les fondamentaux et comprendre leur pertinence dans votre parcours de d\u00e9veloppeur.</p> <p>D\u00e9roulement :</p> <ol> <li> <p>D\u00e9monstration 1 : GitHub Copilot ou similaire (4 min)</p> <ul> <li>Montrer en direct la compl\u00e9tion de code intelligente.</li> <li>Exemple : \u00e9crire le d\u00e9but d'une fonction et laisser l'IA compl\u00e9ter.</li> <li>Expliquer bri\u00e8vement que c'est du Deep Learning qui analyse des millions de lignes de code.</li> </ul> </li> <li> <p>D\u00e9monstration 2 : D\u00e9tection d'erreurs dans le code (4 min)</p> <ul> <li>Pr\u00e9senter un exemple de code avec des bugs subtils.</li> <li>Utiliser un outil bas\u00e9 sur le Deep Learning pour les d\u00e9tecter.</li> <li>Montrer la diff\u00e9rence avec un linter classique.</li> </ul> </li> <li> <p>D\u00e9monstration 3 : G\u00e9n\u00e9ration d'interface utilisateur (4 min)</p> <ul> <li>Montrer comment \u00e0 partir d'une description textuelle ou d'un croquis.</li> <li>Un mod\u00e8le de Deep Learning peut g\u00e9n\u00e9rer du code HTML/CSS.</li> <li>Mettre en avant l'impact sur la productivit\u00e9 du d\u00e9veloppeur.</li> </ul> </li> <li> <p>Message cl\u00e9 (3 min)</p> <ul> <li>Expliquer que ces outils font d\u00e9j\u00e0 partie de l'environnement de travail des d\u00e9veloppeurs.</li> <li>Souligner que comprendre leur fonctionnement permet de mieux les utiliser.</li> <li>Annoncer qu'ils vont pouvoir exp\u00e9rimenter eux-m\u00eames imm\u00e9diatement.</li> </ul> </li> </ol>"},{"location":"seance1%20bis/partie1-mise-en-situation/#prise-en-main-immediate-45-min","title":"Prise en main imm\u00e9diate (45 min)","text":"<p>Objectif : Faire manipuler rapidement un mod\u00e8le de Deep Learning fonctionnel sans s'enliser dans des d\u00e9tails techniques.</p> <p>D\u00e9roulement :</p> <ol> <li> <p>Configuration de l'environnement Google Colab (10 min)</p> <ul> <li>Guide pas \u00e0 pas pour acc\u00e9der \u00e0 Google Colab.</li> <li>Connexion avec compte Google (ou pr\u00e9voir des comptes g\u00e9n\u00e9riques).</li> <li>V\u00e9rification que tous les \u00e9tudiants ont acc\u00e8s \u00e0 la plateforme.</li> <li>Pr\u00e9sentation rapide de l'interface (cellules de code, ex\u00e9cution, etc.).</li> </ul> </li> <li> <p>Notebook \"Hello World du Deep Learning\" (20 min)</p> <ul> <li>Partage du lien vers un notebook pr\u00e9configur\u00e9.</li> <li>Le notebook contient un mod\u00e8le simple de reconnaissance de chiffres manuscrits (MNIST).</li> <li>Structure du notebook :<ul> <li>Cellule 1 : Importation des biblioth\u00e8ques et chargement des donn\u00e9es.</li> <li>Cellule 2 : D\u00e9finition du mod\u00e8le (d\u00e9j\u00e0 configur\u00e9).</li> <li>Cellule 3 : Entra\u00eenement (limit\u00e9 \u00e0 quelques \u00e9poques pour \u00eatre rapide).</li> <li>Cellule 4 : Visualisation des r\u00e9sultats avec graphiques.</li> <li>Cellule 5 : Interface pour tester le mod\u00e8le avec leur propre dessin.</li> </ul> </li> </ul> </li> <li> <p>Challenge rapide : Exp\u00e9rimentation guid\u00e9e (15 min)</p> <ul> <li>Mission : \"Que se passe-t-il si on modifie X ?\"</li> <li>Proposer 3-4 modifications simples \u00e0 essayer :<ul> <li>Changer le nombre d'\u00e9poques d'entra\u00eenement.</li> <li>Modifier le nombre de neurones dans une couche.</li> <li>Changer la fonction d'activation.</li> <li>Ajuster le learning rate.</li> </ul> </li> <li>Les \u00e9tudiants testent, observent et notent les diff\u00e9rences de performances.</li> </ul> </li> <li> <p>Partage rapide des observations (10 minutes)</p> <ul> <li>Tour de table rapide : \"Qu'avez-vous d\u00e9couvert ?\"</li> <li>Mise en commun des effets observ\u00e9s.</li> <li>Introduction informelle de quelques termes cl\u00e9s bas\u00e9s sur leurs d\u00e9couvertes.</li> </ul> </li> </ol> <p>Mat\u00e9riel et ressources pour la Phase 1 :</p> <ul> <li>Lien vers le notebook Google Colab pr\u00e9configur\u00e9.</li> <li>Document d'accompagnement avec les \u00e9tapes \u00e0 suivre.</li> <li>Fiche \"Que faire si \u00e7a ne marche pas ?\" avec solutions aux probl\u00e8mes courants.</li> <li>Liste des modifications sugg\u00e9r\u00e9es pour le challenge rapide.</li> </ul>"},{"location":"seance1%20bis/partie2-decouverte-concepts/","title":"Partie2 decouverte concepts","text":""},{"location":"seance1%20bis/partie2-decouverte-concepts/#phase-2-decouverte-des-concepts-par-lexperimentation-1h30","title":"Phase 2 : D\u00e9couverte des concepts par l'exp\u00e9rimentation (1h30)","text":""},{"location":"seance1%20bis/partie2-decouverte-concepts/#atelier-pratique-boite-noire-machine-learning-vs-deep-learning-45-min","title":"Atelier pratique \"Bo\u00eete noire\" : Machine Learning vs Deep Learning (45 min)","text":"<p>Objectif : Comprendre par la pratique les diff\u00e9rences fondamentales entre le Machine Learning classique et le Deep Learning.</p> <p>D\u00e9roulement :</p> <ol> <li>Pr\u00e9paration et contexte (5 min)<ul> <li>Travaillez en bin\u00f4me. Chaque bin\u00f4me doit explorer en parall\u00e8le les deux notebooks fournis.</li> <li>Compte Google (pour acc\u00e9der \u00e0 Google Colab)</li> <li>Liens vers deux notebooks compl\u00e9mentaires :<ul> <li>Notebook A : Classification avec un algorithme classique (Random Forest).</li> <li>Notebook B : Classification avec un r\u00e9seau de neurones simple.</li> </ul> </li> <li>Explication du jeu de donn\u00e9es : MNIST (chiffres manuscrits) ou Fashion MNIST (v\u00eatements).</li> </ul> </li> </ol> <p>Instructions</p> <p>\u00c9tape 1 : Exploration parall\u00e8le (25 min)</p> <ol> <li>Ouvrez les deux notebooks (A et B) dans deux onglets s\u00e9par\u00e9s.</li> <li>Ex\u00e9cutez les cellules dans l'ordre indiqu\u00e9 (Ctrl+Enter ou bouton \u25b6\ufe0f).</li> <li>Pour chaque notebook, observez et notez :<ul> <li>Comment les donn\u00e9es sont pr\u00e9par\u00e9es</li> <li>Quels param\u00e8tres peuvent \u00eatre ajust\u00e9s</li> <li>Le temps n\u00e9cessaire \u00e0 l'entra\u00eenement</li> <li>Les performances obtenues (pr\u00e9cision, rappel, F1-score)</li> <li>Les types d'erreurs commises par chaque mod\u00e8le</li> </ul> </li> <li>Utilisez ce tableau comparatif pour vos notes :</li> </ol> Aspect observ\u00e9 Machine Learning (Random Forest) Deep Learning (R\u00e9seau de neurones) Pr\u00e9paration des donn\u00e9es Param\u00e8tres principaux Temps d'entra\u00eenement Pr\u00e9cision globale Types d'erreurs fr\u00e9quentes <p>\u00c9tape 2 : D\u00e9fi de g\u00e9n\u00e9ralisation (10 min)</p> <ol> <li>Dans chaque notebook, localisez la section \"D\u00e9fi de g\u00e9n\u00e9ralisation\".</li> <li>Ex\u00e9cutez les cellules qui chargent le nouveau jeu de test.</li> <li>Observez comment chaque mod\u00e8le performe sur ces nouvelles donn\u00e9es.</li> <li>Notez les diff\u00e9rences de performance entre les deux approches.</li> </ol> <p>Questions \u00e0 discuter :</p> <ul> <li>Lequel des mod\u00e8les g\u00e9n\u00e9ralise le mieux aux nouvelles donn\u00e9es ?</li> <li>Pourquoi pensez-vous qu'il y a cette diff\u00e9rence ?</li> <li>Quels avantages et inconv\u00e9nients voyez-vous pour chaque approche ?</li> </ul> <p>\u00c9tape 3 : Mise en commun (5 min)</p> <p>Pr\u00e9parez-vous \u00e0 partager vos observations avec le reste de la classe :</p> <ul> <li>Principales diff\u00e9rences constat\u00e9es</li> <li>Surprises ou d\u00e9couvertes int\u00e9ressantes</li> <li>Questions que cette exp\u00e9rimentation a soulev\u00e9es</li> </ul> <p>Concepts cl\u00e9s \u00e0 identifier</p> <p>\u00c0 travers cette exp\u00e9rimentation, essayez d'identifier par vous-m\u00eames ces concepts fondamentaux :</p> <ul> <li>Comment les caract\u00e9ristiques (features) sont trait\u00e9es dans chaque approche</li> <li>Le r\u00f4le de la repr\u00e9sentation des donn\u00e9es</li> <li>La capacit\u00e9 d'abstraction des diff\u00e9rents mod\u00e8les</li> <li>Les compromis entre temps d'entra\u00eenement et performance</li> </ul> <p>Ressources suppl\u00e9mentaires</p> <ul> <li>Documentation scikit-learn (Random Forest) : [lien]</li> <li>Documentation TensorFlow/Keras : [lien]</li> <li>Visualisations interactives : [lien]</li> </ul>"},{"location":"seance1%20bis/partie2-decouverte-concepts/#tp-guide-anatomie-dun-reseau-de-neurones-45-min","title":"TP guid\u00e9 : Anatomie d'un r\u00e9seau de neurones (45 min)","text":"<p>Objectif : D\u00e9mystifier le fonctionnement interne d'un r\u00e9seau de neurones en le manipulant directement.</p> <p>Mat\u00e9riel et ressources pour la Phase 2 :</p> <ul> <li>Compte Google (pour acc\u00e9der \u00e0 Google Colab)</li> <li>Deux notebooks comparatifs (ML classique vs Deep Learning).</li> <li>Notebook interactif \"Anatomie d'un r\u00e9seau de neurones\" avec visualisations.</li> <li>Jeu de donn\u00e9es de test suppl\u00e9mentaire pour le d\u00e9fi de g\u00e9n\u00e9ralisation.</li> <li>Sch\u00e9ma \u00e0 compl\u00e9ter pour la synth\u00e8se.</li> <li>Fiche r\u00e9capitulative des termes techniques associ\u00e9s.</li> </ul> <p>Instructions</p> <p>Partie 1 : Exploration d'un neurone unique (15 min)</p> <p>Dans cette partie, vous allez manipuler un neurone artificiel unique pour comprendre son fonctionnement de base.</p> <ol> <li>Ex\u00e9cutez les cellules d'importation des biblioth\u00e8ques et de configuration.</li> <li>Localisez la section \"Neurone unique\" et ex\u00e9cutez la cellule d'initialisation.</li> <li>Exp\u00e9rimentez avec les contr\u00f4les interactifs pour :<ul> <li>Modifier les valeurs d'entr\u00e9e (x\u2081, x\u2082)</li> <li>Ajuster les poids (w\u2081, w\u2082)</li> <li>Changer la valeur du biais (b)</li> <li>Observer l'effet sur la sortie du neurone</li> </ul> </li> </ol> <p>Questions \u00e0 explorer :</p> <ul> <li>Que se passe-t-il si tous les poids sont \u00e0 z\u00e9ro ?</li> <li>Comment pouvez-vous configurer le neurone pour qu'il s'active uniquement si les deux entr\u00e9es sont \u00e9lev\u00e9es ?</li> <li>Quel est l'effet du biais sur le \"seuil\" d'activation ?</li> <li>Comment la fonction d'activation ReLU transforme-t-elle la sortie ?</li> </ul> <p>Partie 2 : De l'unique au r\u00e9seau (15 min)</p> <p>Nous allons maintenant passer \u00e0 un petit r\u00e9seau de neurones pour comprendre comment l'information circule \u00e0 travers les couches.</p> <ol> <li>Localisez la section \"R\u00e9seau simple\" et ex\u00e9cutez les cellules d'initialisation.</li> <li>Explorez le r\u00e9seau compos\u00e9 de :<ul> <li>Une couche d'entr\u00e9e (2 neurones)</li> <li>Une couche cach\u00e9e (3 neurones)</li> <li>Une couche de sortie (1 neurone)</li> </ul> </li> <li>R\u00e9alisez les exp\u00e9riences suivantes :<ul> <li>Observez comment le signal se propage \u00e0 travers les couches</li> <li>Suivez le parcours d'une information sp\u00e9cifique (valeur d'entr\u00e9e)</li> <li>Identifiez les \"motifs d'activation\" qui se forment pour diff\u00e9rentes entr\u00e9es</li> <li>Testez diff\u00e9rentes fonctions d'activation (ReLU, Sigmoid, Tanh)</li> </ul> </li> </ol> <p>Exercice pratique : Essayez de configurer manuellement les poids pour que le r\u00e9seau r\u00e9alise la fonction logique XOR (entr\u00e9es : [0,0]\u21920, [0,1]\u21921, [1,0]\u21921, [1,1]\u21920).</p> <p>Partie 3 : Visualisation de l'entra\u00eenement (10 min)</p> <p>Dans cette partie, vous allez observer comment un r\u00e9seau apprend au fil du temps.</p> <ol> <li>Localisez la section \"Entra\u00eenement\" et ex\u00e9cutez la cellule d'initialisation.</li> <li>Lancez la visualisation de l'entra\u00eenement en temps r\u00e9el.</li> <li>Observez :<ul> <li>L'\u00e9volution des poids \u00e0 chaque it\u00e9ration</li> <li>Comment la \"fronti\u00e8re de d\u00e9cision\" se modifie</li> <li>La diminution de l'erreur au fil des \u00e9poques</li> </ul> </li> <li>Essayez de modifier :<ul> <li>Le taux d'apprentissage (learning rate)</li> <li>La complexit\u00e9 du probl\u00e8me (type de donn\u00e9es)</li> <li>L'architecture du r\u00e9seau (nombre de neurones)</li> </ul> </li> </ol> <p>Partie 4 : Synth\u00e8se et verbalisation (10 min)</p> <ol> <li>Compl\u00e9tez le sch\u00e9ma du r\u00e9seau de neurones fourni en fin de notebook.</li> <li>Identifiez et nommez correctement :<ul> <li>Les entr\u00e9es et sorties</li> <li>Les poids et biais</li> <li>Les fonctions d'activation</li> <li>Les couches cach\u00e9es</li> </ul> </li> <li>R\u00e9digez un court paragraphe (5-7 lignes) expliquant avec vos propres mots :<ul> <li>Comment un r\u00e9seau de neurones traite l'information</li> <li>Comment il peut apprendre \u00e0 partir d'exemples</li> </ul> </li> </ol> <p>Points cl\u00e9s \u00e0 retenir</p> <p>\u00c0 travers cette exploration, vous devriez avoir d\u00e9couvert :</p> <ul> <li>Le r\u00f4le fondamental des poids et biais</li> <li>L'importance des fonctions d'activation pour introduire la non-lin\u00e9arit\u00e9</li> <li>Comment l'information se propage \u00e0 travers un r\u00e9seau (forward propagation)</li> <li>Les bases du processus d'apprentissage (ajustement des poids)</li> </ul> <p>Ressources suppl\u00e9mentaires</p> <ul> <li>Visualisations interactives : Playground TensorFlow</li> <li>Tutoriel : Comprendre les r\u00e9seaux de neurones</li> <li>Document : Math\u00e9matiques des r\u00e9seaux de neurones simplifi\u00e9es</li> </ul> <p>Cette phase vous permet de passer de l'observation pure \u00e0 une compr\u00e9hension plus approfondie des m\u00e9canismes internes du Deep Learning, tout en conservant une approche tr\u00e8s pratique et exp\u00e9rimentale.</p>"},{"location":"seance1%20bis/partie3-mini-projet/","title":"Partie3 mini projet","text":""},{"location":"seance1%20bis/partie3-mini-projet/#phase-3-mini-projet-collaboratif-1h","title":"Phase 3 : Mini-projet collaboratif (1h)","text":""},{"location":"seance1%20bis/partie3-mini-projet/#objectif","title":"Objectif","text":"<p>Plongez directement dans l'am\u00e9lioration concr\u00e8te d'un mod\u00e8le de Deep Learning ! Cet atelier vous permettra de ma\u00eetriser les facteurs cl\u00e9s de performance des r\u00e9seaux de neurones, tout en aiguisant vos comp\u00e9tences en r\u00e9solution de probl\u00e8mes et en travail d'\u00e9quipe.</p>"},{"location":"seance1%20bis/partie3-mini-projet/#deroulement","title":"D\u00e9roulement","text":"<ol> <li> <p>Formation des groupes (5 min)</p> <ul> <li>Constitution de groupes de 3-4 \u00e9tudiants.</li> <li>Attribution d'un notebook par groupe contenant un mod\u00e8le de base fonctionnel mais avec des performances m\u00e9diocres.</li> </ul> </li> <li> <p>Pr\u00e9sentation du challenge (10 min)</p> <ul> <li>Explication du probl\u00e8me : classification d'images MNIST avec un r\u00e9seau de neurones simple atteignant seulement 85% de pr\u00e9cision.</li> <li>Objectif : am\u00e9liorer la performance en modifiant l'architecture et les hyperparam\u00e8tres.</li> <li>R\u00e8gles : chaque groupe doit documenter ses modifications et justifier ses choix.</li> <li>Pr\u00e9sentation du tableau de scores en temps r\u00e9el o\u00f9 la pr\u00e9cision de chaque mod\u00e8le sera affich\u00e9e.</li> </ul> </li> <li> <p>Travail en groupe (35 min)</p> <ul> <li>Analyse du mod\u00e8le de base et identification des limitations.</li> <li>Exploration des options d'am\u00e9lioration :<ul> <li>Modification du nombre de neurones et de couches.</li> <li>Ajustement des fonctions d'activation.</li> <li>Changement des hyperparam\u00e8tres d'apprentissage (taux d'apprentissage, taille des batchs).</li> <li>Ajout de techniques de r\u00e9gularisation (dropout, batch normalization).</li> </ul> </li> <li>Test des modifications et observation des r\u00e9sultats.</li> <li>Documentation des essais dans un tableau de suivi fourni.</li> </ul> </li> <li> <p>Partage des r\u00e9sultats (10 min)</p> <ul> <li>Chaque groupe soumet sa meilleure version.</li> <li>Les r\u00e9sultats sont compil\u00e9s dans le tableau de scores.</li> <li>Annonce des trois meilleurs mod\u00e8les.</li> </ul> </li> </ol>"},{"location":"seance1%20bis/partie3-mini-projet/#notebook-de-base-fourni","title":"Notebook de base fourni","text":"<p>Le notebook fourni \u00e0 chaque groupe contient :</p> <ul> <li>Code de chargement des donn\u00e9es MNIST.</li> <li>Mod\u00e8le de base simple (1-2 couches) avec une pr\u00e9cision d'environ 85%.</li> <li>Fonctions d'\u00e9valuation et de visualisation des r\u00e9sultats.</li> <li>Sections comment\u00e9es sugg\u00e9rant des zones \u00e0 modifier.</li> </ul>"},{"location":"seance1%20bis/partie3-mini-projet/#ressources-a-disposition","title":"Ressources \u00e0 disposition","text":"<ul> <li>Fiche r\u00e9capitulative des architectures possibles de r\u00e9seaux de neurones.</li> <li>Guide des hyperparam\u00e8tres avec plages de valeurs recommand\u00e9es.</li> <li>Documentation TensorFlow/Keras simplifi\u00e9e ciblant les fonctions pertinentes.</li> <li>Syst\u00e8me de questions/r\u00e9ponses pour d\u00e9bloquer les groupes en difficult\u00e9.</li> </ul>"},{"location":"seance1%20bis/partie3-mini-projet/#tableau-de-suivi-des-modifications","title":"Tableau de suivi des modifications","text":"<p>Chaque groupe remplit un tableau de suivi incluant :</p> <ul> <li>Description de chaque modification test\u00e9e.</li> <li>Impact observ\u00e9 sur la performance (pr\u00e9cision sur l'ensemble de validation).</li> <li>Temps d'entra\u00eenement.</li> <li>Commentaires et observations.</li> </ul>"},{"location":"seance1%20bis/partie3-mini-projet/#evaluation","title":"\u00c9valuation","text":"<p>L'\u00e9valuation porte sur :</p> <ul> <li>L'am\u00e9lioration effective de la performance du mod\u00e8le.</li> <li>La pertinence des modifications apport\u00e9es.</li> <li>La qualit\u00e9 de l'analyse et de la documentation.</li> <li>La capacit\u00e9 \u00e0 justifier les choix techniques.</li> </ul>"},{"location":"seance1%20bis/partie4-debrief/","title":"Partie4 debrief","text":""},{"location":"seance1%20bis/partie4-debrief/#phase-4-debrief-et-conceptualisation-30-min","title":"Phase 4: D\u00e9brief et conceptualisation (30 min)","text":""},{"location":"seance1%20bis/partie4-debrief/#objectif","title":"Objectif","text":"<p>Formaliser vos connaissances acquises pendant la session pratique et \u00e9tablir le vocabulaire technique du Deep Learning \u00e0 partir de vos exp\u00e9riences v\u00e9cues.</p>"},{"location":"seance1%20bis/partie4-debrief/#deroulement","title":"D\u00e9roulement","text":"<ol> <li> <p>Mise en commun des d\u00e9couvertes (20 min)</p> <ul> <li>Chaque groupe pr\u00e9sente bri\u00e8vement (2-3 minutes) sa meilleure solution.</li> <li>Points \u00e0 aborder dans la pr\u00e9sentation :<ul> <li>Modifications qui ont eu le plus d'impact.</li> <li>Apprentissages cl\u00e9s de leurs exp\u00e9rimentations.</li> <li>D\u00e9fis rencontr\u00e9s et comment ils les ont surmont\u00e9s.</li> </ul> </li> <li>Construction collaborative d'une carte mentale des concepts cl\u00e9s au tableau :<ul> <li>Les liens entre concepts sont visualis\u00e9s.</li> <li>Les termes techniques sont formalis\u00e9s.</li> </ul> </li> </ul> </li> <li> <p>Synth\u00e8se et introduction de la terminologie (10 min)</p> <ul> <li>Reprise des concepts d\u00e9couverts empiriquement.</li> <li>Introduction formelle du vocabulaire technique correspondant.</li> <li>Distribution du document de synth\u00e8se.</li> <li>Pr\u00e9sentation des ressources disponibles pour approfondir.</li> </ul> </li> </ol>"},{"location":"seance2/arborescence/","title":"Arborescence","text":"<p>seance2/ \u2502 \u251c\u2500\u2500 index.md                                       # Page principale de la s\u00e9ance 2 \u2502 \u251c\u2500\u2500 atelier1-reconnaissance-images/                # Atelier 1 \u2502   \u251c\u2500\u2500 guide-atelier1.md                          # Guide de travail pratique \u2502   \u251c\u2500\u2500 notebooks/ \u2502   \u2502   \u251c\u2500\u2500 00_workshop_intro.ipynb                # Introduction \u00e0 l'atelier \u2502   \u2502   \u251c\u2500\u2500 01_model_exploration.ipynb             # Exploration du mod\u00e8le pr\u00e9-entra\u00een\u00e9 \u2502   \u2502   \u251c\u2500\u2500 02_model_adaptation.ipynb              # Adaptation du mod\u00e8le au catalogue \u2502   \u2502   \u2514\u2500\u2500 03_business_adaptation.ipynb           # Configuration des seuils et cas sp\u00e9ciaux \u2502   \u251c\u2500\u2500 api_project/ \u2502   \u2502   \u251c\u2500\u2500 app.py                                 # Squelette de l'API Flask \u2502   \u2502   \u251c\u2500\u2500 requirements.txt                       # D\u00e9pendances Python \u2502   \u2502   \u2514\u2500\u2500 Dockerfile                             # Template pour la conteneurisation \u2502   \u251c\u2500\u2500 api_docs/ \u2502   \u2502   \u2514\u2500\u2500 openapi.yaml                           # Documentation OpenAPI/Swagger \u2502   \u2514\u2500\u2500 data/ \u2502       \u251c\u2500\u2500 examples/                              # Images d'exemple pour les tests \u2502       \u2514\u2500\u2500 techretail/                            # Dataset client (images + m\u00e9tadonn\u00e9es) \u2502 \u251c\u2500\u2500 atelier2-assistant-virtuel/                    # Atelier 2 \u2502   \u251c\u2500\u2500 guide-atelier2.md                          # Guide de travail pratique \u2502   \u251c\u2500\u2500 notebooks/ \u2502   \u2502   \u251c\u2500\u2500 01_data_exploration.ipynb              # Analyse du dataset de tickets \u2502   \u2502   \u251c\u2500\u2500 02_data_preparation.ipynb              # Pr\u00e9traitement du texte \u2502   \u2502   \u251c\u2500\u2500 03_model_setup.ipynb                   # Configuration du mod\u00e8le NLP \u2502   \u2502   \u2514\u2500\u2500 04_model_training.ipynb                # Entra\u00eenement et \u00e9valuation \u2502   \u251c\u2500\u2500 knowledge_base/                            # Base de connaissances pour l'assistant \u2502   \u2502   \u251c\u2500\u2500 common_issues.json                     # Probl\u00e8mes fr\u00e9quents \u2502   \u2502   \u251c\u2500\u2500 hardware_issues.json                   # Probl\u00e8mes mat\u00e9riels \u2502   \u2502   \u251c\u2500\u2500 software_issues.json                   # Probl\u00e8mes logiciels \u2502   \u2502   \u2514\u2500\u2500 network_issues.json                    # Probl\u00e8mes r\u00e9seau \u2502   \u251c\u2500\u2500 assistant_api/ \u2502   \u2502   \u251c\u2500\u2500 app.py                                 # Serveur Flask pour l'assistant \u2502   \u2502   \u2514\u2500\u2500 utils/                                 # Fonctions utilitaires \u2502   \u251c\u2500\u2500 chat_interface/ \u2502   \u2502   \u251c\u2500\u2500 index.html                             # Interface web de chat \u2502   \u2502   \u251c\u2500\u2500 styles.css                             # Styles CSS \u2502   \u2502   \u2514\u2500\u2500 script.js                              # Script JavaScript \u00e0 compl\u00e9ter \u2502   \u251c\u2500\u2500 routing_system.py                          # Syst\u00e8me de routage des demandes \u2502   \u2514\u2500\u2500 test_assistant.py                          # Outil de test \u2502 \u251c\u2500\u2500 atelier3-optimisation-deploiement/              # Atelier 3 \u2502   \u251c\u2500\u2500 guide-atelier3.md                          # Guide de travail pratique \u2502   \u251c\u2500\u2500 notebooks/ \u2502   \u2502   \u251c\u2500\u2500 01_performance_analysis.ipynb          # Analyse des performances \u2502   \u2502   \u251c\u2500\u2500 02_quantization.ipynb                  # Techniques de quantification \u2502   \u2502   \u2514\u2500\u2500 03_inference_optimization.ipynb        # Optimisation des op\u00e9rations d'inf\u00e9rence \u2502   \u251c\u2500\u2500 image_recognition_service/                 # Service de reconnaissance d'images \u2502   \u2502   \u251c\u2500\u2500 Dockerfile                             # Template \u00e0 compl\u00e9ter \u2502   \u2502   \u2514\u2500\u2500 app/                                   # Code source du service \u2502   \u251c\u2500\u2500 assistant_service/                         # Service d'assistant virtuel \u2502   \u2502   \u251c\u2500\u2500 Dockerfile                             # Template \u00e0 compl\u00e9ter \u2502   \u2502   \u2514\u2500\u2500 app/                                   # Code source du service \u2502   \u251c\u2500\u2500 monitoring/                                # Configuration du monitoring \u2502   \u2502   \u251c\u2500\u2500 prometheus/                            # Configuration Prometheus \u2502   \u2502   \u2514\u2500\u2500 grafana/                               # Dashboards Grafana \u2502   \u251c\u2500\u2500 docker-compose.yml                         # Configuration multi-services \u2502   \u251c\u2500\u2500 deploy.sh                                  # Script de d\u00e9ploiement \u2502   \u2514\u2500\u2500 health_check.sh                            # Script de v\u00e9rification \u2502 \u2514\u2500\u2500 ressources/                                    # Ressources communes     \u251c\u2500\u2500 guides/     \u2502   \u251c\u2500\u2500 bonnes_pratiques_api.md                # Guide des bonnes pratiques API REST     \u2502   \u251c\u2500\u2500 conteneurisation_ml.md                 # Guide de conteneurisation pour ML     \u2502   \u2514\u2500\u2500 optimisation_modeles.md                # Guide d'optimisation des mod\u00e8les     \u251c\u2500\u2500 templates/     \u2502   \u251c\u2500\u2500 compte_rendu.md                        # Template de compte-rendu     \u2502   \u2514\u2500\u2500 documentation_technique.md             # Template de documentation technique     \u2514\u2500\u2500 evaluation/         \u2514\u2500\u2500 grille_evaluation.md                   # Grille d'\u00e9valuation d\u00e9taill\u00e9e</p>"}]}